{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"prefect-dbt Welcome! prefect-dbt is a collection of Prefect integrations for working with dbt with your Prefect flows. Getting Started Python setup Requires an installation of Python 3.7+. We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv. These tasks are designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the Prefect documentation . Installation Install prefect-dbt with pip : pip install prefect-dbt Some dbt CLI profiles require additional installation; for example Databricks: pip install dbt-databricks Then, register to view the blocks on Prefect Cloud: prefect block register -m prefect_dbt Note, to use the load method on Blocks, you must already have a block document saved through code or saved through the UI . Trigger a dbt Cloud job and wait for completion from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion @flow def run_dbt_job_flow (): run_result = trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 ) run_dbt_job_flow () Execute a dbt CLI command from prefect import flow from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_command_flow () -> str : result = trigger_dbt_cli_command ( \"dbt debug\" ) return result # Returns the last line the in CLI output trigger_dbt_cli_command_flow () Execute a dbt CLI command without a pre-populated profiles.yml from prefect import flow from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command from prefect_dbt.cli.configs import SnowflakeTargetConfigs @flow def trigger_dbt_cli_command_flow (): connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ), ) target_configs = SnowflakeTargetConfigs ( connector = connector ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) result = trigger_dbt_cli_command ( \"dbt debug\" , overwrite_profiles = True , dbt_cli_profile = dbt_cli_profile ) return result trigger_dbt_cli_command_flow () Idempotent way to execute multiple dbt CLI commands without prepopulated profiles.yml from prefect import flow from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_commands_flow (): dbt_cli_profile = DbtCliProfile . load ( \"MY_BLOCK_NAME\" ) trigger_kwargs = dict ( profiles_dir = \".\" , overwrite_profiles = True , dbt_cli_profile = dbt_cli_profile , ) trigger_dbt_cli_command ( \"dbt deps\" , ** trigger_kwargs ) result = trigger_dbt_cli_command ( \"dbt debug\" , ** trigger_kwargs ) return result trigger_dbt_cli_commands_flow () Resources If you encounter any bugs while using prefect-dbt , feel free to open an issue in the prefect-dbt repository. If you have any questions or issues while using prefect-dbt , you can find help in either the Prefect Discourse forum or the Prefect Slack community . If you need help getting started with or using dbt, please consult the dbt documentation . Feel free to \u2b50\ufe0f or watch prefect-dbt for updates too! Development If you'd like to install a version of prefect-dbt for development, clone the repository and perform an editable install with pip : git clone https://github.com/PrefectHQ/prefect-dbt.git cd prefect-dbt/ pip install -e \".[dev]\" # Install linting pre-commit hooks pre-commit install","title":"Home"},{"location":"#prefect-dbt","text":"","title":"prefect-dbt"},{"location":"#welcome","text":"prefect-dbt is a collection of Prefect integrations for working with dbt with your Prefect flows.","title":"Welcome!"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#python-setup","text":"Requires an installation of Python 3.7+. We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv. These tasks are designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the Prefect documentation .","title":"Python setup"},{"location":"#installation","text":"Install prefect-dbt with pip : pip install prefect-dbt Some dbt CLI profiles require additional installation; for example Databricks: pip install dbt-databricks Then, register to view the blocks on Prefect Cloud: prefect block register -m prefect_dbt Note, to use the load method on Blocks, you must already have a block document saved through code or saved through the UI .","title":"Installation"},{"location":"#trigger-a-dbt-cloud-job-and-wait-for-completion","text":"from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion @flow def run_dbt_job_flow (): run_result = trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 ) run_dbt_job_flow ()","title":"Trigger a dbt Cloud job and wait for completion"},{"location":"#execute-a-dbt-cli-command","text":"from prefect import flow from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_command_flow () -> str : result = trigger_dbt_cli_command ( \"dbt debug\" ) return result # Returns the last line the in CLI output trigger_dbt_cli_command_flow ()","title":"Execute a dbt CLI command"},{"location":"#execute-a-dbt-cli-command-without-a-pre-populated-profilesyml","text":"from prefect import flow from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command from prefect_dbt.cli.configs import SnowflakeTargetConfigs @flow def trigger_dbt_cli_command_flow (): connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ), ) target_configs = SnowflakeTargetConfigs ( connector = connector ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) result = trigger_dbt_cli_command ( \"dbt debug\" , overwrite_profiles = True , dbt_cli_profile = dbt_cli_profile ) return result trigger_dbt_cli_command_flow ()","title":"Execute a dbt CLI command without a pre-populated profiles.yml"},{"location":"#idempotent-way-to-execute-multiple-dbt-cli-commands-without-prepopulated-profilesyml","text":"from prefect import flow from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_commands_flow (): dbt_cli_profile = DbtCliProfile . load ( \"MY_BLOCK_NAME\" ) trigger_kwargs = dict ( profiles_dir = \".\" , overwrite_profiles = True , dbt_cli_profile = dbt_cli_profile , ) trigger_dbt_cli_command ( \"dbt deps\" , ** trigger_kwargs ) result = trigger_dbt_cli_command ( \"dbt debug\" , ** trigger_kwargs ) return result trigger_dbt_cli_commands_flow ()","title":"Idempotent way to execute multiple dbt CLI commands without prepopulated profiles.yml"},{"location":"#resources","text":"If you encounter any bugs while using prefect-dbt , feel free to open an issue in the prefect-dbt repository. If you have any questions or issues while using prefect-dbt , you can find help in either the Prefect Discourse forum or the Prefect Slack community . If you need help getting started with or using dbt, please consult the dbt documentation . Feel free to \u2b50\ufe0f or watch prefect-dbt for updates too!","title":"Resources"},{"location":"#development","text":"If you'd like to install a version of prefect-dbt for development, clone the repository and perform an editable install with pip : git clone https://github.com/PrefectHQ/prefect-dbt.git cd prefect-dbt/ pip install -e \".[dev]\" # Install linting pre-commit hooks pre-commit install","title":"Development"},{"location":"cli/commands/","text":"prefect_dbt.cli.commands Module containing tasks and flows for interacting with dbt CLI Classes Functions trigger_dbt_cli_command async Task for running dbt commands. If no profiles.yml file is found or if overwrite_profiles flag is set to True, this will first generate a profiles.yml file in the profiles_dir directory. Then run the dbt CLI shell command. Parameters: Name Type Description Default command str The dbt command to be executed. required profiles_dir Optional [ Union [ Path , str ]] The directory to search for the profiles.yml file. Setting this appends the --profiles-dir option to the command provided. If this is not set, will try using the DBT_PROFILES_DIR environment variable, but if that's also not set, will use the default directory $HOME/.dbt/ . None project_dir Optional [ Union [ Path , str ]] The directory to search for the dbt_project.yml file. Default is the current working directory and its parents. None overwrite_profiles bool Whether the existing profiles.yml file under profiles_dir should be overwritten with a new profile. False dbt_cli_profile Optional [ DbtCliProfile ] Profiles class containing the profile written to profiles.yml. Note! This is optional and will raise an error if profiles.yml already exists under profile_dir and overwrite_profiles is set to False. None **shell_run_command_kwargs Dict [ str , Any ] Additional keyword arguments to pass to shell_run_command . {} Returns: Name Type Description last_line_cli_output str The last line of the CLI output will be returned if return_all in shell_run_command_kwargs is False. This is the default behavior. full_cli_output List [ str ] Full CLI output will be returned if return_all in shell_run_command_kwargs is True. Examples: Execute dbt debug with a pre-populated profiles.yml. from prefect import flow from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_command_flow (): result = trigger_dbt_cli_command ( \"dbt debug\" ) return result trigger_dbt_cli_command_flow () Execute dbt debug without a pre-populated profiles.yml. from prefect import flow from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials @flow def trigger_dbt_cli_command_flow (): credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ) connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = credentials , ) target_configs = SnowflakeTargetConfigs ( connector = connector ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) result = trigger_dbt_cli_command ( \"dbt debug\" , overwrite_profiles = True , dbt_cli_profile = dbt_cli_profile ) return result trigger_dbt_cli_command_flow () Source code in prefect_dbt/cli/commands.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 @task async def trigger_dbt_cli_command ( command : str , profiles_dir : Optional [ Union [ Path , str ]] = None , project_dir : Optional [ Union [ Path , str ]] = None , overwrite_profiles : bool = False , dbt_cli_profile : Optional [ DbtCliProfile ] = None , ** shell_run_command_kwargs : Dict [ str , Any ], ) -> Union [ List [ str ], str ]: \"\"\" Task for running dbt commands. If no profiles.yml file is found or if overwrite_profiles flag is set to True, this will first generate a profiles.yml file in the profiles_dir directory. Then run the dbt CLI shell command. Args: command: The dbt command to be executed. profiles_dir: The directory to search for the profiles.yml file. Setting this appends the `--profiles-dir` option to the command provided. If this is not set, will try using the DBT_PROFILES_DIR environment variable, but if that's also not set, will use the default directory `$HOME/.dbt/`. project_dir: The directory to search for the dbt_project.yml file. Default is the current working directory and its parents. overwrite_profiles: Whether the existing profiles.yml file under profiles_dir should be overwritten with a new profile. dbt_cli_profile: Profiles class containing the profile written to profiles.yml. Note! This is optional and will raise an error if profiles.yml already exists under profile_dir and overwrite_profiles is set to False. **shell_run_command_kwargs: Additional keyword arguments to pass to [shell_run_command](https://prefecthq.github.io/prefect-shell/commands/#prefect_shell.commands.shell_run_command). Returns: last_line_cli_output (str): The last line of the CLI output will be returned if `return_all` in `shell_run_command_kwargs` is False. This is the default behavior. full_cli_output (List[str]): Full CLI output will be returned if `return_all` in `shell_run_command_kwargs` is True. Examples: Execute `dbt debug` with a pre-populated profiles.yml. ```python from prefect import flow from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_command_flow(): result = trigger_dbt_cli_command(\"dbt debug\") return result trigger_dbt_cli_command_flow() ``` Execute `dbt debug` without a pre-populated profiles.yml. ```python from prefect import flow from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials @flow def trigger_dbt_cli_command_flow(): credentials = SnowflakeCredentials( user=\"user\", password=\"password\", account=\"account.region.aws\", role=\"role\", ) connector = SnowflakeConnector( schema=\"public\", database=\"database\", warehouse=\"warehouse\", credentials=credentials, ) target_configs = SnowflakeTargetConfigs( connector=connector ) dbt_cli_profile = DbtCliProfile( name=\"jaffle_shop\", target=\"dev\", target_configs=target_configs, ) result = trigger_dbt_cli_command( \"dbt debug\", overwrite_profiles=True, dbt_cli_profile=dbt_cli_profile ) return result trigger_dbt_cli_command_flow() ``` \"\"\" # noqa # check if variable is set, if not check env, if not use expected default logger = get_run_logger () if not which ( \"dbt\" ): raise ImportError ( \"dbt-core needs to be installed to use this task; run \" '`pip install \"prefect-dbt[cli]\"' ) elif not command . startswith ( \"dbt\" ): await shell_run_command . fn ( command = \"dbt --help\" ) raise ValueError ( \"Command is not a valid dbt sub-command; see dbt --help above,\" \"or use prefect_shell.commands.shell_run_command for non-dbt related \" \"commands instead\" ) if profiles_dir is None : profiles_dir = os . getenv ( \"DBT_PROFILES_DIR\" , Path . home () / \".dbt\" ) profiles_dir = Path ( profiles_dir ) . expanduser () # https://docs.getdbt.com/dbt-cli/configure-your-profile # Note that the file always needs to be called profiles.yml, # regardless of which directory it is in. profiles_path = profiles_dir / \"profiles.yml\" logger . debug ( f \"Using this profiles path: { profiles_path } \" ) # write the profile if overwrite or no profiles exist if overwrite_profiles or not profiles_path . exists (): if dbt_cli_profile is None : raise ValueError ( \"Provide `dbt_cli_profile` keyword for writing profiles\" ) profile = dbt_cli_profile . get_profile () profiles_dir . mkdir ( exist_ok = True ) with open ( profiles_path , \"w+\" ) as f : yaml . dump ( profile , f , default_flow_style = False ) logger . info ( f \"Wrote profile to { profiles_path } \" ) elif dbt_cli_profile is not None : raise ValueError ( f \"Since overwrite_profiles is False and profiles_path ( { profiles_path } ) \" f \"already exists, the profile within dbt_cli_profile could not be used; \" f \"if the existing profile is satisfactory, do not pass dbt_cli_profile\" ) # append the options command += f \" --profiles-dir { profiles_dir } \" if project_dir is not None : project_dir = Path ( project_dir ) . expanduser () command += f \" --project-dir { project_dir } \" # fix up empty shell_run_command_kwargs shell_run_command_kwargs = shell_run_command_kwargs or {} logger . info ( f \"Running dbt command: { command } \" ) result = await shell_run_command . fn ( command = command , ** shell_run_command_kwargs ) return result","title":"Commands"},{"location":"cli/commands/#prefect_dbt.cli.commands","text":"Module containing tasks and flows for interacting with dbt CLI","title":"commands"},{"location":"cli/commands/#prefect_dbt.cli.commands-classes","text":"","title":"Classes"},{"location":"cli/commands/#prefect_dbt.cli.commands-functions","text":"","title":"Functions"},{"location":"cli/commands/#prefect_dbt.cli.commands.trigger_dbt_cli_command","text":"Task for running dbt commands. If no profiles.yml file is found or if overwrite_profiles flag is set to True, this will first generate a profiles.yml file in the profiles_dir directory. Then run the dbt CLI shell command. Parameters: Name Type Description Default command str The dbt command to be executed. required profiles_dir Optional [ Union [ Path , str ]] The directory to search for the profiles.yml file. Setting this appends the --profiles-dir option to the command provided. If this is not set, will try using the DBT_PROFILES_DIR environment variable, but if that's also not set, will use the default directory $HOME/.dbt/ . None project_dir Optional [ Union [ Path , str ]] The directory to search for the dbt_project.yml file. Default is the current working directory and its parents. None overwrite_profiles bool Whether the existing profiles.yml file under profiles_dir should be overwritten with a new profile. False dbt_cli_profile Optional [ DbtCliProfile ] Profiles class containing the profile written to profiles.yml. Note! This is optional and will raise an error if profiles.yml already exists under profile_dir and overwrite_profiles is set to False. None **shell_run_command_kwargs Dict [ str , Any ] Additional keyword arguments to pass to shell_run_command . {} Returns: Name Type Description last_line_cli_output str The last line of the CLI output will be returned if return_all in shell_run_command_kwargs is False. This is the default behavior. full_cli_output List [ str ] Full CLI output will be returned if return_all in shell_run_command_kwargs is True. Examples: Execute dbt debug with a pre-populated profiles.yml. from prefect import flow from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_command_flow (): result = trigger_dbt_cli_command ( \"dbt debug\" ) return result trigger_dbt_cli_command_flow () Execute dbt debug without a pre-populated profiles.yml. from prefect import flow from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials @flow def trigger_dbt_cli_command_flow (): credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ) connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = credentials , ) target_configs = SnowflakeTargetConfigs ( connector = connector ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) result = trigger_dbt_cli_command ( \"dbt debug\" , overwrite_profiles = True , dbt_cli_profile = dbt_cli_profile ) return result trigger_dbt_cli_command_flow () Source code in prefect_dbt/cli/commands.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 @task async def trigger_dbt_cli_command ( command : str , profiles_dir : Optional [ Union [ Path , str ]] = None , project_dir : Optional [ Union [ Path , str ]] = None , overwrite_profiles : bool = False , dbt_cli_profile : Optional [ DbtCliProfile ] = None , ** shell_run_command_kwargs : Dict [ str , Any ], ) -> Union [ List [ str ], str ]: \"\"\" Task for running dbt commands. If no profiles.yml file is found or if overwrite_profiles flag is set to True, this will first generate a profiles.yml file in the profiles_dir directory. Then run the dbt CLI shell command. Args: command: The dbt command to be executed. profiles_dir: The directory to search for the profiles.yml file. Setting this appends the `--profiles-dir` option to the command provided. If this is not set, will try using the DBT_PROFILES_DIR environment variable, but if that's also not set, will use the default directory `$HOME/.dbt/`. project_dir: The directory to search for the dbt_project.yml file. Default is the current working directory and its parents. overwrite_profiles: Whether the existing profiles.yml file under profiles_dir should be overwritten with a new profile. dbt_cli_profile: Profiles class containing the profile written to profiles.yml. Note! This is optional and will raise an error if profiles.yml already exists under profile_dir and overwrite_profiles is set to False. **shell_run_command_kwargs: Additional keyword arguments to pass to [shell_run_command](https://prefecthq.github.io/prefect-shell/commands/#prefect_shell.commands.shell_run_command). Returns: last_line_cli_output (str): The last line of the CLI output will be returned if `return_all` in `shell_run_command_kwargs` is False. This is the default behavior. full_cli_output (List[str]): Full CLI output will be returned if `return_all` in `shell_run_command_kwargs` is True. Examples: Execute `dbt debug` with a pre-populated profiles.yml. ```python from prefect import flow from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_command_flow(): result = trigger_dbt_cli_command(\"dbt debug\") return result trigger_dbt_cli_command_flow() ``` Execute `dbt debug` without a pre-populated profiles.yml. ```python from prefect import flow from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials @flow def trigger_dbt_cli_command_flow(): credentials = SnowflakeCredentials( user=\"user\", password=\"password\", account=\"account.region.aws\", role=\"role\", ) connector = SnowflakeConnector( schema=\"public\", database=\"database\", warehouse=\"warehouse\", credentials=credentials, ) target_configs = SnowflakeTargetConfigs( connector=connector ) dbt_cli_profile = DbtCliProfile( name=\"jaffle_shop\", target=\"dev\", target_configs=target_configs, ) result = trigger_dbt_cli_command( \"dbt debug\", overwrite_profiles=True, dbt_cli_profile=dbt_cli_profile ) return result trigger_dbt_cli_command_flow() ``` \"\"\" # noqa # check if variable is set, if not check env, if not use expected default logger = get_run_logger () if not which ( \"dbt\" ): raise ImportError ( \"dbt-core needs to be installed to use this task; run \" '`pip install \"prefect-dbt[cli]\"' ) elif not command . startswith ( \"dbt\" ): await shell_run_command . fn ( command = \"dbt --help\" ) raise ValueError ( \"Command is not a valid dbt sub-command; see dbt --help above,\" \"or use prefect_shell.commands.shell_run_command for non-dbt related \" \"commands instead\" ) if profiles_dir is None : profiles_dir = os . getenv ( \"DBT_PROFILES_DIR\" , Path . home () / \".dbt\" ) profiles_dir = Path ( profiles_dir ) . expanduser () # https://docs.getdbt.com/dbt-cli/configure-your-profile # Note that the file always needs to be called profiles.yml, # regardless of which directory it is in. profiles_path = profiles_dir / \"profiles.yml\" logger . debug ( f \"Using this profiles path: { profiles_path } \" ) # write the profile if overwrite or no profiles exist if overwrite_profiles or not profiles_path . exists (): if dbt_cli_profile is None : raise ValueError ( \"Provide `dbt_cli_profile` keyword for writing profiles\" ) profile = dbt_cli_profile . get_profile () profiles_dir . mkdir ( exist_ok = True ) with open ( profiles_path , \"w+\" ) as f : yaml . dump ( profile , f , default_flow_style = False ) logger . info ( f \"Wrote profile to { profiles_path } \" ) elif dbt_cli_profile is not None : raise ValueError ( f \"Since overwrite_profiles is False and profiles_path ( { profiles_path } ) \" f \"already exists, the profile within dbt_cli_profile could not be used; \" f \"if the existing profile is satisfactory, do not pass dbt_cli_profile\" ) # append the options command += f \" --profiles-dir { profiles_dir } \" if project_dir is not None : project_dir = Path ( project_dir ) . expanduser () command += f \" --project-dir { project_dir } \" # fix up empty shell_run_command_kwargs shell_run_command_kwargs = shell_run_command_kwargs or {} logger . info ( f \"Running dbt command: { command } \" ) result = await shell_run_command . fn ( command = command , ** shell_run_command_kwargs ) return result","title":"trigger_dbt_cli_command()"},{"location":"cli/credentials/","text":"prefect_dbt.cli.credentials Module containing credentials for interacting with dbt CLI Classes DbtCliProfile Bases: Block Profile for use across dbt CLI tasks and flows. Attributes: Name Type Description name str Profile name used for populating profiles.yml. target str The default target your dbt project will use. target_configs TargetConfigs Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink. global_configs GlobalConfigs Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Valid keys can be found here . Examples: Load stored dbt CLI profile: from prefect_dbt.cli import DbtCliProfile dbt_cli_profile = DbtCliProfile . load ( \"BLOCK_NAME\" ) . get_profile () Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs: from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ) connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = credentials , ) target_configs = SnowflakeTargetConfigs ( connector = connector ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) profile = dbt_cli_profile . get_profile () Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs: from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import GlobalConfigs , TargetConfigs target_configs_extras = dict ( host = \"hostname.region.redshift.amazonaws.com\" , user = \"username\" , password = \"password1\" , port = 5439 , dbname = \"analytics\" , ) target_configs = TargetConfigs ( type = \"redshift\" , schema = \"schema\" , threads = 4 , extras = target_configs_extras ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) profile = dbt_cli_profile . get_profile () Source code in prefect_dbt/cli/credentials.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 class DbtCliProfile ( Block ): \"\"\" Profile for use across dbt CLI tasks and flows. Attributes: name (str): Profile name used for populating profiles.yml. target (str): The default target your dbt project will use. target_configs (TargetConfigs): Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the [Available adapters]( https://docs.getdbt.com/docs/available-adapters) page and click the desired adapter's \"Profile Setup\" hyperlink. global_configs (GlobalConfigs): Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Valid keys can be found [here]( https://docs.getdbt.com/reference/global-configs). Examples: Load stored dbt CLI profile: ```python from prefect_dbt.cli import DbtCliProfile dbt_cli_profile = DbtCliProfile.load(\"BLOCK_NAME\").get_profile() ``` Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs: ```python from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector credentials = SnowflakeCredentials( user=\"user\", password=\"password\", account=\"account.region.aws\", role=\"role\", ) connector = SnowflakeConnector( schema=\"public\", database=\"database\", warehouse=\"warehouse\", credentials=credentials, ) target_configs = SnowflakeTargetConfigs( connector=connector ) dbt_cli_profile = DbtCliProfile( name=\"jaffle_shop\", target=\"dev\", target_configs=target_configs, ) profile = dbt_cli_profile.get_profile() ``` Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs: ```python from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import GlobalConfigs, TargetConfigs target_configs_extras = dict( host=\"hostname.region.redshift.amazonaws.com\", user=\"username\", password=\"password1\", port=5439, dbname=\"analytics\", ) target_configs = TargetConfigs( type=\"redshift\", schema=\"schema\", threads=4, extras=target_configs_extras ) dbt_cli_profile = DbtCliProfile( name=\"jaffle_shop\", target=\"dev\", target_configs=target_configs, ) profile = dbt_cli_profile.get_profile() ``` \"\"\" _block_type_name = \"dbt CLI Profile\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa name : str target : str target_configs : TargetConfigs global_configs : Optional [ GlobalConfigs ] = None def get_profile ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt profile, likely used for writing to profiles.yml. Returns: A JSON compatible dictionary with the expected format of profiles.yml. \"\"\" profile = { \"config\" : self . global_configs . get_configs () if self . global_configs else {}, self . name : { \"target\" : self . target , \"outputs\" : { self . target : self . target_configs . get_configs ()}, }, } return profile Functions get_profile Returns the dbt profile, likely used for writing to profiles.yml. Returns: Type Description Dict [ str , Any ] A JSON compatible dictionary with the expected format of profiles.yml. Source code in prefect_dbt/cli/credentials.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def get_profile ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt profile, likely used for writing to profiles.yml. Returns: A JSON compatible dictionary with the expected format of profiles.yml. \"\"\" profile = { \"config\" : self . global_configs . get_configs () if self . global_configs else {}, self . name : { \"target\" : self . target , \"outputs\" : { self . target : self . target_configs . get_configs ()}, }, } return profile","title":"Credentials"},{"location":"cli/credentials/#prefect_dbt.cli.credentials","text":"Module containing credentials for interacting with dbt CLI","title":"credentials"},{"location":"cli/credentials/#prefect_dbt.cli.credentials-classes","text":"","title":"Classes"},{"location":"cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile","text":"Bases: Block Profile for use across dbt CLI tasks and flows. Attributes: Name Type Description name str Profile name used for populating profiles.yml. target str The default target your dbt project will use. target_configs TargetConfigs Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink. global_configs GlobalConfigs Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Valid keys can be found here . Examples: Load stored dbt CLI profile: from prefect_dbt.cli import DbtCliProfile dbt_cli_profile = DbtCliProfile . load ( \"BLOCK_NAME\" ) . get_profile () Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs: from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ) connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = credentials , ) target_configs = SnowflakeTargetConfigs ( connector = connector ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) profile = dbt_cli_profile . get_profile () Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs: from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import GlobalConfigs , TargetConfigs target_configs_extras = dict ( host = \"hostname.region.redshift.amazonaws.com\" , user = \"username\" , password = \"password1\" , port = 5439 , dbname = \"analytics\" , ) target_configs = TargetConfigs ( type = \"redshift\" , schema = \"schema\" , threads = 4 , extras = target_configs_extras ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) profile = dbt_cli_profile . get_profile () Source code in prefect_dbt/cli/credentials.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 class DbtCliProfile ( Block ): \"\"\" Profile for use across dbt CLI tasks and flows. Attributes: name (str): Profile name used for populating profiles.yml. target (str): The default target your dbt project will use. target_configs (TargetConfigs): Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the [Available adapters]( https://docs.getdbt.com/docs/available-adapters) page and click the desired adapter's \"Profile Setup\" hyperlink. global_configs (GlobalConfigs): Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Valid keys can be found [here]( https://docs.getdbt.com/reference/global-configs). Examples: Load stored dbt CLI profile: ```python from prefect_dbt.cli import DbtCliProfile dbt_cli_profile = DbtCliProfile.load(\"BLOCK_NAME\").get_profile() ``` Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs: ```python from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector credentials = SnowflakeCredentials( user=\"user\", password=\"password\", account=\"account.region.aws\", role=\"role\", ) connector = SnowflakeConnector( schema=\"public\", database=\"database\", warehouse=\"warehouse\", credentials=credentials, ) target_configs = SnowflakeTargetConfigs( connector=connector ) dbt_cli_profile = DbtCliProfile( name=\"jaffle_shop\", target=\"dev\", target_configs=target_configs, ) profile = dbt_cli_profile.get_profile() ``` Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs: ```python from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import GlobalConfigs, TargetConfigs target_configs_extras = dict( host=\"hostname.region.redshift.amazonaws.com\", user=\"username\", password=\"password1\", port=5439, dbname=\"analytics\", ) target_configs = TargetConfigs( type=\"redshift\", schema=\"schema\", threads=4, extras=target_configs_extras ) dbt_cli_profile = DbtCliProfile( name=\"jaffle_shop\", target=\"dev\", target_configs=target_configs, ) profile = dbt_cli_profile.get_profile() ``` \"\"\" _block_type_name = \"dbt CLI Profile\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa name : str target : str target_configs : TargetConfigs global_configs : Optional [ GlobalConfigs ] = None def get_profile ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt profile, likely used for writing to profiles.yml. Returns: A JSON compatible dictionary with the expected format of profiles.yml. \"\"\" profile = { \"config\" : self . global_configs . get_configs () if self . global_configs else {}, self . name : { \"target\" : self . target , \"outputs\" : { self . target : self . target_configs . get_configs ()}, }, } return profile","title":"DbtCliProfile"},{"location":"cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile-functions","text":"","title":"Functions"},{"location":"cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile.get_profile","text":"Returns the dbt profile, likely used for writing to profiles.yml. Returns: Type Description Dict [ str , Any ] A JSON compatible dictionary with the expected format of profiles.yml. Source code in prefect_dbt/cli/credentials.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def get_profile ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt profile, likely used for writing to profiles.yml. Returns: A JSON compatible dictionary with the expected format of profiles.yml. \"\"\" profile = { \"config\" : self . global_configs . get_configs () if self . global_configs else {}, self . name : { \"target\" : self . target , \"outputs\" : { self . target : self . target_configs . get_configs ()}, }, } return profile","title":"get_profile()"},{"location":"cli/configs/base/","text":"prefect_dbt.cli.configs.base Module containing models for base configs Classes DbtConfigs Bases: Block , abc . ABC Abstract class for other dbt Configs. Attributes: Name Type Description extras Optional [ Dict [ str , Any ]] Extra target configs' keywords, not yet added to prefect-dbt, but available in dbt; if there are duplicate keys between extras and TargetConfigs, an error will be raised. Source code in prefect_dbt/cli/configs/base.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class DbtConfigs ( Block , abc . ABC ): \"\"\" Abstract class for other dbt Configs. Attributes: extras: Extra target configs' keywords, not yet added to prefect-dbt, but available in dbt; if there are duplicate keys between extras and TargetConfigs, an error will be raised. \"\"\" extras : Optional [ Dict [ str , Any ]] = None def _populate_configs_json ( self , configs_json : Dict [ str , Any ], fields : Dict [ str , Any ], model : BaseModel = None , ) -> Dict [ str , Any ]: \"\"\" Recursively populate configs_json. \"\"\" for field_name , field in fields . items (): if model is not None : # get actual value from model field_value = getattr ( model , field_name ) # override the name with alias so dbt parser can recognize the keyword; # e.g. schema_ -> schema, returns the original name if no alias is set field_name = field . alias else : field_value = field if field_value is None : # do not add to configs json if no value or default is set continue if isinstance ( field_value , BaseModel ): configs_json = self . _populate_configs_json ( configs_json , field_value . __fields__ , model = field_value ) elif field_name == \"extras\" : configs_json = self . _populate_configs_json ( configs_json , field_value ) else : if field_name in configs_json . keys (): raise ValueError ( f \"The keyword, { field_name } , has already been provided in \" f \"TargetConfigs; remove duplicated keywords to continue\" ) if isinstance ( field_value , SecretField ): field_value = field_value . get_secret_value () configs_json [ field_name ] = field_value return configs_json def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs, likely used eventually for writing to profiles.yml. Returns: A configs JSON. \"\"\" return self . _populate_configs_json ({}, self . __fields__ , model = self ) Functions get_configs Returns the dbt configs, likely used eventually for writing to profiles.yml. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/base.py 64 65 66 67 68 69 70 71 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs, likely used eventually for writing to profiles.yml. Returns: A configs JSON. \"\"\" return self . _populate_configs_json ({}, self . __fields__ , model = self ) GlobalConfigs Bases: DbtConfigs Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Docs can be found here . Attributes: Name Type Description send_anonymous_usage_stats Optional [ bool ] Whether usage stats are sent to dbt. use_colors Optional [ bool ] Colorize the output it prints in your terminal. partial_parse Optional [ bool ] When partial parsing is enabled, dbt will use an stored internal manifest to determine which files have been changed (if any) since it last parsed the project. printer_width Optional [ int ] Length of characters before starting a new line. write_json Optional [ bool ] Determines whether dbt writes JSON artifacts to the target/ directory. warn_error Optional [ bool ] Whether to convert dbt warnings into errors. log_format Optional [ bool ] The LOG_FORMAT config specifies how dbt's logs should be formatted. If the value of this config is json, dbt will output fully structured logs in JSON format. debug Optional [ bool ] Whether to redirect dbt's debug logs to standard out. version_check Optional [ bool ] Whether to raise an error if a project's version is used with an incompatible dbt version. fail_fast Optional [ bool ] Make dbt exit immediately if a single resource fails to build. use_experimental_parser Optional [ bool ] Opt into the latest experimental version of the static parser. static_parser Optional [ bool ] Whether to use the static parser . Examples: Load stored GlobalConfigs: from prefect_dbt.cli.configs import GlobalConfigs dbt_cli_global_configs = GlobalConfigs . load ( \"BLOCK_NAME\" ) Source code in prefect_dbt/cli/configs/base.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 class GlobalConfigs ( DbtConfigs ): \"\"\" Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Docs can be found [here]( https://docs.getdbt.com/reference/global-configs). Attributes: send_anonymous_usage_stats: Whether usage stats are sent to dbt. use_colors: Colorize the output it prints in your terminal. partial_parse: When partial parsing is enabled, dbt will use an stored internal manifest to determine which files have been changed (if any) since it last parsed the project. printer_width: Length of characters before starting a new line. write_json: Determines whether dbt writes JSON artifacts to the target/ directory. warn_error: Whether to convert dbt warnings into errors. log_format: The LOG_FORMAT config specifies how dbt's logs should be formatted. If the value of this config is json, dbt will output fully structured logs in JSON format. debug: Whether to redirect dbt's debug logs to standard out. version_check: Whether to raise an error if a project's version is used with an incompatible dbt version. fail_fast: Make dbt exit immediately if a single resource fails to build. use_experimental_parser: Opt into the latest experimental version of the static parser. static_parser: Whether to use the [static parser]( https://docs.getdbt.com/reference/parsing#static-parser). Examples: Load stored GlobalConfigs: ```python from prefect_dbt.cli.configs import GlobalConfigs dbt_cli_global_configs = GlobalConfigs.load(\"BLOCK_NAME\") ``` \"\"\" _block_type_name = \"dbt CLI Global Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa send_anonymous_usage_stats : Optional [ bool ] = None use_colors : Optional [ bool ] = None partial_parse : Optional [ bool ] = None printer_width : Optional [ int ] = None write_json : Optional [ bool ] = None warn_error : Optional [ bool ] = None log_format : Optional [ bool ] = None debug : Optional [ bool ] = None version_check : Optional [ bool ] = None fail_fast : Optional [ bool ] = None use_experimental_parser : Optional [ bool ] = None static_parser : Optional [ bool ] = None TargetConfigs Bases: DbtConfigs Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink. Attributes: Name Type Description type str The name of the database warehouse schema str The schema that dbt will build objects into; in BigQuery, a schema is actually a dataset. threads int The number of threads representing the max number of paths through the graph dbt may work on at once. Examples: Load stored TargetConfigs: from prefect_dbt.cli.configs import TargetConfigs dbt_cli_target_configs = TargetConfigs . load ( \"BLOCK_NAME\" ) Source code in prefect_dbt/cli/configs/base.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 class TargetConfigs ( DbtConfigs ): \"\"\" Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the [Available adapters]( https://docs.getdbt.com/docs/available-adapters) page and click the desired adapter's \"Profile Setup\" hyperlink. Attributes: type: The name of the database warehouse schema: The schema that dbt will build objects into; in BigQuery, a schema is actually a dataset. threads: The number of threads representing the max number of paths through the graph dbt may work on at once. Examples: Load stored TargetConfigs: ```python from prefect_dbt.cli.configs import TargetConfigs dbt_cli_target_configs = TargetConfigs.load(\"BLOCK_NAME\") ``` \"\"\" _block_type_name = \"dbt CLI Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa type : str schema_ : str = Field ( alias = \"schema\" ) threads : int = 4","title":"Base"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base","text":"Module containing models for base configs","title":"base"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base-classes","text":"","title":"Classes"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs","text":"Bases: Block , abc . ABC Abstract class for other dbt Configs. Attributes: Name Type Description extras Optional [ Dict [ str , Any ]] Extra target configs' keywords, not yet added to prefect-dbt, but available in dbt; if there are duplicate keys between extras and TargetConfigs, an error will be raised. Source code in prefect_dbt/cli/configs/base.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class DbtConfigs ( Block , abc . ABC ): \"\"\" Abstract class for other dbt Configs. Attributes: extras: Extra target configs' keywords, not yet added to prefect-dbt, but available in dbt; if there are duplicate keys between extras and TargetConfigs, an error will be raised. \"\"\" extras : Optional [ Dict [ str , Any ]] = None def _populate_configs_json ( self , configs_json : Dict [ str , Any ], fields : Dict [ str , Any ], model : BaseModel = None , ) -> Dict [ str , Any ]: \"\"\" Recursively populate configs_json. \"\"\" for field_name , field in fields . items (): if model is not None : # get actual value from model field_value = getattr ( model , field_name ) # override the name with alias so dbt parser can recognize the keyword; # e.g. schema_ -> schema, returns the original name if no alias is set field_name = field . alias else : field_value = field if field_value is None : # do not add to configs json if no value or default is set continue if isinstance ( field_value , BaseModel ): configs_json = self . _populate_configs_json ( configs_json , field_value . __fields__ , model = field_value ) elif field_name == \"extras\" : configs_json = self . _populate_configs_json ( configs_json , field_value ) else : if field_name in configs_json . keys (): raise ValueError ( f \"The keyword, { field_name } , has already been provided in \" f \"TargetConfigs; remove duplicated keywords to continue\" ) if isinstance ( field_value , SecretField ): field_value = field_value . get_secret_value () configs_json [ field_name ] = field_value return configs_json def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs, likely used eventually for writing to profiles.yml. Returns: A configs JSON. \"\"\" return self . _populate_configs_json ({}, self . __fields__ , model = self )","title":"DbtConfigs"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs-functions","text":"","title":"Functions"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs.get_configs","text":"Returns the dbt configs, likely used eventually for writing to profiles.yml. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/base.py 64 65 66 67 68 69 70 71 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs, likely used eventually for writing to profiles.yml. Returns: A configs JSON. \"\"\" return self . _populate_configs_json ({}, self . __fields__ , model = self )","title":"get_configs()"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.GlobalConfigs","text":"Bases: DbtConfigs Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Docs can be found here . Attributes: Name Type Description send_anonymous_usage_stats Optional [ bool ] Whether usage stats are sent to dbt. use_colors Optional [ bool ] Colorize the output it prints in your terminal. partial_parse Optional [ bool ] When partial parsing is enabled, dbt will use an stored internal manifest to determine which files have been changed (if any) since it last parsed the project. printer_width Optional [ int ] Length of characters before starting a new line. write_json Optional [ bool ] Determines whether dbt writes JSON artifacts to the target/ directory. warn_error Optional [ bool ] Whether to convert dbt warnings into errors. log_format Optional [ bool ] The LOG_FORMAT config specifies how dbt's logs should be formatted. If the value of this config is json, dbt will output fully structured logs in JSON format. debug Optional [ bool ] Whether to redirect dbt's debug logs to standard out. version_check Optional [ bool ] Whether to raise an error if a project's version is used with an incompatible dbt version. fail_fast Optional [ bool ] Make dbt exit immediately if a single resource fails to build. use_experimental_parser Optional [ bool ] Opt into the latest experimental version of the static parser. static_parser Optional [ bool ] Whether to use the static parser . Examples: Load stored GlobalConfigs: from prefect_dbt.cli.configs import GlobalConfigs dbt_cli_global_configs = GlobalConfigs . load ( \"BLOCK_NAME\" ) Source code in prefect_dbt/cli/configs/base.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 class GlobalConfigs ( DbtConfigs ): \"\"\" Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Docs can be found [here]( https://docs.getdbt.com/reference/global-configs). Attributes: send_anonymous_usage_stats: Whether usage stats are sent to dbt. use_colors: Colorize the output it prints in your terminal. partial_parse: When partial parsing is enabled, dbt will use an stored internal manifest to determine which files have been changed (if any) since it last parsed the project. printer_width: Length of characters before starting a new line. write_json: Determines whether dbt writes JSON artifacts to the target/ directory. warn_error: Whether to convert dbt warnings into errors. log_format: The LOG_FORMAT config specifies how dbt's logs should be formatted. If the value of this config is json, dbt will output fully structured logs in JSON format. debug: Whether to redirect dbt's debug logs to standard out. version_check: Whether to raise an error if a project's version is used with an incompatible dbt version. fail_fast: Make dbt exit immediately if a single resource fails to build. use_experimental_parser: Opt into the latest experimental version of the static parser. static_parser: Whether to use the [static parser]( https://docs.getdbt.com/reference/parsing#static-parser). Examples: Load stored GlobalConfigs: ```python from prefect_dbt.cli.configs import GlobalConfigs dbt_cli_global_configs = GlobalConfigs.load(\"BLOCK_NAME\") ``` \"\"\" _block_type_name = \"dbt CLI Global Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa send_anonymous_usage_stats : Optional [ bool ] = None use_colors : Optional [ bool ] = None partial_parse : Optional [ bool ] = None printer_width : Optional [ int ] = None write_json : Optional [ bool ] = None warn_error : Optional [ bool ] = None log_format : Optional [ bool ] = None debug : Optional [ bool ] = None version_check : Optional [ bool ] = None fail_fast : Optional [ bool ] = None use_experimental_parser : Optional [ bool ] = None static_parser : Optional [ bool ] = None","title":"GlobalConfigs"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.TargetConfigs","text":"Bases: DbtConfigs Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink. Attributes: Name Type Description type str The name of the database warehouse schema str The schema that dbt will build objects into; in BigQuery, a schema is actually a dataset. threads int The number of threads representing the max number of paths through the graph dbt may work on at once. Examples: Load stored TargetConfigs: from prefect_dbt.cli.configs import TargetConfigs dbt_cli_target_configs = TargetConfigs . load ( \"BLOCK_NAME\" ) Source code in prefect_dbt/cli/configs/base.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 class TargetConfigs ( DbtConfigs ): \"\"\" Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the [Available adapters]( https://docs.getdbt.com/docs/available-adapters) page and click the desired adapter's \"Profile Setup\" hyperlink. Attributes: type: The name of the database warehouse schema: The schema that dbt will build objects into; in BigQuery, a schema is actually a dataset. threads: The number of threads representing the max number of paths through the graph dbt may work on at once. Examples: Load stored TargetConfigs: ```python from prefect_dbt.cli.configs import TargetConfigs dbt_cli_target_configs = TargetConfigs.load(\"BLOCK_NAME\") ``` \"\"\" _block_type_name = \"dbt CLI Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa type : str schema_ : str = Field ( alias = \"schema\" ) threads : int = 4","title":"TargetConfigs"},{"location":"cli/configs/bigquery/","text":"prefect_dbt.cli.configs.bigquery Module containing models for BigQuery configs Classes BigQueryTargetConfigs Bases: TargetConfigs Target configs contain credentials and settings, specific to BigQuery. To find valid keys, head to the BigQuery Profile page. Attributes: Name Type Description credentials GcpCredentials The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored BigQueryTargetConfigs: from prefect_dbt.cli.configs import BigQueryTargetConfigs bigquery_target_configs = BigQueryTargetConfigs . load ( \"BLOCK_NAME\" ) Instantiate BigQueryTargetConfigs with service account file. from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials ( service_account_file = \"~/.secrets/gcp\" ) target_configs = BigQueryTargetConfigs ( schema = \"schema\" , project = \"project\" , credentials = credentials , ) Instantiate BigQueryTargetConfigs with service account info. import json from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials ( service_account_info = json . dumps ({ \"type\" : \"service_account\" , \"project_id\" : \"project_id\" , \"private_key_id\" : \"private_key_id\" , \"private_key\" : \"private_key\" , \"client_email\" : \"client_email\" , \"client_id\" : \"client_id\" , \"auth_uri\" : \"auth_uri\" , \"token_uri\" : \"token_uri\" , \"auth_provider_x509_cert_url\" : \"auth_provider_x509_cert_url\" , \"client_x509_cert_url\" : \"client_x509_cert_url\" }) ) target_configs = BigQueryTargetConfigs ( schema = \"schema\" , project = \"project\" , credentials = credentials , ) Source code in prefect_dbt/cli/configs/bigquery.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 class BigQueryTargetConfigs ( TargetConfigs ): \"\"\" Target configs contain credentials and settings, specific to BigQuery. To find valid keys, head to the [BigQuery Profile]( https://docs.getdbt.com/reference/warehouse-profiles/bigquery-profile) page. Attributes: credentials: The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored BigQueryTargetConfigs: ```python from prefect_dbt.cli.configs import BigQueryTargetConfigs bigquery_target_configs = BigQueryTargetConfigs.load(\"BLOCK_NAME\") ``` Instantiate BigQueryTargetConfigs with service account file. ```python from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials(service_account_file=\"~/.secrets/gcp\") target_configs = BigQueryTargetConfigs( schema=\"schema\", project=\"project\", credentials=credentials, ) ``` Instantiate BigQueryTargetConfigs with service account info. ```python import json from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials( service_account_info=json.dumps({ \"type\": \"service_account\", \"project_id\": \"project_id\", \"private_key_id\": \"private_key_id\", \"private_key\": \"private_key\", \"client_email\": \"client_email\", \"client_id\": \"client_id\", \"auth_uri\": \"auth_uri\", \"token_uri\": \"token_uri\", \"auth_provider_x509_cert_url\": \"auth_provider_x509_cert_url\", \"client_x509_cert_url\": \"client_x509_cert_url\" }) ) target_configs = BigQueryTargetConfigs( schema=\"schema\", project=\"project\", credentials=credentials, ) ``` \"\"\" _block_type_name = \"dbt CLI BigQuery Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa _description = \"dbt CLI target configs containing credentials and settings, specific to BigQuery.\" # noqa type : Literal [ \"bigquery\" ] = \"bigquery\" project : Optional [ str ] = None credentials : GcpCredentials @sync_compatible async def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to BigQuery profile. Returns: A configs JSON. \"\"\" # since GcpCredentials will always define a project self_copy = self . copy () if self_copy . project is not None : self_copy . credentials . project = None configs_json = self . _populate_configs_json ( {}, self_copy . __fields__ , model = self_copy ) if \"service_account_info\" in configs_json : configs_json [ \"method\" ] = \"service-account-json\" configs_json [ \"keyfile_json\" ] = configs_json . pop ( \"service_account_info\" ) elif \"service_account_file\" in configs_json : configs_json [ \"method\" ] = \"service-account\" configs_json [ \"keyfile\" ] = str ( configs_json . pop ( \"service_account_file\" )) else : configs_json [ \"method\" ] = \"oauth-secrets\" # through gcloud application-default login google_credentials = ( self_copy . credentials . get_credentials_from_service_account () ) if hasattr ( google_credentials , \"token\" ): configs_json [ \"token\" ] = await self_copy . credentials . get_access_token () else : for key in ( \"refresh_token\" , \"client_id\" , \"client_secret\" , \"token_uri\" ): configs_json [ key ] = getattr ( google_credentials , key ) if \"project\" not in configs_json : raise ValueError ( \"The keyword, project, must be provided in either \" \"GcpCredentials or BigQueryTargetConfigs\" ) return configs_json Functions get_configs async Returns the dbt configs specific to BigQuery profile. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/bigquery.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 @sync_compatible async def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to BigQuery profile. Returns: A configs JSON. \"\"\" # since GcpCredentials will always define a project self_copy = self . copy () if self_copy . project is not None : self_copy . credentials . project = None configs_json = self . _populate_configs_json ( {}, self_copy . __fields__ , model = self_copy ) if \"service_account_info\" in configs_json : configs_json [ \"method\" ] = \"service-account-json\" configs_json [ \"keyfile_json\" ] = configs_json . pop ( \"service_account_info\" ) elif \"service_account_file\" in configs_json : configs_json [ \"method\" ] = \"service-account\" configs_json [ \"keyfile\" ] = str ( configs_json . pop ( \"service_account_file\" )) else : configs_json [ \"method\" ] = \"oauth-secrets\" # through gcloud application-default login google_credentials = ( self_copy . credentials . get_credentials_from_service_account () ) if hasattr ( google_credentials , \"token\" ): configs_json [ \"token\" ] = await self_copy . credentials . get_access_token () else : for key in ( \"refresh_token\" , \"client_id\" , \"client_secret\" , \"token_uri\" ): configs_json [ key ] = getattr ( google_credentials , key ) if \"project\" not in configs_json : raise ValueError ( \"The keyword, project, must be provided in either \" \"GcpCredentials or BigQueryTargetConfigs\" ) return configs_json","title":"BigQuery"},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery","text":"Module containing models for BigQuery configs","title":"bigquery"},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery-classes","text":"","title":"Classes"},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs","text":"Bases: TargetConfigs Target configs contain credentials and settings, specific to BigQuery. To find valid keys, head to the BigQuery Profile page. Attributes: Name Type Description credentials GcpCredentials The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored BigQueryTargetConfigs: from prefect_dbt.cli.configs import BigQueryTargetConfigs bigquery_target_configs = BigQueryTargetConfigs . load ( \"BLOCK_NAME\" ) Instantiate BigQueryTargetConfigs with service account file. from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials ( service_account_file = \"~/.secrets/gcp\" ) target_configs = BigQueryTargetConfigs ( schema = \"schema\" , project = \"project\" , credentials = credentials , ) Instantiate BigQueryTargetConfigs with service account info. import json from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials ( service_account_info = json . dumps ({ \"type\" : \"service_account\" , \"project_id\" : \"project_id\" , \"private_key_id\" : \"private_key_id\" , \"private_key\" : \"private_key\" , \"client_email\" : \"client_email\" , \"client_id\" : \"client_id\" , \"auth_uri\" : \"auth_uri\" , \"token_uri\" : \"token_uri\" , \"auth_provider_x509_cert_url\" : \"auth_provider_x509_cert_url\" , \"client_x509_cert_url\" : \"client_x509_cert_url\" }) ) target_configs = BigQueryTargetConfigs ( schema = \"schema\" , project = \"project\" , credentials = credentials , ) Source code in prefect_dbt/cli/configs/bigquery.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 class BigQueryTargetConfigs ( TargetConfigs ): \"\"\" Target configs contain credentials and settings, specific to BigQuery. To find valid keys, head to the [BigQuery Profile]( https://docs.getdbt.com/reference/warehouse-profiles/bigquery-profile) page. Attributes: credentials: The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored BigQueryTargetConfigs: ```python from prefect_dbt.cli.configs import BigQueryTargetConfigs bigquery_target_configs = BigQueryTargetConfigs.load(\"BLOCK_NAME\") ``` Instantiate BigQueryTargetConfigs with service account file. ```python from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials(service_account_file=\"~/.secrets/gcp\") target_configs = BigQueryTargetConfigs( schema=\"schema\", project=\"project\", credentials=credentials, ) ``` Instantiate BigQueryTargetConfigs with service account info. ```python import json from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials( service_account_info=json.dumps({ \"type\": \"service_account\", \"project_id\": \"project_id\", \"private_key_id\": \"private_key_id\", \"private_key\": \"private_key\", \"client_email\": \"client_email\", \"client_id\": \"client_id\", \"auth_uri\": \"auth_uri\", \"token_uri\": \"token_uri\", \"auth_provider_x509_cert_url\": \"auth_provider_x509_cert_url\", \"client_x509_cert_url\": \"client_x509_cert_url\" }) ) target_configs = BigQueryTargetConfigs( schema=\"schema\", project=\"project\", credentials=credentials, ) ``` \"\"\" _block_type_name = \"dbt CLI BigQuery Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa _description = \"dbt CLI target configs containing credentials and settings, specific to BigQuery.\" # noqa type : Literal [ \"bigquery\" ] = \"bigquery\" project : Optional [ str ] = None credentials : GcpCredentials @sync_compatible async def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to BigQuery profile. Returns: A configs JSON. \"\"\" # since GcpCredentials will always define a project self_copy = self . copy () if self_copy . project is not None : self_copy . credentials . project = None configs_json = self . _populate_configs_json ( {}, self_copy . __fields__ , model = self_copy ) if \"service_account_info\" in configs_json : configs_json [ \"method\" ] = \"service-account-json\" configs_json [ \"keyfile_json\" ] = configs_json . pop ( \"service_account_info\" ) elif \"service_account_file\" in configs_json : configs_json [ \"method\" ] = \"service-account\" configs_json [ \"keyfile\" ] = str ( configs_json . pop ( \"service_account_file\" )) else : configs_json [ \"method\" ] = \"oauth-secrets\" # through gcloud application-default login google_credentials = ( self_copy . credentials . get_credentials_from_service_account () ) if hasattr ( google_credentials , \"token\" ): configs_json [ \"token\" ] = await self_copy . credentials . get_access_token () else : for key in ( \"refresh_token\" , \"client_id\" , \"client_secret\" , \"token_uri\" ): configs_json [ key ] = getattr ( google_credentials , key ) if \"project\" not in configs_json : raise ValueError ( \"The keyword, project, must be provided in either \" \"GcpCredentials or BigQueryTargetConfigs\" ) return configs_json","title":"BigQueryTargetConfigs"},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs-functions","text":"","title":"Functions"},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs.get_configs","text":"Returns the dbt configs specific to BigQuery profile. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/bigquery.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 @sync_compatible async def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to BigQuery profile. Returns: A configs JSON. \"\"\" # since GcpCredentials will always define a project self_copy = self . copy () if self_copy . project is not None : self_copy . credentials . project = None configs_json = self . _populate_configs_json ( {}, self_copy . __fields__ , model = self_copy ) if \"service_account_info\" in configs_json : configs_json [ \"method\" ] = \"service-account-json\" configs_json [ \"keyfile_json\" ] = configs_json . pop ( \"service_account_info\" ) elif \"service_account_file\" in configs_json : configs_json [ \"method\" ] = \"service-account\" configs_json [ \"keyfile\" ] = str ( configs_json . pop ( \"service_account_file\" )) else : configs_json [ \"method\" ] = \"oauth-secrets\" # through gcloud application-default login google_credentials = ( self_copy . credentials . get_credentials_from_service_account () ) if hasattr ( google_credentials , \"token\" ): configs_json [ \"token\" ] = await self_copy . credentials . get_access_token () else : for key in ( \"refresh_token\" , \"client_id\" , \"client_secret\" , \"token_uri\" ): configs_json [ key ] = getattr ( google_credentials , key ) if \"project\" not in configs_json : raise ValueError ( \"The keyword, project, must be provided in either \" \"GcpCredentials or BigQueryTargetConfigs\" ) return configs_json","title":"get_configs()"},{"location":"cli/configs/postgres/","text":"prefect_dbt.cli.configs.postgres Module containing models for Postgres configs Classes PostgresTargetConfigs Bases: TargetConfigs Target configs contain credentials and settings, specific to Postgres. To find valid keys, head to the Postgres Profile page. Attributes: Name Type Description credentials DatabaseCredentials The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored PostgresTargetConfigs: from prefect_dbt.cli.configs import PostgresTargetConfigs postgres_target_configs = PostgresTargetConfigs . load ( \"BLOCK_NAME\" ) Instantiate PostgresTargetConfigs with DatabaseCredentials. from prefect_dbt.cli.configs import PostgresTargetConfigs from prefect_sqlalchemy import DatabaseCredentials , SyncDriver credentials = DatabaseCredentials ( driver = SyncDriver . POSTGRESQL_PSYCOPG2 , username = \"prefect\" , password = \"prefect_password\" , database = \"postgres\" , host = \"host\" , port = 8080 ) target_configs = PostgresTargetConfigs ( credentials = credentials , schema = \"schema\" ) Source code in prefect_dbt/cli/configs/postgres.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class PostgresTargetConfigs ( TargetConfigs ): \"\"\" Target configs contain credentials and settings, specific to Postgres. To find valid keys, head to the [Postgres Profile]( https://docs.getdbt.com/reference/warehouse-profiles/postgres-profile) page. Attributes: credentials: The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored PostgresTargetConfigs: ```python from prefect_dbt.cli.configs import PostgresTargetConfigs postgres_target_configs = PostgresTargetConfigs.load(\"BLOCK_NAME\") ``` Instantiate PostgresTargetConfigs with DatabaseCredentials. ```python from prefect_dbt.cli.configs import PostgresTargetConfigs from prefect_sqlalchemy import DatabaseCredentials, SyncDriver credentials = DatabaseCredentials( driver=SyncDriver.POSTGRESQL_PSYCOPG2, username=\"prefect\", password=\"prefect_password\", database=\"postgres\", host=\"host\", port=8080 ) target_configs = PostgresTargetConfigs(credentials=credentials, schema=\"schema\") ``` \"\"\" _block_type_name = \"dbt CLI Postgres Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa _description = \"dbt CLI target configs containing credentials and settings specific to Postgres.\" # noqa type : Literal [ \"postgres\" ] = \"postgres\" credentials : DatabaseCredentials def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Postgres profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () invalid_keys = [ \"driver\" , \"query\" , \"url\" , \"connect_args\" , \"_async_supported\" ] rename_keys = { \"database\" : \"dbname\" , \"username\" : \"user\" , \"password\" : \"password\" , \"host\" : \"host\" , \"port\" : \"port\" , } # get the keys from rendered url for invalid_key in invalid_keys + list ( rename_keys ): configs_json . pop ( invalid_key , None ) rendered_url = self . credentials . rendered_url for key in rename_keys : renamed_key = rename_keys [ key ] configs_json [ renamed_key ] = getattr ( rendered_url , key ) return configs_json Functions get_configs Returns the dbt configs specific to Postgres profile. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/postgres.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Postgres profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () invalid_keys = [ \"driver\" , \"query\" , \"url\" , \"connect_args\" , \"_async_supported\" ] rename_keys = { \"database\" : \"dbname\" , \"username\" : \"user\" , \"password\" : \"password\" , \"host\" : \"host\" , \"port\" : \"port\" , } # get the keys from rendered url for invalid_key in invalid_keys + list ( rename_keys ): configs_json . pop ( invalid_key , None ) rendered_url = self . credentials . rendered_url for key in rename_keys : renamed_key = rename_keys [ key ] configs_json [ renamed_key ] = getattr ( rendered_url , key ) return configs_json","title":"Postgres"},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres","text":"Module containing models for Postgres configs","title":"postgres"},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres-classes","text":"","title":"Classes"},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs","text":"Bases: TargetConfigs Target configs contain credentials and settings, specific to Postgres. To find valid keys, head to the Postgres Profile page. Attributes: Name Type Description credentials DatabaseCredentials The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored PostgresTargetConfigs: from prefect_dbt.cli.configs import PostgresTargetConfigs postgres_target_configs = PostgresTargetConfigs . load ( \"BLOCK_NAME\" ) Instantiate PostgresTargetConfigs with DatabaseCredentials. from prefect_dbt.cli.configs import PostgresTargetConfigs from prefect_sqlalchemy import DatabaseCredentials , SyncDriver credentials = DatabaseCredentials ( driver = SyncDriver . POSTGRESQL_PSYCOPG2 , username = \"prefect\" , password = \"prefect_password\" , database = \"postgres\" , host = \"host\" , port = 8080 ) target_configs = PostgresTargetConfigs ( credentials = credentials , schema = \"schema\" ) Source code in prefect_dbt/cli/configs/postgres.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class PostgresTargetConfigs ( TargetConfigs ): \"\"\" Target configs contain credentials and settings, specific to Postgres. To find valid keys, head to the [Postgres Profile]( https://docs.getdbt.com/reference/warehouse-profiles/postgres-profile) page. Attributes: credentials: The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored PostgresTargetConfigs: ```python from prefect_dbt.cli.configs import PostgresTargetConfigs postgres_target_configs = PostgresTargetConfigs.load(\"BLOCK_NAME\") ``` Instantiate PostgresTargetConfigs with DatabaseCredentials. ```python from prefect_dbt.cli.configs import PostgresTargetConfigs from prefect_sqlalchemy import DatabaseCredentials, SyncDriver credentials = DatabaseCredentials( driver=SyncDriver.POSTGRESQL_PSYCOPG2, username=\"prefect\", password=\"prefect_password\", database=\"postgres\", host=\"host\", port=8080 ) target_configs = PostgresTargetConfigs(credentials=credentials, schema=\"schema\") ``` \"\"\" _block_type_name = \"dbt CLI Postgres Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa _description = \"dbt CLI target configs containing credentials and settings specific to Postgres.\" # noqa type : Literal [ \"postgres\" ] = \"postgres\" credentials : DatabaseCredentials def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Postgres profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () invalid_keys = [ \"driver\" , \"query\" , \"url\" , \"connect_args\" , \"_async_supported\" ] rename_keys = { \"database\" : \"dbname\" , \"username\" : \"user\" , \"password\" : \"password\" , \"host\" : \"host\" , \"port\" : \"port\" , } # get the keys from rendered url for invalid_key in invalid_keys + list ( rename_keys ): configs_json . pop ( invalid_key , None ) rendered_url = self . credentials . rendered_url for key in rename_keys : renamed_key = rename_keys [ key ] configs_json [ renamed_key ] = getattr ( rendered_url , key ) return configs_json","title":"PostgresTargetConfigs"},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs-functions","text":"","title":"Functions"},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs.get_configs","text":"Returns the dbt configs specific to Postgres profile. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/postgres.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Postgres profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () invalid_keys = [ \"driver\" , \"query\" , \"url\" , \"connect_args\" , \"_async_supported\" ] rename_keys = { \"database\" : \"dbname\" , \"username\" : \"user\" , \"password\" : \"password\" , \"host\" : \"host\" , \"port\" : \"port\" , } # get the keys from rendered url for invalid_key in invalid_keys + list ( rename_keys ): configs_json . pop ( invalid_key , None ) rendered_url = self . credentials . rendered_url for key in rename_keys : renamed_key = rename_keys [ key ] configs_json [ renamed_key ] = getattr ( rendered_url , key ) return configs_json","title":"get_configs()"},{"location":"cli/configs/snowflake/","text":"prefect_dbt.cli.configs.snowflake Module containing models for Snowflake configs Classes SnowflakeTargetConfigs Bases: TargetConfigs Target configs contain credentials and settings, specific to Snowflake. To find valid keys, head to the Snowflake Profile page. Attributes: Name Type Description credentials The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored SnowflakeTargetConfigs: from prefect_dbt.cli.configs import SnowflakeTargetConfigs snowflake_target_configs = SnowflakeTargetConfigs . load ( \"BLOCK_NAME\" ) Instantiate SnowflakeTargetConfigs. from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ) connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = credentials , ) target_configs = SnowflakeTargetConfigs ( connector = connector ) Source code in prefect_dbt/cli/configs/snowflake.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 class SnowflakeTargetConfigs ( TargetConfigs ): \"\"\" Target configs contain credentials and settings, specific to Snowflake. To find valid keys, head to the [Snowflake Profile]( https://docs.getdbt.com/reference/warehouse-profiles/snowflake-profile) page. Attributes: credentials: The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored SnowflakeTargetConfigs: ```python from prefect_dbt.cli.configs import SnowflakeTargetConfigs snowflake_target_configs = SnowflakeTargetConfigs.load(\"BLOCK_NAME\") ``` Instantiate SnowflakeTargetConfigs. ```python from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector credentials = SnowflakeCredentials( user=\"user\", password=\"password\", account=\"account.region.aws\", role=\"role\", ) connector = SnowflakeConnector( schema=\"public\", database=\"database\", warehouse=\"warehouse\", credentials=credentials, ) target_configs = SnowflakeTargetConfigs( connector=connector ) ``` \"\"\" _block_type_name = \"dbt CLI Snowflake Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa type : Literal [ \"snowflake\" ] = \"snowflake\" schema_ : Optional [ str ] = Field ( default = None , alias = \"schema\" ) connector : SnowflakeConnector def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Snowflake profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () return configs_json Functions get_configs Returns the dbt configs specific to Snowflake profile. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/snowflake.py 71 72 73 74 75 76 77 78 79 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Snowflake profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () return configs_json","title":"Snowflake"},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake","text":"Module containing models for Snowflake configs","title":"snowflake"},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake-classes","text":"","title":"Classes"},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs","text":"Bases: TargetConfigs Target configs contain credentials and settings, specific to Snowflake. To find valid keys, head to the Snowflake Profile page. Attributes: Name Type Description credentials The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored SnowflakeTargetConfigs: from prefect_dbt.cli.configs import SnowflakeTargetConfigs snowflake_target_configs = SnowflakeTargetConfigs . load ( \"BLOCK_NAME\" ) Instantiate SnowflakeTargetConfigs. from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ) connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = credentials , ) target_configs = SnowflakeTargetConfigs ( connector = connector ) Source code in prefect_dbt/cli/configs/snowflake.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 class SnowflakeTargetConfigs ( TargetConfigs ): \"\"\" Target configs contain credentials and settings, specific to Snowflake. To find valid keys, head to the [Snowflake Profile]( https://docs.getdbt.com/reference/warehouse-profiles/snowflake-profile) page. Attributes: credentials: The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored SnowflakeTargetConfigs: ```python from prefect_dbt.cli.configs import SnowflakeTargetConfigs snowflake_target_configs = SnowflakeTargetConfigs.load(\"BLOCK_NAME\") ``` Instantiate SnowflakeTargetConfigs. ```python from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector credentials = SnowflakeCredentials( user=\"user\", password=\"password\", account=\"account.region.aws\", role=\"role\", ) connector = SnowflakeConnector( schema=\"public\", database=\"database\", warehouse=\"warehouse\", credentials=credentials, ) target_configs = SnowflakeTargetConfigs( connector=connector ) ``` \"\"\" _block_type_name = \"dbt CLI Snowflake Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa type : Literal [ \"snowflake\" ] = \"snowflake\" schema_ : Optional [ str ] = Field ( default = None , alias = \"schema\" ) connector : SnowflakeConnector def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Snowflake profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () return configs_json","title":"SnowflakeTargetConfigs"},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs-functions","text":"","title":"Functions"},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs.get_configs","text":"Returns the dbt configs specific to Snowflake profile. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/snowflake.py 71 72 73 74 75 76 77 78 79 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Snowflake profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () return configs_json","title":"get_configs()"},{"location":"cloud/clients/","text":"prefect_dbt.cloud.clients Module containing clients for interacting with the dbt Cloud API Classes DbtCloudAdministrativeClient Client for interacting with the dbt cloud Administrative API. Parameters: Name Type Description Default api_key str API key to authenticate with the dbt Cloud administrative API. required account_id int ID of dbt Cloud account with which to interact. required domain str Domain at which the dbt Cloud API is hosted. 'cloud.getdbt.com' Source code in prefect_dbt/cloud/clients.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 class DbtCloudAdministrativeClient : \"\"\" Client for interacting with the dbt cloud Administrative API. Args: api_key: API key to authenticate with the dbt Cloud administrative API. account_id: ID of dbt Cloud account with which to interact. domain: Domain at which the dbt Cloud API is hosted. \"\"\" def __init__ ( self , api_key : str , account_id : int , domain : str = \"cloud.getdbt.com\" ): self . _closed = False self . _started = False self . _admin_client = AsyncClient ( headers = { \"Authorization\" : f \"Bearer { api_key } \" , \"user-agent\" : f \"prefect- { prefect . __version__ } \" , }, base_url = f \"https:// { domain } /api/v2/accounts/ { account_id } \" , ) async def call_endpoint ( self , http_method : str , path : str , params : Optional [ Dict [ str , Any ]] = None , json : Optional [ Dict [ str , Any ]] = None , ) -> Response : \"\"\" Call an endpoint in the dbt Cloud API. Args: path: The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. http_method: HTTP method to call on the endpoint. params: Query parameters to include in the request. json: JSON serializable body to send in the request. Returns: The response from the dbt Cloud administrative API. \"\"\" response = await self . _admin_client . request ( method = http_method , url = path , params = params , json = json ) response . raise_for_status () return response async def get_job ( self , job_id : int , order_by : Optional [ str ] = None , ) -> Response : \"\"\" Return job details for a job on an account. Args: job_id: Numeric ID of the job. order_by: Field to order the result by. Use - to indicate reverse order. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"order_by\" : order_by } if order_by else None return await self . call_endpoint ( path = f \"/jobs/ { job_id } /\" , http_method = \"GET\" , params = params ) async def trigger_job_run ( self , job_id : int , options : Optional [ TriggerJobRunOptions ] = None ) -> Response : \"\"\" Sends a request to the [trigger job run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Jobs/operation/triggerRun) to initiate a job run. Args: job_id: The ID of the job to trigger. options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa if options is None : options = TriggerJobRunOptions () return await self . call_endpoint ( path = f \"/jobs/ { job_id } /run/\" , http_method = \"POST\" , json = options . dict ( exclude_none = True ), ) async def get_run ( self , run_id : int , include_related : Optional [ List [ Literal [ \"trigger\" , \"job\" , \"debug_logs\" , \"run_steps\" ]] ] = None , ) -> Response : \"\"\" Sends a request to the [get run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getRunById) to get details about a job run. Args: run_id: The ID of the run to get details for. include_related: List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"include_related\" : include_related } if include_related else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /\" , http_method = \"GET\" , params = params ) async def list_run_artifacts ( self , run_id : int , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [list run artifacts endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/listArtifactsByRunId) to fetch a list of paths of artifacts generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/\" , http_method = \"GET\" , params = params ) async def get_run_artifact ( self , run_id : int , path : str , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [get run artifact endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getArtifactsByRunId) to fetch an artifact generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. path: The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/ { path } \" , http_method = \"GET\" , params = params ) async def __aenter__ ( self ): if self . _closed : raise RuntimeError ( \"The client cannot be started again after it has been closed.\" ) if self . _started : raise RuntimeError ( \"The client cannot be started more than once.\" ) self . _started = True return self async def __aexit__ ( self , * exc ): self . _closed = True await self . _admin_client . __aexit__ () Functions call_endpoint async Call an endpoint in the dbt Cloud API. Parameters: Name Type Description Default path str The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. required http_method str HTTP method to call on the endpoint. required params Optional [ Dict [ str , Any ]] Query parameters to include in the request. None json Optional [ Dict [ str , Any ]] JSON serializable body to send in the request. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 async def call_endpoint ( self , http_method : str , path : str , params : Optional [ Dict [ str , Any ]] = None , json : Optional [ Dict [ str , Any ]] = None , ) -> Response : \"\"\" Call an endpoint in the dbt Cloud API. Args: path: The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. http_method: HTTP method to call on the endpoint. params: Query parameters to include in the request. json: JSON serializable body to send in the request. Returns: The response from the dbt Cloud administrative API. \"\"\" response = await self . _admin_client . request ( method = http_method , url = path , params = params , json = json ) response . raise_for_status () return response get_job async Return job details for a job on an account. Parameters: Name Type Description Default job_id int Numeric ID of the job. required order_by Optional [ str ] Field to order the result by. Use - to indicate reverse order. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 async def get_job ( self , job_id : int , order_by : Optional [ str ] = None , ) -> Response : \"\"\" Return job details for a job on an account. Args: job_id: Numeric ID of the job. order_by: Field to order the result by. Use - to indicate reverse order. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"order_by\" : order_by } if order_by else None return await self . call_endpoint ( path = f \"/jobs/ { job_id } /\" , http_method = \"GET\" , params = params ) get_run async Sends a request to the get run endpoint to get details about a job run. Parameters: Name Type Description Default run_id int The ID of the run to get details for. required include_related Optional [ List [ Literal [ trigger , job , debug_logs , run_steps ]]] List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 async def get_run ( self , run_id : int , include_related : Optional [ List [ Literal [ \"trigger\" , \"job\" , \"debug_logs\" , \"run_steps\" ]] ] = None , ) -> Response : \"\"\" Sends a request to the [get run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getRunById) to get details about a job run. Args: run_id: The ID of the run to get details for. include_related: List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"include_related\" : include_related } if include_related else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /\" , http_method = \"GET\" , params = params ) get_run_artifact async Sends a request to the get run artifact endpoint to fetch an artifact generated for a completed run. Parameters: Name Type Description Default run_id int The ID of the run to list run artifacts for. required path str The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 async def get_run_artifact ( self , run_id : int , path : str , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [get run artifact endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getArtifactsByRunId) to fetch an artifact generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. path: The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/ { path } \" , http_method = \"GET\" , params = params ) list_run_artifacts async Sends a request to the list run artifacts endpoint to fetch a list of paths of artifacts generated for a completed run. Parameters: Name Type Description Default run_id int The ID of the run to list run artifacts for. required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 async def list_run_artifacts ( self , run_id : int , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [list run artifacts endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/listArtifactsByRunId) to fetch a list of paths of artifacts generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/\" , http_method = \"GET\" , params = params ) trigger_job_run async Sends a request to the trigger job run endpoint to initiate a job run. Parameters: Name Type Description Default job_id int The ID of the job to trigger. required options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 async def trigger_job_run ( self , job_id : int , options : Optional [ TriggerJobRunOptions ] = None ) -> Response : \"\"\" Sends a request to the [trigger job run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Jobs/operation/triggerRun) to initiate a job run. Args: job_id: The ID of the job to trigger. options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa if options is None : options = TriggerJobRunOptions () return await self . call_endpoint ( path = f \"/jobs/ { job_id } /run/\" , http_method = \"POST\" , json = options . dict ( exclude_none = True ), ) DbtCloudMetadataClient Client for interacting with the dbt cloud Administrative API. Parameters: Name Type Description Default api_key str API key to authenticate with the dbt Cloud administrative API. required account_id ID of dbt Cloud account with which to interact. required domain str Domain at which the dbt Cloud API is hosted. 'metadata.cloud.getdbt.com' Source code in prefect_dbt/cloud/clients.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 class DbtCloudMetadataClient : \"\"\" Client for interacting with the dbt cloud Administrative API. Args: api_key: API key to authenticate with the dbt Cloud administrative API. account_id: ID of dbt Cloud account with which to interact. domain: Domain at which the dbt Cloud API is hosted. \"\"\" def __init__ ( self , api_key : str , domain : str = \"metadata.cloud.getdbt.com\" ): self . _http_endpoint = HTTPEndpoint ( base_headers = { \"Authorization\" : f \"Bearer { api_key } \" , \"user-agent\" : f \"prefect- { prefect . __version__ } \" , \"content-type\" : \"application/json\" , }, url = f \"https:// { domain } /graphql\" , ) def query ( self , query : str , variables : Optional [ Dict ] = None , operation_name : Optional [ str ] = None , ) -> Dict [ str , Any ]: \"\"\" Run a GraphQL query against the dbt Cloud metadata API. Args: query: The GraphQL query to run. variables: The values of any variables defined in the GraphQL query. operation_name: The name of the operation to run if multiple operations are defined in the provided query. Returns: The result of the GraphQL query. \"\"\" return self . _http_endpoint ( query = query , variables = variables , operation_name = operation_name ) Functions query Run a GraphQL query against the dbt Cloud metadata API. Parameters: Name Type Description Default query str The GraphQL query to run. required variables Optional [ Dict ] The values of any variables defined in the GraphQL query. None operation_name Optional [ str ] The name of the operation to run if multiple operations are defined in the provided query. None Returns: Type Description Dict [ str , Any ] The result of the GraphQL query. Source code in prefect_dbt/cloud/clients.py 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 def query ( self , query : str , variables : Optional [ Dict ] = None , operation_name : Optional [ str ] = None , ) -> Dict [ str , Any ]: \"\"\" Run a GraphQL query against the dbt Cloud metadata API. Args: query: The GraphQL query to run. variables: The values of any variables defined in the GraphQL query. operation_name: The name of the operation to run if multiple operations are defined in the provided query. Returns: The result of the GraphQL query. \"\"\" return self . _http_endpoint ( query = query , variables = variables , operation_name = operation_name )","title":"Clients"},{"location":"cloud/clients/#prefect_dbt.cloud.clients","text":"Module containing clients for interacting with the dbt Cloud API","title":"clients"},{"location":"cloud/clients/#prefect_dbt.cloud.clients-classes","text":"","title":"Classes"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient","text":"Client for interacting with the dbt cloud Administrative API. Parameters: Name Type Description Default api_key str API key to authenticate with the dbt Cloud administrative API. required account_id int ID of dbt Cloud account with which to interact. required domain str Domain at which the dbt Cloud API is hosted. 'cloud.getdbt.com' Source code in prefect_dbt/cloud/clients.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 class DbtCloudAdministrativeClient : \"\"\" Client for interacting with the dbt cloud Administrative API. Args: api_key: API key to authenticate with the dbt Cloud administrative API. account_id: ID of dbt Cloud account with which to interact. domain: Domain at which the dbt Cloud API is hosted. \"\"\" def __init__ ( self , api_key : str , account_id : int , domain : str = \"cloud.getdbt.com\" ): self . _closed = False self . _started = False self . _admin_client = AsyncClient ( headers = { \"Authorization\" : f \"Bearer { api_key } \" , \"user-agent\" : f \"prefect- { prefect . __version__ } \" , }, base_url = f \"https:// { domain } /api/v2/accounts/ { account_id } \" , ) async def call_endpoint ( self , http_method : str , path : str , params : Optional [ Dict [ str , Any ]] = None , json : Optional [ Dict [ str , Any ]] = None , ) -> Response : \"\"\" Call an endpoint in the dbt Cloud API. Args: path: The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. http_method: HTTP method to call on the endpoint. params: Query parameters to include in the request. json: JSON serializable body to send in the request. Returns: The response from the dbt Cloud administrative API. \"\"\" response = await self . _admin_client . request ( method = http_method , url = path , params = params , json = json ) response . raise_for_status () return response async def get_job ( self , job_id : int , order_by : Optional [ str ] = None , ) -> Response : \"\"\" Return job details for a job on an account. Args: job_id: Numeric ID of the job. order_by: Field to order the result by. Use - to indicate reverse order. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"order_by\" : order_by } if order_by else None return await self . call_endpoint ( path = f \"/jobs/ { job_id } /\" , http_method = \"GET\" , params = params ) async def trigger_job_run ( self , job_id : int , options : Optional [ TriggerJobRunOptions ] = None ) -> Response : \"\"\" Sends a request to the [trigger job run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Jobs/operation/triggerRun) to initiate a job run. Args: job_id: The ID of the job to trigger. options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa if options is None : options = TriggerJobRunOptions () return await self . call_endpoint ( path = f \"/jobs/ { job_id } /run/\" , http_method = \"POST\" , json = options . dict ( exclude_none = True ), ) async def get_run ( self , run_id : int , include_related : Optional [ List [ Literal [ \"trigger\" , \"job\" , \"debug_logs\" , \"run_steps\" ]] ] = None , ) -> Response : \"\"\" Sends a request to the [get run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getRunById) to get details about a job run. Args: run_id: The ID of the run to get details for. include_related: List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"include_related\" : include_related } if include_related else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /\" , http_method = \"GET\" , params = params ) async def list_run_artifacts ( self , run_id : int , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [list run artifacts endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/listArtifactsByRunId) to fetch a list of paths of artifacts generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/\" , http_method = \"GET\" , params = params ) async def get_run_artifact ( self , run_id : int , path : str , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [get run artifact endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getArtifactsByRunId) to fetch an artifact generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. path: The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/ { path } \" , http_method = \"GET\" , params = params ) async def __aenter__ ( self ): if self . _closed : raise RuntimeError ( \"The client cannot be started again after it has been closed.\" ) if self . _started : raise RuntimeError ( \"The client cannot be started more than once.\" ) self . _started = True return self async def __aexit__ ( self , * exc ): self . _closed = True await self . _admin_client . __aexit__ ()","title":"DbtCloudAdministrativeClient"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient-functions","text":"","title":"Functions"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.call_endpoint","text":"Call an endpoint in the dbt Cloud API. Parameters: Name Type Description Default path str The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. required http_method str HTTP method to call on the endpoint. required params Optional [ Dict [ str , Any ]] Query parameters to include in the request. None json Optional [ Dict [ str , Any ]] JSON serializable body to send in the request. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 async def call_endpoint ( self , http_method : str , path : str , params : Optional [ Dict [ str , Any ]] = None , json : Optional [ Dict [ str , Any ]] = None , ) -> Response : \"\"\" Call an endpoint in the dbt Cloud API. Args: path: The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. http_method: HTTP method to call on the endpoint. params: Query parameters to include in the request. json: JSON serializable body to send in the request. Returns: The response from the dbt Cloud administrative API. \"\"\" response = await self . _admin_client . request ( method = http_method , url = path , params = params , json = json ) response . raise_for_status () return response","title":"call_endpoint()"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.get_job","text":"Return job details for a job on an account. Parameters: Name Type Description Default job_id int Numeric ID of the job. required order_by Optional [ str ] Field to order the result by. Use - to indicate reverse order. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 async def get_job ( self , job_id : int , order_by : Optional [ str ] = None , ) -> Response : \"\"\" Return job details for a job on an account. Args: job_id: Numeric ID of the job. order_by: Field to order the result by. Use - to indicate reverse order. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"order_by\" : order_by } if order_by else None return await self . call_endpoint ( path = f \"/jobs/ { job_id } /\" , http_method = \"GET\" , params = params )","title":"get_job()"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.get_run","text":"Sends a request to the get run endpoint to get details about a job run. Parameters: Name Type Description Default run_id int The ID of the run to get details for. required include_related Optional [ List [ Literal [ trigger , job , debug_logs , run_steps ]]] List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 async def get_run ( self , run_id : int , include_related : Optional [ List [ Literal [ \"trigger\" , \"job\" , \"debug_logs\" , \"run_steps\" ]] ] = None , ) -> Response : \"\"\" Sends a request to the [get run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getRunById) to get details about a job run. Args: run_id: The ID of the run to get details for. include_related: List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"include_related\" : include_related } if include_related else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /\" , http_method = \"GET\" , params = params )","title":"get_run()"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.get_run_artifact","text":"Sends a request to the get run artifact endpoint to fetch an artifact generated for a completed run. Parameters: Name Type Description Default run_id int The ID of the run to list run artifacts for. required path str The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 async def get_run_artifact ( self , run_id : int , path : str , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [get run artifact endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getArtifactsByRunId) to fetch an artifact generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. path: The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/ { path } \" , http_method = \"GET\" , params = params )","title":"get_run_artifact()"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.list_run_artifacts","text":"Sends a request to the list run artifacts endpoint to fetch a list of paths of artifacts generated for a completed run. Parameters: Name Type Description Default run_id int The ID of the run to list run artifacts for. required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 async def list_run_artifacts ( self , run_id : int , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [list run artifacts endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/listArtifactsByRunId) to fetch a list of paths of artifacts generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/\" , http_method = \"GET\" , params = params )","title":"list_run_artifacts()"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.trigger_job_run","text":"Sends a request to the trigger job run endpoint to initiate a job run. Parameters: Name Type Description Default job_id int The ID of the job to trigger. required options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 async def trigger_job_run ( self , job_id : int , options : Optional [ TriggerJobRunOptions ] = None ) -> Response : \"\"\" Sends a request to the [trigger job run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Jobs/operation/triggerRun) to initiate a job run. Args: job_id: The ID of the job to trigger. options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa if options is None : options = TriggerJobRunOptions () return await self . call_endpoint ( path = f \"/jobs/ { job_id } /run/\" , http_method = \"POST\" , json = options . dict ( exclude_none = True ), )","title":"trigger_job_run()"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudMetadataClient","text":"Client for interacting with the dbt cloud Administrative API. Parameters: Name Type Description Default api_key str API key to authenticate with the dbt Cloud administrative API. required account_id ID of dbt Cloud account with which to interact. required domain str Domain at which the dbt Cloud API is hosted. 'metadata.cloud.getdbt.com' Source code in prefect_dbt/cloud/clients.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 class DbtCloudMetadataClient : \"\"\" Client for interacting with the dbt cloud Administrative API. Args: api_key: API key to authenticate with the dbt Cloud administrative API. account_id: ID of dbt Cloud account with which to interact. domain: Domain at which the dbt Cloud API is hosted. \"\"\" def __init__ ( self , api_key : str , domain : str = \"metadata.cloud.getdbt.com\" ): self . _http_endpoint = HTTPEndpoint ( base_headers = { \"Authorization\" : f \"Bearer { api_key } \" , \"user-agent\" : f \"prefect- { prefect . __version__ } \" , \"content-type\" : \"application/json\" , }, url = f \"https:// { domain } /graphql\" , ) def query ( self , query : str , variables : Optional [ Dict ] = None , operation_name : Optional [ str ] = None , ) -> Dict [ str , Any ]: \"\"\" Run a GraphQL query against the dbt Cloud metadata API. Args: query: The GraphQL query to run. variables: The values of any variables defined in the GraphQL query. operation_name: The name of the operation to run if multiple operations are defined in the provided query. Returns: The result of the GraphQL query. \"\"\" return self . _http_endpoint ( query = query , variables = variables , operation_name = operation_name )","title":"DbtCloudMetadataClient"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudMetadataClient-functions","text":"","title":"Functions"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudMetadataClient.query","text":"Run a GraphQL query against the dbt Cloud metadata API. Parameters: Name Type Description Default query str The GraphQL query to run. required variables Optional [ Dict ] The values of any variables defined in the GraphQL query. None operation_name Optional [ str ] The name of the operation to run if multiple operations are defined in the provided query. None Returns: Type Description Dict [ str , Any ] The result of the GraphQL query. Source code in prefect_dbt/cloud/clients.py 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 def query ( self , query : str , variables : Optional [ Dict ] = None , operation_name : Optional [ str ] = None , ) -> Dict [ str , Any ]: \"\"\" Run a GraphQL query against the dbt Cloud metadata API. Args: query: The GraphQL query to run. variables: The values of any variables defined in the GraphQL query. operation_name: The name of the operation to run if multiple operations are defined in the provided query. Returns: The result of the GraphQL query. \"\"\" return self . _http_endpoint ( query = query , variables = variables , operation_name = operation_name )","title":"query()"},{"location":"cloud/credentials/","text":"prefect_dbt.cloud.credentials Module containing credentials for interacting with dbt Cloud Classes DbtCloudCredentials Bases: CredentialsBlock Credentials block for credential use across dbt Cloud tasks and flows. Attributes: Name Type Description api_key SecretStr API key to authenticate with the dbt Cloud administrative API. Refer to the Authentication docs for retrieving the API key. account_id int ID of dbt Cloud account with which to interact. domain Optional [ str ] Domain at which the dbt Cloud API is hosted. Examples: Load stored dbt Cloud credentials: from prefect_dbt.cloud import DbtCloudCredentials dbt_cloud_credentials = DbtCloudCredentials . load ( \"BLOCK_NAME\" ) Use DbtCloudCredentials instance to trigger a job run: from prefect_dbt.cloud import DbtCloudCredentials credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) async with dbt_cloud_credentials . get_administrative_client () as client : client . trigger_job_run ( job_id = 1 ) Load saved dbt Cloud credentials within a flow: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow (): credentials = DbtCloudCredentials . load ( \"my-dbt-credentials\" ) trigger_dbt_cloud_job_run ( dbt_cloud_credentials = credentials , job_id = 1 ) trigger_dbt_cloud_job_run_flow () Source code in prefect_dbt/cloud/credentials.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class DbtCloudCredentials ( CredentialsBlock ): \"\"\" Credentials block for credential use across dbt Cloud tasks and flows. Attributes: api_key (SecretStr): API key to authenticate with the dbt Cloud administrative API. Refer to the [Authentication docs]( https://docs.getdbt.com/dbt-cloud/api-v2#section/Authentication) for retrieving the API key. account_id (int): ID of dbt Cloud account with which to interact. domain (Optional[str]): Domain at which the dbt Cloud API is hosted. Examples: Load stored dbt Cloud credentials: ```python from prefect_dbt.cloud import DbtCloudCredentials dbt_cloud_credentials = DbtCloudCredentials.load(\"BLOCK_NAME\") ``` Use DbtCloudCredentials instance to trigger a job run: ```python from prefect_dbt.cloud import DbtCloudCredentials credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) async with dbt_cloud_credentials.get_administrative_client() as client: client.trigger_job_run(job_id=1) ``` Load saved dbt Cloud credentials within a flow: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow(): credentials = DbtCloudCredentials.load(\"my-dbt-credentials\") trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1) trigger_dbt_cloud_job_run_flow() ``` \"\"\" _block_type_name = \"dbt Cloud Credentials\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa api_key : SecretStr = Field ( default =... , title = \"API Key\" , description = \"A dbt Cloud API key to use for authentication.\" , ) account_id : int = Field ( default =... , title = \"Account ID\" , description = \"The ID of your dbt Cloud account.\" ) domain : str = Field ( default = \"cloud.getdbt.com\" , description = \"The base domain of your dbt Cloud instance.\" , ) def get_administrative_client ( self ) -> DbtCloudAdministrativeClient : \"\"\" Returns a newly instantiated client for working with the dbt Cloud administrative API. Returns: An authenticated dbt Cloud administrative API client. \"\"\" return DbtCloudAdministrativeClient ( api_key = self . api_key . get_secret_value (), account_id = self . account_id , domain = self . domain , ) def get_metadata_client ( self ) -> DbtCloudMetadataClient : \"\"\" Returns a newly instantiated client for working with the dbt Cloud metadata API. Example: Sending queries via the returned metadata client: ```python from prefect_dbt import DbtCloudCredentials credentials_block = DbtCloudCredentials.load(\"test-account\") metadata_client = credentials_block.get_metadata_client() query = \\\"\\\"\\\" { metrics(jobId: 123) { uniqueId name packageName tags label runId description type sql timestamp timeGrains dimensions meta resourceType filters { field operator value } model { name } } } \\\"\\\"\\\" metadata_client.query(query) # Result: # { # \"data\": { # \"metrics\": [ # { # \"uniqueId\": \"metric.tpch.total_revenue\", # \"name\": \"total_revenue\", # \"packageName\": \"tpch\", # \"tags\": [], # \"label\": \"Total Revenue ($)\", # \"runId\": 108952046, # \"description\": \"\", # \"type\": \"sum\", # \"sql\": \"net_item_sales_amount\", # \"timestamp\": \"order_date\", # \"timeGrains\": [\"day\", \"week\", \"month\"], # \"dimensions\": [\"status_code\", \"priority_code\"], # \"meta\": {}, # \"resourceType\": \"metric\", # \"filters\": [], # \"model\": { \"name\": \"fct_orders\" } # } # ] # } # } ``` Returns: An authenticated dbt Cloud metadata API client. \"\"\" return DbtCloudMetadataClient ( api_key = self . api_key . get_secret_value (), domain = f \"metadata. { self . domain } \" , ) def get_client ( self , client_type : Literal [ \"administrative\" , \"metadata\" ] ) -> Union [ DbtCloudAdministrativeClient , DbtCloudMetadataClient ]: \"\"\" Returns a newly instantiated client for working with the dbt Cloud API. Args: client_type: Type of client to return. Accepts either 'administrative' or 'metadata'. Returns: The authenticated client of the requested type. \"\"\" get_client_method = getattr ( self , f \"get_ { client_type } _client\" , None ) if get_client_method is None : raise ValueError ( f \"' { client_type } ' is not a supported client type.\" ) return get_client_method () Functions get_administrative_client Returns a newly instantiated client for working with the dbt Cloud administrative API. Returns: Type Description DbtCloudAdministrativeClient An authenticated dbt Cloud administrative API client. Source code in prefect_dbt/cloud/credentials.py 77 78 79 80 81 82 83 84 85 86 87 88 89 def get_administrative_client ( self ) -> DbtCloudAdministrativeClient : \"\"\" Returns a newly instantiated client for working with the dbt Cloud administrative API. Returns: An authenticated dbt Cloud administrative API client. \"\"\" return DbtCloudAdministrativeClient ( api_key = self . api_key . get_secret_value (), account_id = self . account_id , domain = self . domain , ) get_client Returns a newly instantiated client for working with the dbt Cloud API. Parameters: Name Type Description Default client_type Literal [ administrative , metadata ] Type of client to return. Accepts either 'administrative' or 'metadata'. required Returns: Type Description Union [ DbtCloudAdministrativeClient , DbtCloudMetadataClient ] The authenticated client of the requested type. Source code in prefect_dbt/cloud/credentials.py 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 def get_client ( self , client_type : Literal [ \"administrative\" , \"metadata\" ] ) -> Union [ DbtCloudAdministrativeClient , DbtCloudMetadataClient ]: \"\"\" Returns a newly instantiated client for working with the dbt Cloud API. Args: client_type: Type of client to return. Accepts either 'administrative' or 'metadata'. Returns: The authenticated client of the requested type. \"\"\" get_client_method = getattr ( self , f \"get_ { client_type } _client\" , None ) if get_client_method is None : raise ValueError ( f \"' { client_type } ' is not a supported client type.\" ) return get_client_method () get_metadata_client Returns a newly instantiated client for working with the dbt Cloud metadata API. Example Sending queries via the returned metadata client: from prefect_dbt import DbtCloudCredentials credentials_block = DbtCloudCredentials . load ( \"test-account\" ) metadata_client = credentials_block . get_metadata_client () query = \"\"\" { metrics(jobId: 123) { uniqueId name packageName tags label runId description type sql timestamp timeGrains dimensions meta resourceType filters { field operator value } model { name } } } \"\"\" metadata_client . query ( query ) # Result: # { # \"data\": { # \"metrics\": [ # { # \"uniqueId\": \"metric.tpch.total_revenue\", # \"name\": \"total_revenue\", # \"packageName\": \"tpch\", # \"tags\": [], # \"label\": \"Total Revenue ($)\", # \"runId\": 108952046, # \"description\": \"\", # \"type\": \"sum\", # \"sql\": \"net_item_sales_amount\", # \"timestamp\": \"order_date\", # \"timeGrains\": [\"day\", \"week\", \"month\"], # \"dimensions\": [\"status_code\", \"priority_code\"], # \"meta\": {}, # \"resourceType\": \"metric\", # \"filters\": [], # \"model\": { \"name\": \"fct_orders\" } # } # ] # } # } Returns: Type Description DbtCloudMetadataClient An authenticated dbt Cloud metadata API client. Source code in prefect_dbt/cloud/credentials.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 def get_metadata_client ( self ) -> DbtCloudMetadataClient : \"\"\" Returns a newly instantiated client for working with the dbt Cloud metadata API. Example: Sending queries via the returned metadata client: ```python from prefect_dbt import DbtCloudCredentials credentials_block = DbtCloudCredentials.load(\"test-account\") metadata_client = credentials_block.get_metadata_client() query = \\\"\\\"\\\" { metrics(jobId: 123) { uniqueId name packageName tags label runId description type sql timestamp timeGrains dimensions meta resourceType filters { field operator value } model { name } } } \\\"\\\"\\\" metadata_client.query(query) # Result: # { # \"data\": { # \"metrics\": [ # { # \"uniqueId\": \"metric.tpch.total_revenue\", # \"name\": \"total_revenue\", # \"packageName\": \"tpch\", # \"tags\": [], # \"label\": \"Total Revenue ($)\", # \"runId\": 108952046, # \"description\": \"\", # \"type\": \"sum\", # \"sql\": \"net_item_sales_amount\", # \"timestamp\": \"order_date\", # \"timeGrains\": [\"day\", \"week\", \"month\"], # \"dimensions\": [\"status_code\", \"priority_code\"], # \"meta\": {}, # \"resourceType\": \"metric\", # \"filters\": [], # \"model\": { \"name\": \"fct_orders\" } # } # ] # } # } ``` Returns: An authenticated dbt Cloud metadata API client. \"\"\" return DbtCloudMetadataClient ( api_key = self . api_key . get_secret_value (), domain = f \"metadata. { self . domain } \" , )","title":"Credentials"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials","text":"Module containing credentials for interacting with dbt Cloud","title":"credentials"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials-classes","text":"","title":"Classes"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials","text":"Bases: CredentialsBlock Credentials block for credential use across dbt Cloud tasks and flows. Attributes: Name Type Description api_key SecretStr API key to authenticate with the dbt Cloud administrative API. Refer to the Authentication docs for retrieving the API key. account_id int ID of dbt Cloud account with which to interact. domain Optional [ str ] Domain at which the dbt Cloud API is hosted. Examples: Load stored dbt Cloud credentials: from prefect_dbt.cloud import DbtCloudCredentials dbt_cloud_credentials = DbtCloudCredentials . load ( \"BLOCK_NAME\" ) Use DbtCloudCredentials instance to trigger a job run: from prefect_dbt.cloud import DbtCloudCredentials credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) async with dbt_cloud_credentials . get_administrative_client () as client : client . trigger_job_run ( job_id = 1 ) Load saved dbt Cloud credentials within a flow: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow (): credentials = DbtCloudCredentials . load ( \"my-dbt-credentials\" ) trigger_dbt_cloud_job_run ( dbt_cloud_credentials = credentials , job_id = 1 ) trigger_dbt_cloud_job_run_flow () Source code in prefect_dbt/cloud/credentials.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class DbtCloudCredentials ( CredentialsBlock ): \"\"\" Credentials block for credential use across dbt Cloud tasks and flows. Attributes: api_key (SecretStr): API key to authenticate with the dbt Cloud administrative API. Refer to the [Authentication docs]( https://docs.getdbt.com/dbt-cloud/api-v2#section/Authentication) for retrieving the API key. account_id (int): ID of dbt Cloud account with which to interact. domain (Optional[str]): Domain at which the dbt Cloud API is hosted. Examples: Load stored dbt Cloud credentials: ```python from prefect_dbt.cloud import DbtCloudCredentials dbt_cloud_credentials = DbtCloudCredentials.load(\"BLOCK_NAME\") ``` Use DbtCloudCredentials instance to trigger a job run: ```python from prefect_dbt.cloud import DbtCloudCredentials credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) async with dbt_cloud_credentials.get_administrative_client() as client: client.trigger_job_run(job_id=1) ``` Load saved dbt Cloud credentials within a flow: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow(): credentials = DbtCloudCredentials.load(\"my-dbt-credentials\") trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1) trigger_dbt_cloud_job_run_flow() ``` \"\"\" _block_type_name = \"dbt Cloud Credentials\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa api_key : SecretStr = Field ( default =... , title = \"API Key\" , description = \"A dbt Cloud API key to use for authentication.\" , ) account_id : int = Field ( default =... , title = \"Account ID\" , description = \"The ID of your dbt Cloud account.\" ) domain : str = Field ( default = \"cloud.getdbt.com\" , description = \"The base domain of your dbt Cloud instance.\" , ) def get_administrative_client ( self ) -> DbtCloudAdministrativeClient : \"\"\" Returns a newly instantiated client for working with the dbt Cloud administrative API. Returns: An authenticated dbt Cloud administrative API client. \"\"\" return DbtCloudAdministrativeClient ( api_key = self . api_key . get_secret_value (), account_id = self . account_id , domain = self . domain , ) def get_metadata_client ( self ) -> DbtCloudMetadataClient : \"\"\" Returns a newly instantiated client for working with the dbt Cloud metadata API. Example: Sending queries via the returned metadata client: ```python from prefect_dbt import DbtCloudCredentials credentials_block = DbtCloudCredentials.load(\"test-account\") metadata_client = credentials_block.get_metadata_client() query = \\\"\\\"\\\" { metrics(jobId: 123) { uniqueId name packageName tags label runId description type sql timestamp timeGrains dimensions meta resourceType filters { field operator value } model { name } } } \\\"\\\"\\\" metadata_client.query(query) # Result: # { # \"data\": { # \"metrics\": [ # { # \"uniqueId\": \"metric.tpch.total_revenue\", # \"name\": \"total_revenue\", # \"packageName\": \"tpch\", # \"tags\": [], # \"label\": \"Total Revenue ($)\", # \"runId\": 108952046, # \"description\": \"\", # \"type\": \"sum\", # \"sql\": \"net_item_sales_amount\", # \"timestamp\": \"order_date\", # \"timeGrains\": [\"day\", \"week\", \"month\"], # \"dimensions\": [\"status_code\", \"priority_code\"], # \"meta\": {}, # \"resourceType\": \"metric\", # \"filters\": [], # \"model\": { \"name\": \"fct_orders\" } # } # ] # } # } ``` Returns: An authenticated dbt Cloud metadata API client. \"\"\" return DbtCloudMetadataClient ( api_key = self . api_key . get_secret_value (), domain = f \"metadata. { self . domain } \" , ) def get_client ( self , client_type : Literal [ \"administrative\" , \"metadata\" ] ) -> Union [ DbtCloudAdministrativeClient , DbtCloudMetadataClient ]: \"\"\" Returns a newly instantiated client for working with the dbt Cloud API. Args: client_type: Type of client to return. Accepts either 'administrative' or 'metadata'. Returns: The authenticated client of the requested type. \"\"\" get_client_method = getattr ( self , f \"get_ { client_type } _client\" , None ) if get_client_method is None : raise ValueError ( f \"' { client_type } ' is not a supported client type.\" ) return get_client_method ()","title":"DbtCloudCredentials"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials-functions","text":"","title":"Functions"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials.get_administrative_client","text":"Returns a newly instantiated client for working with the dbt Cloud administrative API. Returns: Type Description DbtCloudAdministrativeClient An authenticated dbt Cloud administrative API client. Source code in prefect_dbt/cloud/credentials.py 77 78 79 80 81 82 83 84 85 86 87 88 89 def get_administrative_client ( self ) -> DbtCloudAdministrativeClient : \"\"\" Returns a newly instantiated client for working with the dbt Cloud administrative API. Returns: An authenticated dbt Cloud administrative API client. \"\"\" return DbtCloudAdministrativeClient ( api_key = self . api_key . get_secret_value (), account_id = self . account_id , domain = self . domain , )","title":"get_administrative_client()"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials.get_client","text":"Returns a newly instantiated client for working with the dbt Cloud API. Parameters: Name Type Description Default client_type Literal [ administrative , metadata ] Type of client to return. Accepts either 'administrative' or 'metadata'. required Returns: Type Description Union [ DbtCloudAdministrativeClient , DbtCloudMetadataClient ] The authenticated client of the requested type. Source code in prefect_dbt/cloud/credentials.py 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 def get_client ( self , client_type : Literal [ \"administrative\" , \"metadata\" ] ) -> Union [ DbtCloudAdministrativeClient , DbtCloudMetadataClient ]: \"\"\" Returns a newly instantiated client for working with the dbt Cloud API. Args: client_type: Type of client to return. Accepts either 'administrative' or 'metadata'. Returns: The authenticated client of the requested type. \"\"\" get_client_method = getattr ( self , f \"get_ { client_type } _client\" , None ) if get_client_method is None : raise ValueError ( f \"' { client_type } ' is not a supported client type.\" ) return get_client_method ()","title":"get_client()"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials.get_metadata_client","text":"Returns a newly instantiated client for working with the dbt Cloud metadata API. Example Sending queries via the returned metadata client: from prefect_dbt import DbtCloudCredentials credentials_block = DbtCloudCredentials . load ( \"test-account\" ) metadata_client = credentials_block . get_metadata_client () query = \"\"\" { metrics(jobId: 123) { uniqueId name packageName tags label runId description type sql timestamp timeGrains dimensions meta resourceType filters { field operator value } model { name } } } \"\"\" metadata_client . query ( query ) # Result: # { # \"data\": { # \"metrics\": [ # { # \"uniqueId\": \"metric.tpch.total_revenue\", # \"name\": \"total_revenue\", # \"packageName\": \"tpch\", # \"tags\": [], # \"label\": \"Total Revenue ($)\", # \"runId\": 108952046, # \"description\": \"\", # \"type\": \"sum\", # \"sql\": \"net_item_sales_amount\", # \"timestamp\": \"order_date\", # \"timeGrains\": [\"day\", \"week\", \"month\"], # \"dimensions\": [\"status_code\", \"priority_code\"], # \"meta\": {}, # \"resourceType\": \"metric\", # \"filters\": [], # \"model\": { \"name\": \"fct_orders\" } # } # ] # } # } Returns: Type Description DbtCloudMetadataClient An authenticated dbt Cloud metadata API client. Source code in prefect_dbt/cloud/credentials.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 def get_metadata_client ( self ) -> DbtCloudMetadataClient : \"\"\" Returns a newly instantiated client for working with the dbt Cloud metadata API. Example: Sending queries via the returned metadata client: ```python from prefect_dbt import DbtCloudCredentials credentials_block = DbtCloudCredentials.load(\"test-account\") metadata_client = credentials_block.get_metadata_client() query = \\\"\\\"\\\" { metrics(jobId: 123) { uniqueId name packageName tags label runId description type sql timestamp timeGrains dimensions meta resourceType filters { field operator value } model { name } } } \\\"\\\"\\\" metadata_client.query(query) # Result: # { # \"data\": { # \"metrics\": [ # { # \"uniqueId\": \"metric.tpch.total_revenue\", # \"name\": \"total_revenue\", # \"packageName\": \"tpch\", # \"tags\": [], # \"label\": \"Total Revenue ($)\", # \"runId\": 108952046, # \"description\": \"\", # \"type\": \"sum\", # \"sql\": \"net_item_sales_amount\", # \"timestamp\": \"order_date\", # \"timeGrains\": [\"day\", \"week\", \"month\"], # \"dimensions\": [\"status_code\", \"priority_code\"], # \"meta\": {}, # \"resourceType\": \"metric\", # \"filters\": [], # \"model\": { \"name\": \"fct_orders\" } # } # ] # } # } ``` Returns: An authenticated dbt Cloud metadata API client. \"\"\" return DbtCloudMetadataClient ( api_key = self . api_key . get_secret_value (), domain = f \"metadata. { self . domain } \" , )","title":"get_metadata_client()"},{"location":"cloud/jobs/","text":"prefect_dbt.cloud.jobs Module containing tasks and flows for interacting with dbt Cloud jobs Classes DbtCloudGetJobFailed Bases: Exception Raised when unable to retrieve dbt Cloud job. Source code in prefect_dbt/cloud/jobs.py 31 32 class DbtCloudGetJobFailed ( Exception ): \"\"\"Raised when unable to retrieve dbt Cloud job.\"\"\" DbtCloudJobRunTriggerFailed Bases: Exception Raised when a dbt Cloud job trigger fails. Source code in prefect_dbt/cloud/jobs.py 27 28 class DbtCloudJobRunTriggerFailed ( Exception ): \"\"\"Raised when a dbt Cloud job trigger fails.\"\"\" Functions get_dbt_cloud_job_info async A task to retrieve information about a dbt Cloud job. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required job_id int The ID of the job to get. required Returns: Type Description Dict The job data returned by the dbt Cloud administrative API. Example Get status of a dbt Cloud job: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_job @flow def get_job_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return get_job ( dbt_cloud_credentials = credentials , job_id = 42 ) get_job_flow () Source code in prefect_dbt/cloud/jobs.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 @task ( name = \"Get dbt Cloud job details\" , description = \"Retrieves details of a dbt Cloud job \" \"for the job with the given job_id.\" , retries = 3 , retry_delay_seconds = 10 , ) async def get_dbt_cloud_job_info ( dbt_cloud_credentials : DbtCloudCredentials , job_id : int , order_by : Optional [ str ] = None , ) -> Dict : \"\"\" A task to retrieve information about a dbt Cloud job. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. job_id: The ID of the job to get. Returns: The job data returned by the dbt Cloud administrative API. Example: Get status of a dbt Cloud job: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_job @flow def get_job_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return get_job( dbt_cloud_credentials=credentials, job_id=42 ) get_job_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . get_job ( job_id = job_id , order_by = order_by , ) except HTTPStatusError as ex : raise DbtCloudGetJobFailed ( extract_user_message ( ex )) from ex return response . json ()[ \"data\" ] get_run_id Task that extracts the run ID from a trigger job run API response, This task is mainly used to maintain dependency tracking between the trigger_dbt_cloud_job_run task and downstream tasks/flows that use the run ID. Parameters: Name Type Description Default obj Dict The JSON body from the trigger job run response. required Example from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run , get_run_id @flow def trigger_run_and_get_id (): dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) triggered_run_data = trigger_dbt_cloud_job_run ( dbt_cloud_credentials = dbt_cloud_credentials , job_id = job_id , options = trigger_job_run_options , ) run_id = get_run_id . submit ( triggered_run_data ) return run_id trigger_run_and_get_id () Source code in prefect_dbt/cloud/jobs.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 @task ( name = \"Get dbt Cloud job run ID\" , description = \"Extracts the run ID from a trigger job run API response\" , ) def get_run_id ( obj : Dict ): \"\"\" Task that extracts the run ID from a trigger job run API response, This task is mainly used to maintain dependency tracking between the `trigger_dbt_cloud_job_run` task and downstream tasks/flows that use the run ID. Args: obj: The JSON body from the trigger job run response. Example: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run, get_run_id @flow def trigger_run_and_get_id(): dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ) triggered_run_data = trigger_dbt_cloud_job_run( dbt_cloud_credentials=dbt_cloud_credentials, job_id=job_id, options=trigger_job_run_options, ) run_id = get_run_id.submit(triggered_run_data) return run_id trigger_run_and_get_id() ``` \"\"\" id = obj . get ( \"id\" ) if id is None : raise RuntimeError ( \"Unable to determine run ID for triggered job.\" ) return id retry_dbt_cloud_job_run_subset_and_wait_for_completion async Flow that retrys a subset of dbt Cloud job run, filtered by select statuses, and waits for the triggered retry to complete. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required trigger_job_run_options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None max_wait_seconds int Maximum number of seconds to wait for job to complete 900 poll_frequency_seconds int Number of seconds to wait in between checks for run completion. 10 run_id int The ID of the job run to retry. required Raises: Type Description ValueError If trigger_job_run_options.steps_override is set by the user. Returns: Type Description Dict The run data returned by the dbt Cloud administrative API. Examples: Retry a subset of models in a dbt Cloud job run and wait for completion: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import retry_dbt_cloud_job_run_subset_and_wait_for_completion @flow def retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow (): credentials = DbtCloudCredentials . load ( \"MY_BLOCK_NAME\" ) retry_dbt_cloud_job_run_subset_and_wait_for_completion ( dbt_cloud_credentials = credentials , run_id = 88640123 , ) retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow () Source code in prefect_dbt/cloud/jobs.py 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 @flow ( name = \"Retry subset of dbt Cloud job run and wait for completion\" , description = ( \"Retries a subset of dbt Cloud job run, filtered by select statuses, \" \"and waits for the triggered retry to complete.\" ), ) async def retry_dbt_cloud_job_run_subset_and_wait_for_completion ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int , trigger_job_run_options : Optional [ TriggerJobRunOptions ] = None , max_wait_seconds : int = 900 , poll_frequency_seconds : int = 10 , ) -> Dict : \"\"\" Flow that retrys a subset of dbt Cloud job run, filtered by select statuses, and waits for the triggered retry to complete. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. trigger_job_run_options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. max_wait_seconds: Maximum number of seconds to wait for job to complete poll_frequency_seconds: Number of seconds to wait in between checks for run completion. run_id: The ID of the job run to retry. Raises: ValueError: If `trigger_job_run_options.steps_override` is set by the user. Returns: The run data returned by the dbt Cloud administrative API. Examples: Retry a subset of models in a dbt Cloud job run and wait for completion: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import retry_dbt_cloud_job_run_subset_and_wait_for_completion @flow def retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow(): credentials = DbtCloudCredentials.load(\"MY_BLOCK_NAME\") retry_dbt_cloud_job_run_subset_and_wait_for_completion( dbt_cloud_credentials=credentials, run_id=88640123, ) retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow() ``` \"\"\" # noqa if trigger_job_run_options and trigger_job_run_options . steps_override is not None : raise ValueError ( \"Do not set `steps_override` in `trigger_job_run_options` \" \"because this flow will automatically set it\" ) run_info_future = await get_dbt_cloud_run_info . submit ( dbt_cloud_credentials = dbt_cloud_credentials , run_id = run_id , include_related = [ \"run_steps\" ], ) run_info = await run_info_future . result () job_id = run_info [ \"job_id\" ] job_info_future = await get_dbt_cloud_job_info . submit ( dbt_cloud_credentials = dbt_cloud_credentials , job_id = job_id , ) job_info = await job_info_future . result () trigger_job_run_options_override = await _build_trigger_job_run_options ( dbt_cloud_credentials = dbt_cloud_credentials , trigger_job_run_options = trigger_job_run_options , run_id = run_id , run_info = run_info , job_info = job_info , ) # to circumvent `RuntimeError: The task runner is already started!` flow_run_context = FlowRunContext . get () task_runner_type = type ( flow_run_context . task_runner ) run_data = await trigger_dbt_cloud_job_run_and_wait_for_completion . with_options ( task_runner = task_runner_type () )( dbt_cloud_credentials = dbt_cloud_credentials , job_id = job_id , retry_filtered_models_attempts = 0 , trigger_job_run_options = trigger_job_run_options_override , max_wait_seconds = max_wait_seconds , poll_frequency_seconds = poll_frequency_seconds , ) return run_data trigger_dbt_cloud_job_run async A task to trigger a dbt Cloud job run. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required job_id int The ID of the job to trigger. required options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None Returns: Type Description Dict The run data returned from the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) trigger_dbt_cloud_job_run ( dbt_cloud_credentials = credentials , job_id = 1 ) trigger_dbt_cloud_job_run_flow () Trigger a dbt Cloud job run with overrides: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run from prefect_dbt.cloud.models import TriggerJobRunOptions @flow def trigger_dbt_cloud_job_run_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) trigger_dbt_cloud_job_run ( dbt_cloud_credentials = credentials , job_id = 1 , options = TriggerJobRunOptions ( git_branch = \"staging\" , schema_override = \"dbt_cloud_pr_123\" , dbt_version_override = \"0.18.0\" , target_name_override = \"staging\" , timeout_seconds_override = 3000 , generate_docs_override = True , threads_override = 8 , steps_override = [ \"dbt seed\" , \"dbt run --fail-fast\" , \"dbt test --fail fast\" , ], ), ) trigger_dbt_cloud_job_run () Source code in prefect_dbt/cloud/jobs.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 @task ( name = \"Trigger dbt Cloud job run\" , description = \"Triggers a dbt Cloud job run for the job \" \"with the given job_id and optional overrides.\" , retries = 3 , retry_delay_seconds = 10 , ) async def trigger_dbt_cloud_job_run ( dbt_cloud_credentials : DbtCloudCredentials , job_id : int , options : Optional [ TriggerJobRunOptions ] = None , ) -> Dict : \"\"\" A task to trigger a dbt Cloud job run. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. job_id: The ID of the job to trigger. options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. Returns: The run data returned from the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1) trigger_dbt_cloud_job_run_flow() ``` Trigger a dbt Cloud job run with overrides: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run from prefect_dbt.cloud.models import TriggerJobRunOptions @flow def trigger_dbt_cloud_job_run_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) trigger_dbt_cloud_job_run( dbt_cloud_credentials=credentials, job_id=1, options=TriggerJobRunOptions( git_branch=\"staging\", schema_override=\"dbt_cloud_pr_123\", dbt_version_override=\"0.18.0\", target_name_override=\"staging\", timeout_seconds_override=3000, generate_docs_override=True, threads_override=8, steps_override=[ \"dbt seed\", \"dbt run --fail-fast\", \"dbt test --fail fast\", ], ), ) trigger_dbt_cloud_job_run() ``` \"\"\" # noqa logger = get_run_logger () logger . info ( f \"Triggering run for job with ID { job_id } \" ) try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . trigger_job_run ( job_id = job_id , options = options ) except HTTPStatusError as ex : raise DbtCloudJobRunTriggerFailed ( extract_user_message ( ex )) from ex run_data = response . json ()[ \"data\" ] if \"project_id\" in run_data and \"id\" in run_data : logger . info ( f \"Run successfully triggered for job with ID { job_id } . \" \"You can view the status of this run at \" f \"https:// { dbt_cloud_credentials . domain } /#/accounts/\" f \" { dbt_cloud_credentials . account_id } /projects/ { run_data [ 'project_id' ] } /\" f \"runs/ { run_data [ 'id' ] } /\" ) return run_data trigger_dbt_cloud_job_run_and_wait_for_completion async Flow that triggers a job run and waits for the triggered run to complete. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required job_id int The ID of the job to trigger. required trigger_job_run_options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None max_wait_seconds int Maximum number of seconds to wait for job to complete 900 poll_frequency_seconds int Number of seconds to wait in between checks for run completion. 10 retry_filtered_models_attempts int Number of times to retry models selected by retry_status_filters . 3 Raises: Type Description DbtCloudJobRunCancelled The triggered dbt Cloud job run was cancelled. DbtCloudJobRunFailed The triggered dbt Cloud job run failed. RuntimeError The triggered dbt Cloud job run ended in an unexpected state. Returns: Type Description Dict The run data returned by the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job and wait for completion as a stand alone flow: import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion asyncio . run ( trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 ) ) Trigger a dbt Cloud job and wait for completion as a sub-flow: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion @flow def my_flow (): ... run_result = trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 ) ... my_flow () Trigger a dbt Cloud job with overrides: import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion from prefect_dbt.cloud.models import TriggerJobRunOptions asyncio . run ( trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 , trigger_job_run_options = TriggerJobRunOptions ( git_branch = \"staging\" , schema_override = \"dbt_cloud_pr_123\" , dbt_version_override = \"0.18.0\" , target_name_override = \"staging\" , timeout_seconds_override = 3000 , generate_docs_override = True , threads_override = 8 , steps_override = [ \"dbt seed\" , \"dbt run --fail-fast\" , \"dbt test --fail fast\" , ], ), ) ) Source code in prefect_dbt/cloud/jobs.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 @flow ( name = \"Trigger dbt Cloud job run and wait for completion\" , description = \"Triggers a dbt Cloud job run and waits for the\" \"triggered run to complete.\" , ) async def trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials : DbtCloudCredentials , job_id : int , trigger_job_run_options : Optional [ TriggerJobRunOptions ] = None , max_wait_seconds : int = 900 , poll_frequency_seconds : int = 10 , retry_filtered_models_attempts : int = 3 , ) -> Dict : \"\"\" Flow that triggers a job run and waits for the triggered run to complete. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. job_id: The ID of the job to trigger. trigger_job_run_options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. max_wait_seconds: Maximum number of seconds to wait for job to complete poll_frequency_seconds: Number of seconds to wait in between checks for run completion. retry_filtered_models_attempts: Number of times to retry models selected by `retry_status_filters`. Raises: DbtCloudJobRunCancelled: The triggered dbt Cloud job run was cancelled. DbtCloudJobRunFailed: The triggered dbt Cloud job run failed. RuntimeError: The triggered dbt Cloud job run ended in an unexpected state. Returns: The run data returned by the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job and wait for completion as a stand alone flow: ```python import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion asyncio.run( trigger_dbt_cloud_job_run_and_wait_for_completion( dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ), job_id=1 ) ) ``` Trigger a dbt Cloud job and wait for completion as a sub-flow: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion @flow def my_flow(): ... run_result = trigger_dbt_cloud_job_run_and_wait_for_completion( dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ), job_id=1 ) ... my_flow() ``` Trigger a dbt Cloud job with overrides: ```python import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion from prefect_dbt.cloud.models import TriggerJobRunOptions asyncio.run( trigger_dbt_cloud_job_run_and_wait_for_completion( dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ), job_id=1, trigger_job_run_options=TriggerJobRunOptions( git_branch=\"staging\", schema_override=\"dbt_cloud_pr_123\", dbt_version_override=\"0.18.0\", target_name_override=\"staging\", timeout_seconds_override=3000, generate_docs_override=True, threads_override=8, steps_override=[ \"dbt seed\", \"dbt run --fail-fast\", \"dbt test --fail fast\", ], ), ) ) ``` \"\"\" # noqa logger = get_run_logger () triggered_run_data_future = await trigger_dbt_cloud_job_run . submit ( dbt_cloud_credentials = dbt_cloud_credentials , job_id = job_id , options = trigger_job_run_options , ) run_id = ( await triggered_run_data_future . result ()) . get ( \"id\" ) if run_id is None : raise RuntimeError ( \"Unable to determine run ID for triggered job.\" ) final_run_status , run_data = await wait_for_dbt_cloud_job_run ( run_id = run_id , dbt_cloud_credentials = dbt_cloud_credentials , max_wait_seconds = max_wait_seconds , poll_frequency_seconds = poll_frequency_seconds , ) if final_run_status == DbtCloudJobRunStatus . SUCCESS : try : list_run_artifacts_future = await list_dbt_cloud_run_artifacts . submit ( dbt_cloud_credentials = dbt_cloud_credentials , run_id = run_id , ) run_data [ \"artifact_paths\" ] = await list_run_artifacts_future . result () except DbtCloudListRunArtifactsFailed as ex : logger . warning ( \"Unable to retrieve artifacts for job run with ID %s . Reason: %s \" , run_id , ex , ) logger . info ( \"dbt Cloud job run with ID %s completed successfully!\" , run_id , ) return run_data elif final_run_status == DbtCloudJobRunStatus . CANCELLED : raise DbtCloudJobRunCancelled ( f \"Triggered job run with ID { run_id } was cancelled.\" ) elif final_run_status == DbtCloudJobRunStatus . FAILED : while retry_filtered_models_attempts > 0 : logger . info ( f \"Retrying job run with ID: { run_id } \" f \" { retry_filtered_models_attempts } more times\" ) try : retry_filtered_models_attempts -= 1 run_data = await ( retry_dbt_cloud_job_run_subset_and_wait_for_completion ( dbt_cloud_credentials = dbt_cloud_credentials , run_id = run_id , trigger_job_run_options = trigger_job_run_options , max_wait_seconds = max_wait_seconds , poll_frequency_seconds = poll_frequency_seconds , ) ) return run_data except Exception : pass else : raise DbtCloudJobRunFailed ( f \"Triggered job run with ID: { run_id } failed.\" ) else : raise RuntimeError ( f \"Triggered job run with ID: { run_id } ended with unexpected\" f \"status { final_run_status . value } .\" )","title":"Jobs"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs","text":"Module containing tasks and flows for interacting with dbt Cloud jobs","title":"jobs"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs-classes","text":"","title":"Classes"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudGetJobFailed","text":"Bases: Exception Raised when unable to retrieve dbt Cloud job. Source code in prefect_dbt/cloud/jobs.py 31 32 class DbtCloudGetJobFailed ( Exception ): \"\"\"Raised when unable to retrieve dbt Cloud job.\"\"\"","title":"DbtCloudGetJobFailed"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJobRunTriggerFailed","text":"Bases: Exception Raised when a dbt Cloud job trigger fails. Source code in prefect_dbt/cloud/jobs.py 27 28 class DbtCloudJobRunTriggerFailed ( Exception ): \"\"\"Raised when a dbt Cloud job trigger fails.\"\"\"","title":"DbtCloudJobRunTriggerFailed"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs-functions","text":"","title":"Functions"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.get_dbt_cloud_job_info","text":"A task to retrieve information about a dbt Cloud job. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required job_id int The ID of the job to get. required Returns: Type Description Dict The job data returned by the dbt Cloud administrative API. Example Get status of a dbt Cloud job: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_job @flow def get_job_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return get_job ( dbt_cloud_credentials = credentials , job_id = 42 ) get_job_flow () Source code in prefect_dbt/cloud/jobs.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 @task ( name = \"Get dbt Cloud job details\" , description = \"Retrieves details of a dbt Cloud job \" \"for the job with the given job_id.\" , retries = 3 , retry_delay_seconds = 10 , ) async def get_dbt_cloud_job_info ( dbt_cloud_credentials : DbtCloudCredentials , job_id : int , order_by : Optional [ str ] = None , ) -> Dict : \"\"\" A task to retrieve information about a dbt Cloud job. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. job_id: The ID of the job to get. Returns: The job data returned by the dbt Cloud administrative API. Example: Get status of a dbt Cloud job: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_job @flow def get_job_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return get_job( dbt_cloud_credentials=credentials, job_id=42 ) get_job_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . get_job ( job_id = job_id , order_by = order_by , ) except HTTPStatusError as ex : raise DbtCloudGetJobFailed ( extract_user_message ( ex )) from ex return response . json ()[ \"data\" ]","title":"get_dbt_cloud_job_info()"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.get_run_id","text":"Task that extracts the run ID from a trigger job run API response, This task is mainly used to maintain dependency tracking between the trigger_dbt_cloud_job_run task and downstream tasks/flows that use the run ID. Parameters: Name Type Description Default obj Dict The JSON body from the trigger job run response. required Example from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run , get_run_id @flow def trigger_run_and_get_id (): dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) triggered_run_data = trigger_dbt_cloud_job_run ( dbt_cloud_credentials = dbt_cloud_credentials , job_id = job_id , options = trigger_job_run_options , ) run_id = get_run_id . submit ( triggered_run_data ) return run_id trigger_run_and_get_id () Source code in prefect_dbt/cloud/jobs.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 @task ( name = \"Get dbt Cloud job run ID\" , description = \"Extracts the run ID from a trigger job run API response\" , ) def get_run_id ( obj : Dict ): \"\"\" Task that extracts the run ID from a trigger job run API response, This task is mainly used to maintain dependency tracking between the `trigger_dbt_cloud_job_run` task and downstream tasks/flows that use the run ID. Args: obj: The JSON body from the trigger job run response. Example: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run, get_run_id @flow def trigger_run_and_get_id(): dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ) triggered_run_data = trigger_dbt_cloud_job_run( dbt_cloud_credentials=dbt_cloud_credentials, job_id=job_id, options=trigger_job_run_options, ) run_id = get_run_id.submit(triggered_run_data) return run_id trigger_run_and_get_id() ``` \"\"\" id = obj . get ( \"id\" ) if id is None : raise RuntimeError ( \"Unable to determine run ID for triggered job.\" ) return id","title":"get_run_id()"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.retry_dbt_cloud_job_run_subset_and_wait_for_completion","text":"Flow that retrys a subset of dbt Cloud job run, filtered by select statuses, and waits for the triggered retry to complete. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required trigger_job_run_options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None max_wait_seconds int Maximum number of seconds to wait for job to complete 900 poll_frequency_seconds int Number of seconds to wait in between checks for run completion. 10 run_id int The ID of the job run to retry. required Raises: Type Description ValueError If trigger_job_run_options.steps_override is set by the user. Returns: Type Description Dict The run data returned by the dbt Cloud administrative API. Examples: Retry a subset of models in a dbt Cloud job run and wait for completion: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import retry_dbt_cloud_job_run_subset_and_wait_for_completion @flow def retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow (): credentials = DbtCloudCredentials . load ( \"MY_BLOCK_NAME\" ) retry_dbt_cloud_job_run_subset_and_wait_for_completion ( dbt_cloud_credentials = credentials , run_id = 88640123 , ) retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow () Source code in prefect_dbt/cloud/jobs.py 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 @flow ( name = \"Retry subset of dbt Cloud job run and wait for completion\" , description = ( \"Retries a subset of dbt Cloud job run, filtered by select statuses, \" \"and waits for the triggered retry to complete.\" ), ) async def retry_dbt_cloud_job_run_subset_and_wait_for_completion ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int , trigger_job_run_options : Optional [ TriggerJobRunOptions ] = None , max_wait_seconds : int = 900 , poll_frequency_seconds : int = 10 , ) -> Dict : \"\"\" Flow that retrys a subset of dbt Cloud job run, filtered by select statuses, and waits for the triggered retry to complete. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. trigger_job_run_options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. max_wait_seconds: Maximum number of seconds to wait for job to complete poll_frequency_seconds: Number of seconds to wait in between checks for run completion. run_id: The ID of the job run to retry. Raises: ValueError: If `trigger_job_run_options.steps_override` is set by the user. Returns: The run data returned by the dbt Cloud administrative API. Examples: Retry a subset of models in a dbt Cloud job run and wait for completion: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import retry_dbt_cloud_job_run_subset_and_wait_for_completion @flow def retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow(): credentials = DbtCloudCredentials.load(\"MY_BLOCK_NAME\") retry_dbt_cloud_job_run_subset_and_wait_for_completion( dbt_cloud_credentials=credentials, run_id=88640123, ) retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow() ``` \"\"\" # noqa if trigger_job_run_options and trigger_job_run_options . steps_override is not None : raise ValueError ( \"Do not set `steps_override` in `trigger_job_run_options` \" \"because this flow will automatically set it\" ) run_info_future = await get_dbt_cloud_run_info . submit ( dbt_cloud_credentials = dbt_cloud_credentials , run_id = run_id , include_related = [ \"run_steps\" ], ) run_info = await run_info_future . result () job_id = run_info [ \"job_id\" ] job_info_future = await get_dbt_cloud_job_info . submit ( dbt_cloud_credentials = dbt_cloud_credentials , job_id = job_id , ) job_info = await job_info_future . result () trigger_job_run_options_override = await _build_trigger_job_run_options ( dbt_cloud_credentials = dbt_cloud_credentials , trigger_job_run_options = trigger_job_run_options , run_id = run_id , run_info = run_info , job_info = job_info , ) # to circumvent `RuntimeError: The task runner is already started!` flow_run_context = FlowRunContext . get () task_runner_type = type ( flow_run_context . task_runner ) run_data = await trigger_dbt_cloud_job_run_and_wait_for_completion . with_options ( task_runner = task_runner_type () )( dbt_cloud_credentials = dbt_cloud_credentials , job_id = job_id , retry_filtered_models_attempts = 0 , trigger_job_run_options = trigger_job_run_options_override , max_wait_seconds = max_wait_seconds , poll_frequency_seconds = poll_frequency_seconds , ) return run_data","title":"retry_dbt_cloud_job_run_subset_and_wait_for_completion()"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.trigger_dbt_cloud_job_run","text":"A task to trigger a dbt Cloud job run. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required job_id int The ID of the job to trigger. required options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None Returns: Type Description Dict The run data returned from the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) trigger_dbt_cloud_job_run ( dbt_cloud_credentials = credentials , job_id = 1 ) trigger_dbt_cloud_job_run_flow () Trigger a dbt Cloud job run with overrides: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run from prefect_dbt.cloud.models import TriggerJobRunOptions @flow def trigger_dbt_cloud_job_run_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) trigger_dbt_cloud_job_run ( dbt_cloud_credentials = credentials , job_id = 1 , options = TriggerJobRunOptions ( git_branch = \"staging\" , schema_override = \"dbt_cloud_pr_123\" , dbt_version_override = \"0.18.0\" , target_name_override = \"staging\" , timeout_seconds_override = 3000 , generate_docs_override = True , threads_override = 8 , steps_override = [ \"dbt seed\" , \"dbt run --fail-fast\" , \"dbt test --fail fast\" , ], ), ) trigger_dbt_cloud_job_run () Source code in prefect_dbt/cloud/jobs.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 @task ( name = \"Trigger dbt Cloud job run\" , description = \"Triggers a dbt Cloud job run for the job \" \"with the given job_id and optional overrides.\" , retries = 3 , retry_delay_seconds = 10 , ) async def trigger_dbt_cloud_job_run ( dbt_cloud_credentials : DbtCloudCredentials , job_id : int , options : Optional [ TriggerJobRunOptions ] = None , ) -> Dict : \"\"\" A task to trigger a dbt Cloud job run. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. job_id: The ID of the job to trigger. options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. Returns: The run data returned from the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1) trigger_dbt_cloud_job_run_flow() ``` Trigger a dbt Cloud job run with overrides: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run from prefect_dbt.cloud.models import TriggerJobRunOptions @flow def trigger_dbt_cloud_job_run_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) trigger_dbt_cloud_job_run( dbt_cloud_credentials=credentials, job_id=1, options=TriggerJobRunOptions( git_branch=\"staging\", schema_override=\"dbt_cloud_pr_123\", dbt_version_override=\"0.18.0\", target_name_override=\"staging\", timeout_seconds_override=3000, generate_docs_override=True, threads_override=8, steps_override=[ \"dbt seed\", \"dbt run --fail-fast\", \"dbt test --fail fast\", ], ), ) trigger_dbt_cloud_job_run() ``` \"\"\" # noqa logger = get_run_logger () logger . info ( f \"Triggering run for job with ID { job_id } \" ) try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . trigger_job_run ( job_id = job_id , options = options ) except HTTPStatusError as ex : raise DbtCloudJobRunTriggerFailed ( extract_user_message ( ex )) from ex run_data = response . json ()[ \"data\" ] if \"project_id\" in run_data and \"id\" in run_data : logger . info ( f \"Run successfully triggered for job with ID { job_id } . \" \"You can view the status of this run at \" f \"https:// { dbt_cloud_credentials . domain } /#/accounts/\" f \" { dbt_cloud_credentials . account_id } /projects/ { run_data [ 'project_id' ] } /\" f \"runs/ { run_data [ 'id' ] } /\" ) return run_data","title":"trigger_dbt_cloud_job_run()"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.trigger_dbt_cloud_job_run_and_wait_for_completion","text":"Flow that triggers a job run and waits for the triggered run to complete. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required job_id int The ID of the job to trigger. required trigger_job_run_options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None max_wait_seconds int Maximum number of seconds to wait for job to complete 900 poll_frequency_seconds int Number of seconds to wait in between checks for run completion. 10 retry_filtered_models_attempts int Number of times to retry models selected by retry_status_filters . 3 Raises: Type Description DbtCloudJobRunCancelled The triggered dbt Cloud job run was cancelled. DbtCloudJobRunFailed The triggered dbt Cloud job run failed. RuntimeError The triggered dbt Cloud job run ended in an unexpected state. Returns: Type Description Dict The run data returned by the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job and wait for completion as a stand alone flow: import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion asyncio . run ( trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 ) ) Trigger a dbt Cloud job and wait for completion as a sub-flow: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion @flow def my_flow (): ... run_result = trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 ) ... my_flow () Trigger a dbt Cloud job with overrides: import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion from prefect_dbt.cloud.models import TriggerJobRunOptions asyncio . run ( trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 , trigger_job_run_options = TriggerJobRunOptions ( git_branch = \"staging\" , schema_override = \"dbt_cloud_pr_123\" , dbt_version_override = \"0.18.0\" , target_name_override = \"staging\" , timeout_seconds_override = 3000 , generate_docs_override = True , threads_override = 8 , steps_override = [ \"dbt seed\" , \"dbt run --fail-fast\" , \"dbt test --fail fast\" , ], ), ) ) Source code in prefect_dbt/cloud/jobs.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 @flow ( name = \"Trigger dbt Cloud job run and wait for completion\" , description = \"Triggers a dbt Cloud job run and waits for the\" \"triggered run to complete.\" , ) async def trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials : DbtCloudCredentials , job_id : int , trigger_job_run_options : Optional [ TriggerJobRunOptions ] = None , max_wait_seconds : int = 900 , poll_frequency_seconds : int = 10 , retry_filtered_models_attempts : int = 3 , ) -> Dict : \"\"\" Flow that triggers a job run and waits for the triggered run to complete. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. job_id: The ID of the job to trigger. trigger_job_run_options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. max_wait_seconds: Maximum number of seconds to wait for job to complete poll_frequency_seconds: Number of seconds to wait in between checks for run completion. retry_filtered_models_attempts: Number of times to retry models selected by `retry_status_filters`. Raises: DbtCloudJobRunCancelled: The triggered dbt Cloud job run was cancelled. DbtCloudJobRunFailed: The triggered dbt Cloud job run failed. RuntimeError: The triggered dbt Cloud job run ended in an unexpected state. Returns: The run data returned by the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job and wait for completion as a stand alone flow: ```python import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion asyncio.run( trigger_dbt_cloud_job_run_and_wait_for_completion( dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ), job_id=1 ) ) ``` Trigger a dbt Cloud job and wait for completion as a sub-flow: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion @flow def my_flow(): ... run_result = trigger_dbt_cloud_job_run_and_wait_for_completion( dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ), job_id=1 ) ... my_flow() ``` Trigger a dbt Cloud job with overrides: ```python import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion from prefect_dbt.cloud.models import TriggerJobRunOptions asyncio.run( trigger_dbt_cloud_job_run_and_wait_for_completion( dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ), job_id=1, trigger_job_run_options=TriggerJobRunOptions( git_branch=\"staging\", schema_override=\"dbt_cloud_pr_123\", dbt_version_override=\"0.18.0\", target_name_override=\"staging\", timeout_seconds_override=3000, generate_docs_override=True, threads_override=8, steps_override=[ \"dbt seed\", \"dbt run --fail-fast\", \"dbt test --fail fast\", ], ), ) ) ``` \"\"\" # noqa logger = get_run_logger () triggered_run_data_future = await trigger_dbt_cloud_job_run . submit ( dbt_cloud_credentials = dbt_cloud_credentials , job_id = job_id , options = trigger_job_run_options , ) run_id = ( await triggered_run_data_future . result ()) . get ( \"id\" ) if run_id is None : raise RuntimeError ( \"Unable to determine run ID for triggered job.\" ) final_run_status , run_data = await wait_for_dbt_cloud_job_run ( run_id = run_id , dbt_cloud_credentials = dbt_cloud_credentials , max_wait_seconds = max_wait_seconds , poll_frequency_seconds = poll_frequency_seconds , ) if final_run_status == DbtCloudJobRunStatus . SUCCESS : try : list_run_artifacts_future = await list_dbt_cloud_run_artifacts . submit ( dbt_cloud_credentials = dbt_cloud_credentials , run_id = run_id , ) run_data [ \"artifact_paths\" ] = await list_run_artifacts_future . result () except DbtCloudListRunArtifactsFailed as ex : logger . warning ( \"Unable to retrieve artifacts for job run with ID %s . Reason: %s \" , run_id , ex , ) logger . info ( \"dbt Cloud job run with ID %s completed successfully!\" , run_id , ) return run_data elif final_run_status == DbtCloudJobRunStatus . CANCELLED : raise DbtCloudJobRunCancelled ( f \"Triggered job run with ID { run_id } was cancelled.\" ) elif final_run_status == DbtCloudJobRunStatus . FAILED : while retry_filtered_models_attempts > 0 : logger . info ( f \"Retrying job run with ID: { run_id } \" f \" { retry_filtered_models_attempts } more times\" ) try : retry_filtered_models_attempts -= 1 run_data = await ( retry_dbt_cloud_job_run_subset_and_wait_for_completion ( dbt_cloud_credentials = dbt_cloud_credentials , run_id = run_id , trigger_job_run_options = trigger_job_run_options , max_wait_seconds = max_wait_seconds , poll_frequency_seconds = poll_frequency_seconds , ) ) return run_data except Exception : pass else : raise DbtCloudJobRunFailed ( f \"Triggered job run with ID: { run_id } failed.\" ) else : raise RuntimeError ( f \"Triggered job run with ID: { run_id } ended with unexpected\" f \"status { final_run_status . value } .\" )","title":"trigger_dbt_cloud_job_run_and_wait_for_completion()"},{"location":"cloud/models/","text":"prefect_dbt.cloud.models Module containing models used for passing data to dbt Cloud Classes TriggerJobRunOptions Bases: BaseModel Defines options that can be defined when triggering a dbt Cloud job run. Source code in prefect_dbt/cloud/models.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 class TriggerJobRunOptions ( BaseModel ): \"\"\" Defines options that can be defined when triggering a dbt Cloud job run. \"\"\" cause : str = Field ( default_factory = default_cause_factory , description = \"A text description of the reason for running this job.\" , ) git_sha : Optional [ str ] = Field ( default = None , description = \"The git sha to check out before running this job.\" ) git_branch : Optional [ str ] = Field ( default = None , description = \"The git branch to check out before running this job.\" ) schema_override : Optional [ str ] = Field ( default = None , description = \"Override the destination schema in the configured \" \"target for this job.\" , ) dbt_version_override : Optional [ str ] = Field ( default = None , description = \"Override the version of dbt used to run this job.\" ) threads_override : Optional [ int ] = Field ( default = None , description = \"Override the number of threads used to run this job.\" ) target_name_override : Optional [ str ] = Field ( default = None , description = \"Override the target.name context variable used when \" \"running this job\" , ) generate_docs_override : Optional [ bool ] = Field ( default = None , description = \"Override whether or not this job generates docs \" \"(true=yes, false=no).\" , ) timeout_seconds_override : Optional [ int ] = Field ( default = None , description = \"Override the timeout in seconds for this job.\" ) steps_override : Optional [ List [ str ]] = Field ( default = None , description = \"Override the list of steps for this job.\" ) Functions default_cause_factory Factory function to populate the default cause for a job run to include information from the Prefect run context. Source code in prefect_dbt/cloud/models.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def default_cause_factory (): \"\"\" Factory function to populate the default cause for a job run to include information from the Prefect run context. \"\"\" cause = \"Triggered via Prefect\" try : context = get_run_context () if isinstance ( context , FlowRunContext ): cause = f \" { cause } in flow run { context . flow_run . name } \" elif isinstance ( context , TaskRunContext ): cause = f \" { cause } in task run { context . task_run . name } \" except RuntimeError : pass return cause","title":"Models"},{"location":"cloud/models/#prefect_dbt.cloud.models","text":"Module containing models used for passing data to dbt Cloud","title":"models"},{"location":"cloud/models/#prefect_dbt.cloud.models-classes","text":"","title":"Classes"},{"location":"cloud/models/#prefect_dbt.cloud.models.TriggerJobRunOptions","text":"Bases: BaseModel Defines options that can be defined when triggering a dbt Cloud job run. Source code in prefect_dbt/cloud/models.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 class TriggerJobRunOptions ( BaseModel ): \"\"\" Defines options that can be defined when triggering a dbt Cloud job run. \"\"\" cause : str = Field ( default_factory = default_cause_factory , description = \"A text description of the reason for running this job.\" , ) git_sha : Optional [ str ] = Field ( default = None , description = \"The git sha to check out before running this job.\" ) git_branch : Optional [ str ] = Field ( default = None , description = \"The git branch to check out before running this job.\" ) schema_override : Optional [ str ] = Field ( default = None , description = \"Override the destination schema in the configured \" \"target for this job.\" , ) dbt_version_override : Optional [ str ] = Field ( default = None , description = \"Override the version of dbt used to run this job.\" ) threads_override : Optional [ int ] = Field ( default = None , description = \"Override the number of threads used to run this job.\" ) target_name_override : Optional [ str ] = Field ( default = None , description = \"Override the target.name context variable used when \" \"running this job\" , ) generate_docs_override : Optional [ bool ] = Field ( default = None , description = \"Override whether or not this job generates docs \" \"(true=yes, false=no).\" , ) timeout_seconds_override : Optional [ int ] = Field ( default = None , description = \"Override the timeout in seconds for this job.\" ) steps_override : Optional [ List [ str ]] = Field ( default = None , description = \"Override the list of steps for this job.\" )","title":"TriggerJobRunOptions"},{"location":"cloud/models/#prefect_dbt.cloud.models-functions","text":"","title":"Functions"},{"location":"cloud/models/#prefect_dbt.cloud.models.default_cause_factory","text":"Factory function to populate the default cause for a job run to include information from the Prefect run context. Source code in prefect_dbt/cloud/models.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def default_cause_factory (): \"\"\" Factory function to populate the default cause for a job run to include information from the Prefect run context. \"\"\" cause = \"Triggered via Prefect\" try : context = get_run_context () if isinstance ( context , FlowRunContext ): cause = f \" { cause } in flow run { context . flow_run . name } \" elif isinstance ( context , TaskRunContext ): cause = f \" { cause } in task run { context . task_run . name } \" except RuntimeError : pass return cause","title":"default_cause_factory()"},{"location":"cloud/runs/","text":"prefect_dbt.cloud.runs Module containing tasks and flows for interacting with dbt Cloud job runs Classes DbtCloudGetRunArtifactFailed Bases: Exception Raised when unable to get a dbt Cloud run artifact Source code in prefect_dbt/cloud/runs.py 22 23 class DbtCloudGetRunArtifactFailed ( Exception ): \"\"\"Raised when unable to get a dbt Cloud run artifact\"\"\" DbtCloudGetRunFailed Bases: Exception Raised when unable to retrieve dbt Cloud run Source code in prefect_dbt/cloud/runs.py 14 15 class DbtCloudGetRunFailed ( Exception ): \"\"\"Raised when unable to retrieve dbt Cloud run\"\"\" DbtCloudJobRunCancelled Bases: Exception Raised when a triggered job run is cancelled Source code in prefect_dbt/cloud/runs.py 30 31 class DbtCloudJobRunCancelled ( Exception ): \"\"\"Raised when a triggered job run is cancelled\"\"\" DbtCloudJobRunFailed Bases: Exception Raised when a triggered job run fails Source code in prefect_dbt/cloud/runs.py 26 27 class DbtCloudJobRunFailed ( Exception ): \"\"\"Raised when a triggered job run fails\"\"\" DbtCloudJobRunStatus Bases: Enum dbt Cloud Job statuses. Source code in prefect_dbt/cloud/runs.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 class DbtCloudJobRunStatus ( Enum ): \"\"\"dbt Cloud Job statuses.\"\"\" QUEUED = 1 STARTING = 2 RUNNING = 3 SUCCESS = 10 FAILED = 20 CANCELLED = 30 @classmethod def is_terminal_status_code ( cls , status_code : Any ) -> bool : \"\"\" Returns True if a status code is terminal for a job run. Returns False otherwise. \"\"\" return status_code in [ cls . SUCCESS . value , cls . FAILED . value , cls . CANCELLED . value ] Functions is_terminal_status_code classmethod Returns True if a status code is terminal for a job run. Returns False otherwise. Source code in prefect_dbt/cloud/runs.py 51 52 53 54 55 56 57 @classmethod def is_terminal_status_code ( cls , status_code : Any ) -> bool : \"\"\" Returns True if a status code is terminal for a job run. Returns False otherwise. \"\"\" return status_code in [ cls . SUCCESS . value , cls . FAILED . value , cls . CANCELLED . value ] DbtCloudJobRunTimedOut Bases: Exception Raised when a triggered job run does not complete in the configured max wait seconds Source code in prefect_dbt/cloud/runs.py 34 35 36 37 38 class DbtCloudJobRunTimedOut ( Exception ): \"\"\" Raised when a triggered job run does not complete in the configured max wait seconds \"\"\" DbtCloudListRunArtifactsFailed Bases: Exception Raised when unable to list dbt Cloud run artifacts Source code in prefect_dbt/cloud/runs.py 18 19 class DbtCloudListRunArtifactsFailed ( Exception ): \"\"\"Raised when unable to list dbt Cloud run artifacts\"\"\" Functions get_dbt_cloud_run_artifact async A task to get an artifact generated for a completed run. The requested artifact is saved to a file in the current working directory. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required run_id int The ID of the run to list run artifacts for. required path str The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description Union [ Dict , str ] The contents of the requested manifest. Returns a Dict if the requested artifact is a JSON file and a str otherwise. Examples: Get an artifact of a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact @flow def get_artifact_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return get_dbt_cloud_run_artifact ( dbt_cloud_credentials = credentials , run_id = 42 , path = \"manifest.json\" ) get_artifact_flow () Get an artifact of a dbt Cloud job run and write it to a file: import json from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact @flow def get_artifact_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) get_run_artifact_result = get_dbt_cloud_run_artifact ( dbt_cloud_credentials = credentials , run_id = 42 , path = \"manifest.json\" ) with open ( \"manifest.json\" , \"w\" ) as file : json . dump ( get_run_artifact_result , file ) get_artifact_flow () Source code in prefect_dbt/cloud/runs.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 @task ( name = \"Get dbt Cloud job artifact\" , description = \"Fetches an artifact from a completed run.\" , retries = 3 , retry_delay_seconds = 10 , ) async def get_dbt_cloud_run_artifact ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int , path : str , step : Optional [ int ] = None , ) -> Union [ Dict , str ]: \"\"\" A task to get an artifact generated for a completed run. The requested artifact is saved to a file in the current working directory. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. run_id: The ID of the run to list run artifacts for. path: The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The contents of the requested manifest. Returns a `Dict` if the requested artifact is a JSON file and a `str` otherwise. Examples: Get an artifact of a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact @flow def get_artifact_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return get_dbt_cloud_run_artifact( dbt_cloud_credentials=credentials, run_id=42, path=\"manifest.json\" ) get_artifact_flow() ``` Get an artifact of a dbt Cloud job run and write it to a file: ```python import json from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact @flow def get_artifact_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) get_run_artifact_result = get_dbt_cloud_run_artifact( dbt_cloud_credentials=credentials, run_id=42, path=\"manifest.json\" ) with open(\"manifest.json\", \"w\") as file: json.dump(get_run_artifact_result, file) get_artifact_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . get_run_artifact ( run_id = run_id , path = path , step = step ) except HTTPStatusError as ex : raise DbtCloudGetRunArtifactFailed ( extract_user_message ( ex )) from ex if path . endswith ( \".json\" ): artifact_contents = response . json () else : artifact_contents = response . text return artifact_contents get_dbt_cloud_run_info async A task to retrieve information about a dbt Cloud job run. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required run_id int The ID of the job to trigger. required include_related Optional [ List [ Literal [ trigger , job , debug_logs , run_steps ]]] List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file. None Returns: Type Description Dict The run data returned by the dbt Cloud administrative API. Example Get status of a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_run @flow def get_run_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return get_run ( dbt_cloud_credentials = credentials , run_id = 42 ) get_run_flow () Source code in prefect_dbt/cloud/runs.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 @task ( name = \"Get dbt Cloud job run details\" , description = \"Retrieves details of a dbt Cloud job run \" \"for the run with the given run_id.\" , retries = 3 , retry_delay_seconds = 10 , ) async def get_dbt_cloud_run_info ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int , include_related : Optional [ List [ Literal [ \"trigger\" , \"job\" , \"debug_logs\" , \"run_steps\" ]] ] = None , ) -> Dict : \"\"\" A task to retrieve information about a dbt Cloud job run. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. run_id: The ID of the job to trigger. include_related: List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file. Returns: The run data returned by the dbt Cloud administrative API. Example: Get status of a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_run @flow def get_run_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return get_run( dbt_cloud_credentials=credentials, run_id=42 ) get_run_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . get_run ( run_id = run_id , include_related = include_related ) except HTTPStatusError as ex : raise DbtCloudGetRunFailed ( extract_user_message ( ex )) from ex return response . json ()[ \"data\" ] list_dbt_cloud_run_artifacts async A task to list the artifact files generated for a completed run. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required run_id int The ID of the run to list run artifacts for. required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description List [ str ] A list of paths to artifact files that can be used to retrieve the generated artifacts. Example List artifacts of a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts @flow def list_artifacts_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return list_dbt_cloud_run_artifacts ( dbt_cloud_credentials = credentials , run_id = 42 ) list_artifacts_flow () Source code in prefect_dbt/cloud/runs.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 @task ( name = \"List dbt Cloud job artifacts\" , description = \"Fetches a list of artifact files generated for a completed run.\" , retries = 3 , retry_delay_seconds = 10 , ) async def list_dbt_cloud_run_artifacts ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int , step : Optional [ int ] = None ) -> List [ str ]: \"\"\" A task to list the artifact files generated for a completed run. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. run_id: The ID of the run to list run artifacts for. step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: A list of paths to artifact files that can be used to retrieve the generated artifacts. Example: List artifacts of a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts @flow def list_artifacts_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return list_dbt_cloud_run_artifacts( dbt_cloud_credentials=credentials, run_id=42 ) list_artifacts_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . list_run_artifacts ( run_id = run_id , step = step ) except HTTPStatusError as ex : raise DbtCloudListRunArtifactsFailed ( extract_user_message ( ex )) from ex return response . json ()[ \"data\" ] wait_for_dbt_cloud_job_run async Waits for the given dbt Cloud job run to finish running. Parameters: Name Type Description Default run_id int The ID of the run to wait for. required dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required max_wait_seconds int Maximum number of seconds to wait for job to complete 900 poll_frequency_seconds int Number of seconds to wait in between checks for run completion. 10 Raises: Type Description DbtCloudJobRunTimedOut When the elapsed wait time exceeds max_wait_seconds . Returns: Name Type Description run_status DbtCloudJobRunStatus An enum representing the final dbt Cloud job run status run_data Dict A dictionary containing information about the run after completion. Source code in prefect_dbt/cloud/runs.py 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 @flow ( name = \"Wait for dbt Cloud job run\" , description = \"Waits for a dbt Cloud job run to finish running.\" , ) async def wait_for_dbt_cloud_job_run ( run_id : int , dbt_cloud_credentials : DbtCloudCredentials , max_wait_seconds : int = 900 , poll_frequency_seconds : int = 10 , ) -> Tuple [ DbtCloudJobRunStatus , Dict ]: \"\"\" Waits for the given dbt Cloud job run to finish running. Args: run_id: The ID of the run to wait for. dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. max_wait_seconds: Maximum number of seconds to wait for job to complete poll_frequency_seconds: Number of seconds to wait in between checks for run completion. Raises: DbtCloudJobRunTimedOut: When the elapsed wait time exceeds `max_wait_seconds`. Returns: run_status: An enum representing the final dbt Cloud job run status run_data: A dictionary containing information about the run after completion. Example: \"\"\" logger = get_run_logger () seconds_waited_for_run_completion = 0 wait_for = [] while seconds_waited_for_run_completion <= max_wait_seconds : run_data_future = await get_dbt_cloud_run_info . submit ( dbt_cloud_credentials = dbt_cloud_credentials , run_id = run_id , wait_for = wait_for , ) run_data = await run_data_future . result () run_status_code = run_data . get ( \"status\" ) if DbtCloudJobRunStatus . is_terminal_status_code ( run_status_code ): return DbtCloudJobRunStatus ( run_status_code ), run_data wait_for = [ run_data_future ] logger . debug ( \"dbt Cloud job run with ID %i has status %s . Waiting for %i seconds.\" , run_id , DbtCloudJobRunStatus ( run_status_code ) . name , poll_frequency_seconds , ) await asyncio . sleep ( poll_frequency_seconds ) seconds_waited_for_run_completion += poll_frequency_seconds raise DbtCloudJobRunTimedOut ( f \"Max wait time of { max_wait_seconds } seconds exceeded while waiting \" \"for job run with ID {run_id} \" )","title":"Runs"},{"location":"cloud/runs/#prefect_dbt.cloud.runs","text":"Module containing tasks and flows for interacting with dbt Cloud job runs","title":"runs"},{"location":"cloud/runs/#prefect_dbt.cloud.runs-classes","text":"","title":"Classes"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudGetRunArtifactFailed","text":"Bases: Exception Raised when unable to get a dbt Cloud run artifact Source code in prefect_dbt/cloud/runs.py 22 23 class DbtCloudGetRunArtifactFailed ( Exception ): \"\"\"Raised when unable to get a dbt Cloud run artifact\"\"\"","title":"DbtCloudGetRunArtifactFailed"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudGetRunFailed","text":"Bases: Exception Raised when unable to retrieve dbt Cloud run Source code in prefect_dbt/cloud/runs.py 14 15 class DbtCloudGetRunFailed ( Exception ): \"\"\"Raised when unable to retrieve dbt Cloud run\"\"\"","title":"DbtCloudGetRunFailed"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunCancelled","text":"Bases: Exception Raised when a triggered job run is cancelled Source code in prefect_dbt/cloud/runs.py 30 31 class DbtCloudJobRunCancelled ( Exception ): \"\"\"Raised when a triggered job run is cancelled\"\"\"","title":"DbtCloudJobRunCancelled"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunFailed","text":"Bases: Exception Raised when a triggered job run fails Source code in prefect_dbt/cloud/runs.py 26 27 class DbtCloudJobRunFailed ( Exception ): \"\"\"Raised when a triggered job run fails\"\"\"","title":"DbtCloudJobRunFailed"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunStatus","text":"Bases: Enum dbt Cloud Job statuses. Source code in prefect_dbt/cloud/runs.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 class DbtCloudJobRunStatus ( Enum ): \"\"\"dbt Cloud Job statuses.\"\"\" QUEUED = 1 STARTING = 2 RUNNING = 3 SUCCESS = 10 FAILED = 20 CANCELLED = 30 @classmethod def is_terminal_status_code ( cls , status_code : Any ) -> bool : \"\"\" Returns True if a status code is terminal for a job run. Returns False otherwise. \"\"\" return status_code in [ cls . SUCCESS . value , cls . FAILED . value , cls . CANCELLED . value ]","title":"DbtCloudJobRunStatus"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunStatus-functions","text":"","title":"Functions"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunStatus.is_terminal_status_code","text":"Returns True if a status code is terminal for a job run. Returns False otherwise. Source code in prefect_dbt/cloud/runs.py 51 52 53 54 55 56 57 @classmethod def is_terminal_status_code ( cls , status_code : Any ) -> bool : \"\"\" Returns True if a status code is terminal for a job run. Returns False otherwise. \"\"\" return status_code in [ cls . SUCCESS . value , cls . FAILED . value , cls . CANCELLED . value ]","title":"is_terminal_status_code()"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunTimedOut","text":"Bases: Exception Raised when a triggered job run does not complete in the configured max wait seconds Source code in prefect_dbt/cloud/runs.py 34 35 36 37 38 class DbtCloudJobRunTimedOut ( Exception ): \"\"\" Raised when a triggered job run does not complete in the configured max wait seconds \"\"\"","title":"DbtCloudJobRunTimedOut"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudListRunArtifactsFailed","text":"Bases: Exception Raised when unable to list dbt Cloud run artifacts Source code in prefect_dbt/cloud/runs.py 18 19 class DbtCloudListRunArtifactsFailed ( Exception ): \"\"\"Raised when unable to list dbt Cloud run artifacts\"\"\"","title":"DbtCloudListRunArtifactsFailed"},{"location":"cloud/runs/#prefect_dbt.cloud.runs-functions","text":"","title":"Functions"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.get_dbt_cloud_run_artifact","text":"A task to get an artifact generated for a completed run. The requested artifact is saved to a file in the current working directory. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required run_id int The ID of the run to list run artifacts for. required path str The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description Union [ Dict , str ] The contents of the requested manifest. Returns a Dict if the requested artifact is a JSON file and a str otherwise. Examples: Get an artifact of a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact @flow def get_artifact_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return get_dbt_cloud_run_artifact ( dbt_cloud_credentials = credentials , run_id = 42 , path = \"manifest.json\" ) get_artifact_flow () Get an artifact of a dbt Cloud job run and write it to a file: import json from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact @flow def get_artifact_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) get_run_artifact_result = get_dbt_cloud_run_artifact ( dbt_cloud_credentials = credentials , run_id = 42 , path = \"manifest.json\" ) with open ( \"manifest.json\" , \"w\" ) as file : json . dump ( get_run_artifact_result , file ) get_artifact_flow () Source code in prefect_dbt/cloud/runs.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 @task ( name = \"Get dbt Cloud job artifact\" , description = \"Fetches an artifact from a completed run.\" , retries = 3 , retry_delay_seconds = 10 , ) async def get_dbt_cloud_run_artifact ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int , path : str , step : Optional [ int ] = None , ) -> Union [ Dict , str ]: \"\"\" A task to get an artifact generated for a completed run. The requested artifact is saved to a file in the current working directory. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. run_id: The ID of the run to list run artifacts for. path: The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The contents of the requested manifest. Returns a `Dict` if the requested artifact is a JSON file and a `str` otherwise. Examples: Get an artifact of a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact @flow def get_artifact_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return get_dbt_cloud_run_artifact( dbt_cloud_credentials=credentials, run_id=42, path=\"manifest.json\" ) get_artifact_flow() ``` Get an artifact of a dbt Cloud job run and write it to a file: ```python import json from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact @flow def get_artifact_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) get_run_artifact_result = get_dbt_cloud_run_artifact( dbt_cloud_credentials=credentials, run_id=42, path=\"manifest.json\" ) with open(\"manifest.json\", \"w\") as file: json.dump(get_run_artifact_result, file) get_artifact_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . get_run_artifact ( run_id = run_id , path = path , step = step ) except HTTPStatusError as ex : raise DbtCloudGetRunArtifactFailed ( extract_user_message ( ex )) from ex if path . endswith ( \".json\" ): artifact_contents = response . json () else : artifact_contents = response . text return artifact_contents","title":"get_dbt_cloud_run_artifact()"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.get_dbt_cloud_run_info","text":"A task to retrieve information about a dbt Cloud job run. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required run_id int The ID of the job to trigger. required include_related Optional [ List [ Literal [ trigger , job , debug_logs , run_steps ]]] List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file. None Returns: Type Description Dict The run data returned by the dbt Cloud administrative API. Example Get status of a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_run @flow def get_run_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return get_run ( dbt_cloud_credentials = credentials , run_id = 42 ) get_run_flow () Source code in prefect_dbt/cloud/runs.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 @task ( name = \"Get dbt Cloud job run details\" , description = \"Retrieves details of a dbt Cloud job run \" \"for the run with the given run_id.\" , retries = 3 , retry_delay_seconds = 10 , ) async def get_dbt_cloud_run_info ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int , include_related : Optional [ List [ Literal [ \"trigger\" , \"job\" , \"debug_logs\" , \"run_steps\" ]] ] = None , ) -> Dict : \"\"\" A task to retrieve information about a dbt Cloud job run. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. run_id: The ID of the job to trigger. include_related: List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file. Returns: The run data returned by the dbt Cloud administrative API. Example: Get status of a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_run @flow def get_run_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return get_run( dbt_cloud_credentials=credentials, run_id=42 ) get_run_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . get_run ( run_id = run_id , include_related = include_related ) except HTTPStatusError as ex : raise DbtCloudGetRunFailed ( extract_user_message ( ex )) from ex return response . json ()[ \"data\" ]","title":"get_dbt_cloud_run_info()"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.list_dbt_cloud_run_artifacts","text":"A task to list the artifact files generated for a completed run. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required run_id int The ID of the run to list run artifacts for. required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description List [ str ] A list of paths to artifact files that can be used to retrieve the generated artifacts. Example List artifacts of a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts @flow def list_artifacts_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return list_dbt_cloud_run_artifacts ( dbt_cloud_credentials = credentials , run_id = 42 ) list_artifacts_flow () Source code in prefect_dbt/cloud/runs.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 @task ( name = \"List dbt Cloud job artifacts\" , description = \"Fetches a list of artifact files generated for a completed run.\" , retries = 3 , retry_delay_seconds = 10 , ) async def list_dbt_cloud_run_artifacts ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int , step : Optional [ int ] = None ) -> List [ str ]: \"\"\" A task to list the artifact files generated for a completed run. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. run_id: The ID of the run to list run artifacts for. step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: A list of paths to artifact files that can be used to retrieve the generated artifacts. Example: List artifacts of a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts @flow def list_artifacts_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return list_dbt_cloud_run_artifacts( dbt_cloud_credentials=credentials, run_id=42 ) list_artifacts_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . list_run_artifacts ( run_id = run_id , step = step ) except HTTPStatusError as ex : raise DbtCloudListRunArtifactsFailed ( extract_user_message ( ex )) from ex return response . json ()[ \"data\" ]","title":"list_dbt_cloud_run_artifacts()"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.wait_for_dbt_cloud_job_run","text":"Waits for the given dbt Cloud job run to finish running. Parameters: Name Type Description Default run_id int The ID of the run to wait for. required dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required max_wait_seconds int Maximum number of seconds to wait for job to complete 900 poll_frequency_seconds int Number of seconds to wait in between checks for run completion. 10 Raises: Type Description DbtCloudJobRunTimedOut When the elapsed wait time exceeds max_wait_seconds . Returns: Name Type Description run_status DbtCloudJobRunStatus An enum representing the final dbt Cloud job run status run_data Dict A dictionary containing information about the run after completion. Source code in prefect_dbt/cloud/runs.py 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 @flow ( name = \"Wait for dbt Cloud job run\" , description = \"Waits for a dbt Cloud job run to finish running.\" , ) async def wait_for_dbt_cloud_job_run ( run_id : int , dbt_cloud_credentials : DbtCloudCredentials , max_wait_seconds : int = 900 , poll_frequency_seconds : int = 10 , ) -> Tuple [ DbtCloudJobRunStatus , Dict ]: \"\"\" Waits for the given dbt Cloud job run to finish running. Args: run_id: The ID of the run to wait for. dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. max_wait_seconds: Maximum number of seconds to wait for job to complete poll_frequency_seconds: Number of seconds to wait in between checks for run completion. Raises: DbtCloudJobRunTimedOut: When the elapsed wait time exceeds `max_wait_seconds`. Returns: run_status: An enum representing the final dbt Cloud job run status run_data: A dictionary containing information about the run after completion. Example: \"\"\" logger = get_run_logger () seconds_waited_for_run_completion = 0 wait_for = [] while seconds_waited_for_run_completion <= max_wait_seconds : run_data_future = await get_dbt_cloud_run_info . submit ( dbt_cloud_credentials = dbt_cloud_credentials , run_id = run_id , wait_for = wait_for , ) run_data = await run_data_future . result () run_status_code = run_data . get ( \"status\" ) if DbtCloudJobRunStatus . is_terminal_status_code ( run_status_code ): return DbtCloudJobRunStatus ( run_status_code ), run_data wait_for = [ run_data_future ] logger . debug ( \"dbt Cloud job run with ID %i has status %s . Waiting for %i seconds.\" , run_id , DbtCloudJobRunStatus ( run_status_code ) . name , poll_frequency_seconds , ) await asyncio . sleep ( poll_frequency_seconds ) seconds_waited_for_run_completion += poll_frequency_seconds raise DbtCloudJobRunTimedOut ( f \"Max wait time of { max_wait_seconds } seconds exceeded while waiting \" \"for job run with ID {run_id} \" )","title":"wait_for_dbt_cloud_job_run()"},{"location":"cloud/utils/","text":"prefect_dbt.cloud.utils Utilities for common interactions with the dbt Cloud API Classes DbtCloudAdministrativeApiCallFailed Bases: Exception Raised when a call to dbt Cloud administrative API fails. Source code in prefect_dbt/cloud/utils.py 44 45 class DbtCloudAdministrativeApiCallFailed ( Exception ): \"\"\"Raised when a call to dbt Cloud administrative API fails.\"\"\" Functions call_dbt_cloud_administrative_api_endpoint async Task that calls a specified endpoint in the dbt Cloud administrative API. Use this task if a prebuilt one is not yet available. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required path str The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. required http_method str HTTP method to call on the endpoint. required params Optional [ Dict [ str , Any ]] Query parameters to include in the request. None json Optional [ Dict [ str , Any ]] JSON serializable body to send in the request. None Returns: Type Description Any The body of the response. If the body is JSON serializable, then the result of json.loads with the body as the input will be returned. Otherwise, the body will be returned directly. Examples: List projects for an account: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def get_projects_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) result = call_dbt_cloud_administrative_api_endpoint ( dbt_cloud_credentials = credentials , path = \"/projects/\" , http_method = \"GET\" , ) return result [ \"data\" ] get_projects_flow () Create a new job: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def create_job_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) result = call_dbt_cloud_administrative_api_endpoint ( dbt_cloud_credentials = credentials , path = \"/jobs/\" , http_method = \"POST\" , json = { \"id\" : None , \"account_id\" : 123456789 , \"project_id\" : 100 , \"environment_id\" : 10 , \"name\" : \"Nightly run\" , \"dbt_version\" : None , \"triggers\" : { \"github_webhook\" : True , \"schedule\" : True }, \"execute_steps\" : [ \"dbt run\" , \"dbt test\" , \"dbt source snapshot-freshness\" ], \"settings\" : { \"threads\" : 4 , \"target_name\" : \"prod\" }, \"state\" : 1 , \"schedule\" : { \"date\" : { \"type\" : \"every_day\" }, \"time\" : { \"type\" : \"every_hour\" , \"interval\" : 1 }, }, }, ) return result [ \"data\" ] create_job_flow () Source code in prefect_dbt/cloud/utils.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 @task ( name = \"Call dbt Cloud administrative API endpoint\" , description = \"Calls a dbt Cloud administrative API endpoint\" , retries = 3 , retry_delay_seconds = 10 , ) async def call_dbt_cloud_administrative_api_endpoint ( dbt_cloud_credentials : DbtCloudCredentials , path : str , http_method : str , params : Optional [ Dict [ str , Any ]] = None , json : Optional [ Dict [ str , Any ]] = None , ) -> Any : \"\"\" Task that calls a specified endpoint in the dbt Cloud administrative API. Use this task if a prebuilt one is not yet available. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. path: The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. http_method: HTTP method to call on the endpoint. params: Query parameters to include in the request. json: JSON serializable body to send in the request. Returns: The body of the response. If the body is JSON serializable, then the result of `json.loads` with the body as the input will be returned. Otherwise, the body will be returned directly. Examples: List projects for an account: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def get_projects_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) result = call_dbt_cloud_administrative_api_endpoint( dbt_cloud_credentials=credentials, path=\"/projects/\", http_method=\"GET\", ) return result[\"data\"] get_projects_flow() ``` Create a new job: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def create_job_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) result = call_dbt_cloud_administrative_api_endpoint( dbt_cloud_credentials=credentials, path=\"/jobs/\", http_method=\"POST\", json={ \"id\": None, \"account_id\": 123456789, \"project_id\": 100, \"environment_id\": 10, \"name\": \"Nightly run\", \"dbt_version\": None, \"triggers\": {\"github_webhook\": True, \"schedule\": True}, \"execute_steps\": [\"dbt run\", \"dbt test\", \"dbt source snapshot-freshness\"], \"settings\": {\"threads\": 4, \"target_name\": \"prod\"}, \"state\": 1, \"schedule\": { \"date\": {\"type\": \"every_day\"}, \"time\": {\"type\": \"every_hour\", \"interval\": 1}, }, }, ) return result[\"data\"] create_job_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . call_endpoint ( http_method = http_method , path = path , params = params , json = json ) except HTTPStatusError as ex : raise DbtCloudAdministrativeApiCallFailed ( extract_developer_message ( ex )) from ex try : return response . json () except JSONDecodeError : return response . text extract_developer_message Extracts developer message from a error response from the dbt Cloud administrative API. Parameters: Name Type Description Default ex HTTPStatusError An HTTPStatusError raised by httpx required Returns: Type Description Optional [ str ] developer_message from dbt Cloud administrative API response or None if a Optional [ str ] developer_message cannot be extracted Source code in prefect_dbt/cloud/utils.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def extract_developer_message ( ex : HTTPStatusError ) -> Optional [ str ]: \"\"\" Extracts developer message from a error response from the dbt Cloud administrative API. Args: ex: An HTTPStatusError raised by httpx Returns: developer_message from dbt Cloud administrative API response or None if a developer_message cannot be extracted \"\"\" response_payload = ex . response . json () status = response_payload . get ( \"status\" , {}) return status . get ( \"developer_message\" ) extract_user_message Extracts user message from a error response from the dbt Cloud administrative API. Parameters: Name Type Description Default ex HTTPStatusError An HTTPStatusError raised by httpx required Returns: Type Description Optional [ str ] user_message from dbt Cloud administrative API response or None if a Optional [ str ] user_message cannot be extracted Source code in prefect_dbt/cloud/utils.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def extract_user_message ( ex : HTTPStatusError ) -> Optional [ str ]: \"\"\" Extracts user message from a error response from the dbt Cloud administrative API. Args: ex: An HTTPStatusError raised by httpx Returns: user_message from dbt Cloud administrative API response or None if a user_message cannot be extracted \"\"\" response_payload = ex . response . json () status = response_payload . get ( \"status\" , {}) return status . get ( \"user_message\" )","title":"Utils"},{"location":"cloud/utils/#prefect_dbt.cloud.utils","text":"Utilities for common interactions with the dbt Cloud API","title":"utils"},{"location":"cloud/utils/#prefect_dbt.cloud.utils-classes","text":"","title":"Classes"},{"location":"cloud/utils/#prefect_dbt.cloud.utils.DbtCloudAdministrativeApiCallFailed","text":"Bases: Exception Raised when a call to dbt Cloud administrative API fails. Source code in prefect_dbt/cloud/utils.py 44 45 class DbtCloudAdministrativeApiCallFailed ( Exception ): \"\"\"Raised when a call to dbt Cloud administrative API fails.\"\"\"","title":"DbtCloudAdministrativeApiCallFailed"},{"location":"cloud/utils/#prefect_dbt.cloud.utils-functions","text":"","title":"Functions"},{"location":"cloud/utils/#prefect_dbt.cloud.utils.call_dbt_cloud_administrative_api_endpoint","text":"Task that calls a specified endpoint in the dbt Cloud administrative API. Use this task if a prebuilt one is not yet available. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required path str The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. required http_method str HTTP method to call on the endpoint. required params Optional [ Dict [ str , Any ]] Query parameters to include in the request. None json Optional [ Dict [ str , Any ]] JSON serializable body to send in the request. None Returns: Type Description Any The body of the response. If the body is JSON serializable, then the result of json.loads with the body as the input will be returned. Otherwise, the body will be returned directly. Examples: List projects for an account: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def get_projects_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) result = call_dbt_cloud_administrative_api_endpoint ( dbt_cloud_credentials = credentials , path = \"/projects/\" , http_method = \"GET\" , ) return result [ \"data\" ] get_projects_flow () Create a new job: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def create_job_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) result = call_dbt_cloud_administrative_api_endpoint ( dbt_cloud_credentials = credentials , path = \"/jobs/\" , http_method = \"POST\" , json = { \"id\" : None , \"account_id\" : 123456789 , \"project_id\" : 100 , \"environment_id\" : 10 , \"name\" : \"Nightly run\" , \"dbt_version\" : None , \"triggers\" : { \"github_webhook\" : True , \"schedule\" : True }, \"execute_steps\" : [ \"dbt run\" , \"dbt test\" , \"dbt source snapshot-freshness\" ], \"settings\" : { \"threads\" : 4 , \"target_name\" : \"prod\" }, \"state\" : 1 , \"schedule\" : { \"date\" : { \"type\" : \"every_day\" }, \"time\" : { \"type\" : \"every_hour\" , \"interval\" : 1 }, }, }, ) return result [ \"data\" ] create_job_flow () Source code in prefect_dbt/cloud/utils.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 @task ( name = \"Call dbt Cloud administrative API endpoint\" , description = \"Calls a dbt Cloud administrative API endpoint\" , retries = 3 , retry_delay_seconds = 10 , ) async def call_dbt_cloud_administrative_api_endpoint ( dbt_cloud_credentials : DbtCloudCredentials , path : str , http_method : str , params : Optional [ Dict [ str , Any ]] = None , json : Optional [ Dict [ str , Any ]] = None , ) -> Any : \"\"\" Task that calls a specified endpoint in the dbt Cloud administrative API. Use this task if a prebuilt one is not yet available. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. path: The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. http_method: HTTP method to call on the endpoint. params: Query parameters to include in the request. json: JSON serializable body to send in the request. Returns: The body of the response. If the body is JSON serializable, then the result of `json.loads` with the body as the input will be returned. Otherwise, the body will be returned directly. Examples: List projects for an account: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def get_projects_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) result = call_dbt_cloud_administrative_api_endpoint( dbt_cloud_credentials=credentials, path=\"/projects/\", http_method=\"GET\", ) return result[\"data\"] get_projects_flow() ``` Create a new job: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def create_job_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) result = call_dbt_cloud_administrative_api_endpoint( dbt_cloud_credentials=credentials, path=\"/jobs/\", http_method=\"POST\", json={ \"id\": None, \"account_id\": 123456789, \"project_id\": 100, \"environment_id\": 10, \"name\": \"Nightly run\", \"dbt_version\": None, \"triggers\": {\"github_webhook\": True, \"schedule\": True}, \"execute_steps\": [\"dbt run\", \"dbt test\", \"dbt source snapshot-freshness\"], \"settings\": {\"threads\": 4, \"target_name\": \"prod\"}, \"state\": 1, \"schedule\": { \"date\": {\"type\": \"every_day\"}, \"time\": {\"type\": \"every_hour\", \"interval\": 1}, }, }, ) return result[\"data\"] create_job_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . call_endpoint ( http_method = http_method , path = path , params = params , json = json ) except HTTPStatusError as ex : raise DbtCloudAdministrativeApiCallFailed ( extract_developer_message ( ex )) from ex try : return response . json () except JSONDecodeError : return response . text","title":"call_dbt_cloud_administrative_api_endpoint()"},{"location":"cloud/utils/#prefect_dbt.cloud.utils.extract_developer_message","text":"Extracts developer message from a error response from the dbt Cloud administrative API. Parameters: Name Type Description Default ex HTTPStatusError An HTTPStatusError raised by httpx required Returns: Type Description Optional [ str ] developer_message from dbt Cloud administrative API response or None if a Optional [ str ] developer_message cannot be extracted Source code in prefect_dbt/cloud/utils.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def extract_developer_message ( ex : HTTPStatusError ) -> Optional [ str ]: \"\"\" Extracts developer message from a error response from the dbt Cloud administrative API. Args: ex: An HTTPStatusError raised by httpx Returns: developer_message from dbt Cloud administrative API response or None if a developer_message cannot be extracted \"\"\" response_payload = ex . response . json () status = response_payload . get ( \"status\" , {}) return status . get ( \"developer_message\" )","title":"extract_developer_message()"},{"location":"cloud/utils/#prefect_dbt.cloud.utils.extract_user_message","text":"Extracts user message from a error response from the dbt Cloud administrative API. Parameters: Name Type Description Default ex HTTPStatusError An HTTPStatusError raised by httpx required Returns: Type Description Optional [ str ] user_message from dbt Cloud administrative API response or None if a Optional [ str ] user_message cannot be extracted Source code in prefect_dbt/cloud/utils.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def extract_user_message ( ex : HTTPStatusError ) -> Optional [ str ]: \"\"\" Extracts user message from a error response from the dbt Cloud administrative API. Args: ex: An HTTPStatusError raised by httpx Returns: user_message from dbt Cloud administrative API response or None if a user_message cannot be extracted \"\"\" response_payload = ex . response . json () status = response_payload . get ( \"status\" , {}) return status . get ( \"user_message\" )","title":"extract_user_message()"}]}