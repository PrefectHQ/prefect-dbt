{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Coordinate and use dbt in your dataflow with prefect-dbt","text":"<p>With prefect-dbt, you can easily trigger and monitor dbt Cloud jobs, execute dbt Core CLI commands, and incorporate other services, like Snowflake, into your dbt runs!</p> <p>Check out the examples below to get started!</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Be sure to install prefect-dbt and save a block to run the examples below!</p>"},{"location":"#integrate-dbt-cloud-jobs-with-prefect-flows","title":"Integrate dbt Cloud jobs with Prefect flows","text":"<p>If you have an existing dbt Cloud job, take advantage of the flow, <code>run_dbt_cloud_job</code>.</p> <p>This flow triggers the job and waits until the job run is finished.</p> <p>If certain nodes fail, <code>run_dbt_cloud_job</code> efficiently retries the specific, unsuccessful nodes.</p> <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudJob\nfrom prefect_dbt.cloud.jobs import run_dbt_cloud_job\n\n@flow\ndef run_dbt_job_flow():\n    result = run_dbt_cloud_job(\n        dbt_cloud_job=DbtCloudJob.load(\"my-block-name\"),\n        targeted_retries=5,\n    )\n    return result\n\nrun_dbt_job_flow()\n</code></pre>"},{"location":"#integrate-dbt-core-cli-commands-with-prefect-flows","title":"Integrate dbt Core CLI commands with Prefect flows","text":"<p><code>prefect-dbt</code> also supports execution of dbt Core CLI commands.</p> <p>To get started, if you don't have a <code>DbtCoreOperation</code> block already saved, set the commands that you want to run; it can include a mix of dbt and non-dbt commands.</p> <p>Then, optionally specify the <code>project_dir</code>.</p> <p>If <code>profiles_dir</code> is unset, it will try to use the <code>DBT_PROFILES_DIR</code> environment variable. If that's also not set, it will use the default directory <code>$HOME/.dbt/</code>.</p>"},{"location":"#using-an-existing-profile","title":"Using an existing profile","text":"<p>If you already have an existing dbt profile, specify the <code>profiles_dir</code> where <code>profiles.yml</code> is located.</p> <pre><code>from prefect import flow\nfrom prefect_dbt.cli.commands import DbtCoreOperation\n\n@flow\ndef trigger_dbt_flow() -&gt; str:\n    result = DbtCoreOperation(\n        commands=[\"pwd\", \"dbt debug\", \"dbt run\"],\n        project_dir=\"PROJECT-DIRECTORY-PLACEHOLDER\",\n        profiles_dir=\"PROFILES-DIRECTORY-PLACEHOLDER\"\n    ).run()\n    return result\n\ntrigger_dbt_flow()\n</code></pre>"},{"location":"#writing-a-new-profile","title":"Writing a new profile","text":"<p>To setup a new profile, first save and load a DbtCliProfile block and use it in <code>DbtCoreOperation</code>.</p> <p>Then, specify <code>profiles_dir</code> where <code>profiles.yml</code> will be written.</p> <pre><code>from prefect import flow\nfrom prefect_dbt.cli import DbtCliProfile, DbtCoreOperation\n\n@flow\ndef trigger_dbt_flow():\n    dbt_cli_profile = DbtCliProfile.load(\"DBT-CORE-OPERATION-BLOCK-NAME-PLACEHOLDER\")\n    with DbtCoreOperation(\n        commands=[\"dbt debug\", \"dbt run\"],\n        project_dir=\"PROJECT-DIRECTORY-PLACEHOLDER\",\n        profiles_dir=\"PROFILES-DIRECTORY-PLACEHOLDER\",\n        dbt_cli_profile=dbt_cli_profile,\n    ) as dbt_operation:\n        dbt_process = dbt_operation.trigger()\n        # do other things before waiting for completion\n        dbt_process.wait_for_completion()\n        result = dbt_process.fetch_result()\n    return result\n\ntrigger_dbt_flow()\n</code></pre>"},{"location":"#resources","title":"Resources","text":"<p>If you need help getting started with or using dbt, please consult the dbt documentation.</p>"},{"location":"#installation","title":"Installation","text":"<p>To use <code>prefect-dbt</code> with dbt Cloud:</p> <pre><code>pip install prefect-dbt\n</code></pre> <p>To use dbt Core (CLI):</p> <pre><code>pip install \"prefect-dbt[cli]\"\n</code></pre> <p>To use dbt Core with Snowflake profiles:</p> <pre><code>pip install \"prefect-dbt[snowflake]\"\n</code></pre> <p>To use dbt Core with BigQuery profiles:</p> <pre><code>pip install \"prefect-dbt[bigquery]\"\n</code></pre> <p>To use dbt Core with Postgres profiles:</p> <pre><code>pip install \"prefect-dbt[postgres]\"\n</code></pre> <p>Some dbt Core profiles require additional installation</p> <p>According to dbt's Databricks setup page, users must first install the adapter:</p> <pre><code>pip install dbt-databricks\n</code></pre> <p>Check out the desired profile setup page on the sidebar for others.</p> <p>Requires an installation of Python 3.7+.</p> <p>We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv.</p> <p>These tasks are designed to work with Prefect 2. For more information about how to use Prefect, please refer to the Prefect documentation.</p>"},{"location":"#saving-credentials-to-block","title":"Saving credentials to block","text":"<p>Note, to use the <code>load</code> method on Blocks, you must already have a block document saved through code or saved through the UI.</p> <p>Registering blocks</p> <p>Register blocks in this module to view and edit them on Prefect Cloud:</p> <pre><code>prefect block register -m prefect_dbt\n</code></pre> <p>A list of available blocks in <code>prefect-dbt</code> and their setup instructions can be found here.</p>"},{"location":"#dbt-cloud","title":"dbt Cloud","text":"<p>To create a dbt Cloud credentials block:</p> <ol> <li>Head over to your dbt Cloud profile.</li> <li>Login to your dbt Cloud account.</li> <li>Scroll down to \"API\" or click \"API Access\" on the sidebar.</li> <li>Copy the API Key.</li> <li>Click Projects on the sidebar.</li> <li>Copy the account ID from the URL: <code>https://cloud.getdbt.com/settings/accounts/&lt;ACCOUNT_ID&gt;</code>.</li> <li>Create a short script, replacing the placeholders.</li> </ol> <pre><code>from prefect_dbt.cloud import DbtCloudCredentials\n\nDbtCloudCredentials(\n    api_key=\"API-KEY-PLACEHOLDER\",\n    account_id=\"ACCOUNT-ID-PLACEHOLDER\"\n).save(\"CREDENTIALS-BLOCK-NAME-PLACEHOLDER\")\n</code></pre> <p>Then, to create a dbt Cloud job block:</p> <ol> <li>Head over to your dbt home page.</li> <li>On the top nav bar, click on Deploy -&gt; Jobs.</li> <li>Select a job.</li> <li>Copy the job ID from the URL: <code>https://cloud.getdbt.com/deploy/&lt;ACCOUNT_ID&gt;/projects/&lt;PROJECT_ID&gt;/jobs/&lt;JOB_ID&gt;</code></li> <li>Create a short script, replacing the placeholders.</li> </ol> <pre><code>from prefect_dbt.cloud import DbtCloudCredentials, DbtCloudJob\n\ndbt_cloud_credentials = DbtCloudCredentials.load(\"CREDENTIALS-BLOCK-NAME-PLACEHOLDER\")\ndbt_cloud_job = DbtCloudJob(\n    dbt_cloud_credentials=dbt_cloud_credentials,\n    job_id=\"JOB-ID-PLACEHOLDER\"\n).save(\"JOB-BLOCK-NAME-PLACEHOLDER\")\n</code></pre> <p>Congrats! You can now easily load the saved block, which holds your credentials:</p> <pre><code>from prefect_dbt.cloud import DbtCloudJob\n\nDbtCloudJob.load(\"JOB-BLOCK-NAME-PLACEHOLDER\")\n</code></pre>"},{"location":"#dbt-core-cli","title":"dbt Core CLI","text":"<p>Available <code>TargetConfigs</code> blocks</p> <p>The following may vary slightly depending on the service you want to incorporate.</p> <p>Visit the API Reference to see other built-in <code>TargetConfigs</code> blocks.</p> <p>If the desired service profile is not available, check out the Examples Catalog to see how you can build one from the generic <code>TargetConfigs</code> class.</p> <p>To create dbt Core target config and profile blocks for BigQuery:</p> <ol> <li>Save and load a <code>GcpCredentials</code> block.</li> <li>Determine the schema / dataset you want to use in BigQuery.</li> <li>Create a short script, replacing the placeholders.</li> </ol> <pre><code>from prefect_gcp.credentials import GcpCredentials\nfrom prefect_dbt.cli import BigQueryTargetConfigs, DbtCliProfile\n\ncredentials = GcpCredentials.load(\"CREDENTIALS-BLOCK-NAME-PLACEHOLDER\")\ntarget_configs = BigQueryTargetConfigs(\n    schema=\"SCHEMA-NAME-PLACEHOLDER\",  # also known as dataset\n    credentials=credentials,\n)\ntarget_configs.save(\"TARGET-CONFIGS-BLOCK-NAME-PLACEHOLDER\")\n\ndbt_cli_profile = DbtCliProfile(\n    name=\"PROFILE-NAME-PLACEHOLDER\",\n    target=\"TARGET-NAME-placeholder\",\n    target_configs=target_configs,\n)\ndbt_cli_profile.save(\"DBT-CLI-PROFILE-BLOCK-NAME-PLACEHOLDER\")\n</code></pre> <p>Then, to create a dbt Core operation block:</p> <ol> <li>Determine the dbt commands you want to run.</li> <li>Create a short script, replacing the placeholders.</li> </ol> <pre><code>from prefect_dbt.cli import DbtCliProfile, DbtCoreOperation\n\ndbt_cli_profile = DbtCliProfile.load(\"DBT-CLI-PROFILE-BLOCK-NAME-PLACEHOLDER\")\ndbt_core_operation = DbtCoreOperation(\n    commands=[\"DBT-CLI-COMMANDS-PLACEHOLDER\"],\n    dbt_cli_profile=dbt_cli_profile,\n    overwrite_profiles=True,\n)\ndbt_core_operation.save(\"DBT-CORE-OPERATION-BLOCK-NAME-PLACEHOLDER\")\n</code></pre> <p>Congrats! You can now easily load the saved block, which holds your credentials:</p> <pre><code>from prefect_dbt.cloud import DbtCoreOperation\n\nDbtCoreOperation.load(\"DBT-CORE-OPERATION-BLOCK-NAME-PLACEHOLDER\")\n</code></pre>"},{"location":"#feedback","title":"Feedback","text":"<p>If you encounter any bugs while using <code>prefect-dbt</code>, feel free to open an issue in the prefect-dbt repository.</p> <p>If you have any questions or issues while using <code>prefect-dbt</code>, you can find help in either the Prefect Discourse forum or the Prefect Slack community.</p> <p>Feel free to star or watch <code>prefect-dbt</code> for updates too!</p>"},{"location":"#contributing","title":"Contributing","text":"<p>If you'd like to help contribute to fix an issue or add a feature to <code>prefect-dbt</code>, please propose changes through a pull request from a fork of the repository.</p> <p>Here are the steps:</p> <ol> <li>Fork the repository</li> <li>Clone the forked repository</li> <li>Install the repository and its dependencies: <pre><code>pip install -e \".[dev]\"\n</code></pre></li> <li>Make desired changes</li> <li>Add tests</li> <li>Insert an entry to CHANGELOG.md</li> <li>Install <code>pre-commit</code> to perform quality checks prior to commit: <pre><code>pre-commit install\n</code></pre></li> <li><code>git commit</code>, <code>git push</code>, and create a pull request</li> </ol>"},{"location":"blocks_catalog/","title":"Blocks Catalog","text":"<p>Below is a list of Blocks available for registration in <code>prefect-dbt</code>.</p> <p>To register blocks in this module to view and edit them on Prefect Cloud, first install the required packages, then <pre><code>prefect block register -m prefect_dbt\n</code></pre> Note, to use the <code>load</code> method on Blocks, you must already have a block document saved through code or saved through the UI.</p>"},{"location":"blocks_catalog/#cloudcredentials-module","title":"Cloud.Credentials Module","text":"<p>DbtCloudCredentials</p> <p>Credentials block for credential use across dbt Cloud tasks and flows.</p> <p>To load the DbtCloudCredentials: <pre><code>from prefect import flow\nfrom prefect_dbt.cloud.credentials import DbtCloudCredentials\n\n@flow\ndef my_flow():\n    my_block = DbtCloudCredentials.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cloud.Credentials Module under Examples Catalog.</p>"},{"location":"blocks_catalog/#cloudjobs-module","title":"Cloud.Jobs Module","text":"<p>DbtCloudJob</p> <p>Block that holds the information and methods to interact with a dbt Cloud job.</p> <p>To load the DbtCloudJob: <pre><code>from prefect import flow\nfrom prefect_dbt.cloud.jobs import DbtCloudJob\n\n@flow\ndef my_flow():\n    my_block = DbtCloudJob.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cloud.Jobs Module under Examples Catalog.</p>"},{"location":"blocks_catalog/#cliconfigsbase-module","title":"Cli.Configs.Base Module","text":"<p>TargetConfigs</p> <p>Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink.</p> <p>To load the TargetConfigs: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.configs.base import TargetConfigs\n\n@flow\ndef my_flow():\n    my_block = TargetConfigs.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> GlobalConfigs</p> <p>Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Docs can be found here.</p> <p>To load the GlobalConfigs: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.configs.base import GlobalConfigs\n\n@flow\ndef my_flow():\n    my_block = GlobalConfigs.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cli.Configs.Base Module under Examples Catalog.</p>"},{"location":"blocks_catalog/#cliconfigssnowflake-module","title":"Cli.Configs.Snowflake Module","text":"<p>SnowflakeTargetConfigs</p> <p>Target configs contain credentials and settings, specific to Snowflake. To find valid keys, head to the Snowflake Profile page.</p> <p>To load the SnowflakeTargetConfigs: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.configs.snowflake import SnowflakeTargetConfigs\n\n@flow\ndef my_flow():\n    my_block = SnowflakeTargetConfigs.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cli.Configs.Snowflake Module under Examples Catalog.</p>"},{"location":"blocks_catalog/#cliconfigsbigquery-module","title":"Cli.Configs.Bigquery Module","text":"<p>BigQueryTargetConfigs</p> <p>dbt CLI target configs containing credentials and settings, specific to BigQuery.</p> <p>To load the BigQueryTargetConfigs: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.configs.bigquery import BigQueryTargetConfigs\n\n@flow\ndef my_flow():\n    my_block = BigQueryTargetConfigs.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cli.Configs.Bigquery Module under Examples Catalog.</p>"},{"location":"blocks_catalog/#cliconfigspostgres-module","title":"Cli.Configs.Postgres Module","text":"<p>PostgresTargetConfigs</p> <p>dbt CLI target configs containing credentials and settings specific to Postgres.</p> <p>To load the PostgresTargetConfigs: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.configs.postgres import PostgresTargetConfigs\n\n@flow\ndef my_flow():\n    my_block = PostgresTargetConfigs.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cli.Configs.Postgres Module under Examples Catalog.</p>"},{"location":"blocks_catalog/#clicredentials-module","title":"Cli.Credentials Module","text":"<p>DbtCliProfile</p> <p>Profile for use across dbt CLI tasks and flows.</p> <p>To load the DbtCliProfile: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.credentials import DbtCliProfile\n\n@flow\ndef my_flow():\n    my_block = DbtCliProfile.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cli.Credentials Module under Examples Catalog.</p>"},{"location":"blocks_catalog/#clicommands-module","title":"Cli.Commands Module","text":"<p>DbtCoreOperation</p> <p>A block representing a dbt operation, containing multiple dbt and shell commands.</p> <p>For long-lasting operations, use the trigger method and utilize the block as a context manager for automatic closure of processes when context is exited. If not, manually call the close method to close processes.</p> <p>For short-lasting operations, use the run method. Context is automatically managed with this method.</p> <p>To load the DbtCoreOperation: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.commands import DbtCoreOperation\n\n@flow\ndef my_flow():\n    my_block = DbtCoreOperation.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cli.Commands Module under Examples Catalog.</p>"},{"location":"examples_catalog/","title":"Examples Catalog","text":"<p>Below is a list of examples for <code>prefect-dbt</code>.</p>"},{"location":"examples_catalog/#clicommands-module","title":"Cli.Commands Module","text":"<p>Execute <code>dbt debug</code> with a pre-populated profiles.yml. <pre><code>from prefect import flow\nfrom prefect_dbt.cli.commands import trigger_dbt_cli_command\n\n@flow\ndef trigger_dbt_cli_command_flow():\n    result = trigger_dbt_cli_command(\"dbt debug\")\n    return result\n\ntrigger_dbt_cli_command_flow()\n</code></pre></p> <p>Execute <code>dbt debug</code> without a pre-populated profiles.yml. <pre><code>from prefect import flow\nfrom prefect_dbt.cli.credentials import DbtCliProfile\nfrom prefect_dbt.cli.commands import trigger_dbt_cli_command\nfrom prefect_dbt.cli.configs import SnowflakeTargetConfigs\nfrom prefect_snowflake.credentials import SnowflakeCredentials\n\n@flow\ndef trigger_dbt_cli_command_flow():\n    credentials = SnowflakeCredentials(\n        user=\"user\",\n        password=\"password\",\n        account=\"account.region.aws\",\n        role=\"role\",\n    )\n    connector = SnowflakeConnector(\n        schema=\"public\",\n        database=\"database\",\n        warehouse=\"warehouse\",\n        credentials=credentials,\n    )\n    target_configs = SnowflakeTargetConfigs(\n        connector=connector\n    )\n    dbt_cli_profile = DbtCliProfile(\n        name=\"jaffle_shop\",\n        target=\"dev\",\n        target_configs=target_configs,\n    )\n    result = trigger_dbt_cli_command(\n        \"dbt debug\",\n        overwrite_profiles=True,\n        dbt_cli_profile=dbt_cli_profile\n    )\n    return result\n\ntrigger_dbt_cli_command_flow()\n</code></pre> Load a configured block. <pre><code>from prefect_dbt import DbtCoreOperation\n\ndbt_op = DbtCoreOperation.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Execute short-lasting dbt debug and list with a custom DbtCliProfile. <pre><code>from prefect_dbt import DbtCoreOperation, DbtCliProfile\nfrom prefect_dbt.cli.configs import SnowflakeTargetConfigs\nfrom prefect_snowflake import SnowflakeConnector\n\nsnowflake_connector = await SnowflakeConnector.load(\"snowflake-connector\")\ntarget_configs = SnowflakeTargetConfigs(connector=snowflake_connector)\ndbt_cli_profile = DbtCliProfile(\n    name=\"jaffle_shop\",\n    target=\"dev\",\n    target_configs=target_configs,\n)\ndbt_init = DbtCoreOperation(\n    commands=[\"dbt debug\", \"dbt list\"],\n    dbt_cli_profile=dbt_cli_profile,\n    overwrite_profiles=True\n)\ndbt_init.run()\n</code></pre></p> <p>Execute a longer-lasting dbt run as a context manager. <pre><code>with DbtCoreOperation(commands=[\"dbt run\"]) as dbt_run:\n    dbt_process = dbt_run.trigger()\n    # do other things\n    dbt_process.wait_for_completion()\n    dbt_output = dbt_process.fetch_result()\n</code></pre></p>"},{"location":"examples_catalog/#clicredentials-module","title":"Cli.Credentials Module","text":"<p>Load stored dbt CLI profile: <pre><code>from prefect_dbt.cli import DbtCliProfile\ndbt_cli_profile = DbtCliProfile.load(\"BLOCK_NAME\").get_profile()\n</code></pre></p> <p>Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs: <pre><code>from prefect_dbt.cli import DbtCliProfile\nfrom prefect_dbt.cli.configs import SnowflakeTargetConfigs\nfrom prefect_snowflake.credentials import SnowflakeCredentials\nfrom prefect_snowflake.database import SnowflakeConnector\n\ncredentials = SnowflakeCredentials(\n    user=\"user\",\n    password=\"password\",\n    account=\"account.region.aws\",\n    role=\"role\",\n)\nconnector = SnowflakeConnector(\n    schema=\"public\",\n    database=\"database\",\n    warehouse=\"warehouse\",\n    credentials=credentials,\n)\ntarget_configs = SnowflakeTargetConfigs(\n    connector=connector\n)\ndbt_cli_profile = DbtCliProfile(\n    name=\"jaffle_shop\",\n    target=\"dev\",\n    target_configs=target_configs,\n)\nprofile = dbt_cli_profile.get_profile()\n</code></pre></p> <p>Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs: <pre><code>from prefect_dbt.cli import DbtCliProfile\nfrom prefect_dbt.cli.configs import GlobalConfigs, TargetConfigs\n\ntarget_configs_extras = dict(\n    host=\"hostname.region.redshift.amazonaws.com\",\n    user=\"username\",\n    password=\"password1\",\n    port=5439,\n    dbname=\"analytics\",\n)\ntarget_configs = TargetConfigs(\n    type=\"redshift\",\n    schema=\"schema\",\n    threads=4,\n    extras=target_configs_extras\n)\ndbt_cli_profile = DbtCliProfile(\n    name=\"jaffle_shop\",\n    target=\"dev\",\n    target_configs=target_configs,\n)\nprofile = dbt_cli_profile.get_profile()\n</code></pre></p>"},{"location":"examples_catalog/#cloudcredentials-module","title":"Cloud.Credentials Module","text":"<p>Sending queries via the returned metadata client: <pre><code>from prefect_dbt import DbtCloudCredentials\n\ncredentials_block = DbtCloudCredentials.load(\"test-account\")\nmetadata_client = credentials_block.get_metadata_client()\nquery = \"\"\"\n{\n    metrics(jobId: 123) {\n        uniqueId\n        name\n        packageName\n        tags\n        label\n        runId\n        description\n        type\n        sql\n        timestamp\n        timeGrains\n        dimensions\n        meta\n        resourceType\n        filters {\n            field\n            operator\n            value\n        }\n        model {\n            name\n        }\n    }\n}\n\"\"\"\nmetadata_client.query(query)\n# Result:\n# {\n#   \"data\": {\n#     \"metrics\": [\n#       {\n#         \"uniqueId\": \"metric.tpch.total_revenue\",\n#         \"name\": \"total_revenue\",\n#         \"packageName\": \"tpch\",\n#         \"tags\": [],\n#         \"label\": \"Total Revenue ($)\",\n#         \"runId\": 108952046,\n#         \"description\": \"\",\n#         \"type\": \"sum\",\n#         \"sql\": \"net_item_sales_amount\",\n#         \"timestamp\": \"order_date\",\n#         \"timeGrains\": [\"day\", \"week\", \"month\"],\n#         \"dimensions\": [\"status_code\", \"priority_code\"],\n#         \"meta\": {},\n#         \"resourceType\": \"metric\",\n#         \"filters\": [],\n#         \"model\": { \"name\": \"fct_orders\" }\n#       }\n#     ]\n#   }\n# }\n</code></pre> Load stored dbt Cloud credentials: <pre><code>from prefect_dbt.cloud import DbtCloudCredentials\n\ndbt_cloud_credentials = DbtCloudCredentials.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Use DbtCloudCredentials instance to trigger a job run: <pre><code>from prefect_dbt.cloud import DbtCloudCredentials\n\ncredentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\nasync with dbt_cloud_credentials.get_administrative_client() as client:\n    client.trigger_job_run(job_id=1)\n</code></pre></p> <p>Load saved dbt Cloud credentials within a flow: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n\n\n@flow\ndef trigger_dbt_cloud_job_run_flow():\n    credentials = DbtCloudCredentials.load(\"my-dbt-credentials\")\n    trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1)\n\ntrigger_dbt_cloud_job_run_flow()\n</code></pre></p>"},{"location":"examples_catalog/#cloudjobs-module","title":"Cloud.Jobs Module","text":"<p>Get status of a dbt Cloud job: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import get_job\n\n@flow\ndef get_job_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    return get_job(\n        dbt_cloud_credentials=credentials,\n        job_id=42\n    )\n\nget_job_flow()\n</code></pre> Trigger a dbt Cloud job run: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n\n\n@flow\ndef trigger_dbt_cloud_job_run_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1)\n\n\ntrigger_dbt_cloud_job_run_flow()\n</code></pre></p> <p>Trigger a dbt Cloud job run with overrides: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\nfrom prefect_dbt.cloud.models import TriggerJobRunOptions\n\n\n@flow\ndef trigger_dbt_cloud_job_run_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    trigger_dbt_cloud_job_run(\n        dbt_cloud_credentials=credentials,\n        job_id=1,\n        options=TriggerJobRunOptions(\n            git_branch=\"staging\",\n            schema_override=\"dbt_cloud_pr_123\",\n            dbt_version_override=\"0.18.0\",\n            target_name_override=\"staging\",\n            timeout_seconds_override=3000,\n            generate_docs_override=True,\n            threads_override=8,\n            steps_override=[\n                \"dbt seed\",\n                \"dbt run --fail-fast\",\n                \"dbt test --fail-fast\",\n            ],\n        ),\n    )\n\n\ntrigger_dbt_cloud_job_run()\n</code></pre> <pre><code>from prefect import flow\nfrom prefect_dbt.cloud import DbtCloudCredentials, DbtCloudJob\nfrom prefect_dbt.cloud.jobs import run_dbt_cloud_job\n\n@flow\ndef run_dbt_cloud_job_flow():\n    dbt_cloud_credentials = DbtCloudCredentials.load(\"dbt-token\")\n    dbt_cloud_job = DbtCloudJob(\n        dbt_cloud_credentials=dbt_cloud_credentials, job_id=154217\n    )\n    return run_dbt_cloud_job(dbt_cloud_job=dbt_cloud_job)\n\nrun_dbt_cloud_job_flow()\n</code></pre> Load a configured dbt Cloud job block. <pre><code>from prefect_dbt.cloud import DbtCloudJob\n\ndbt_cloud_job = DbtCloudJob.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Triggers a dbt Cloud job, waits for completion, and fetches the results. <pre><code>from prefect import flow\nfrom prefect_dbt.cloud import DbtCloudCredentials, DbtCloudJob\n\n@flow\ndef dbt_cloud_job_flow():\n    dbt_cloud_credentials = DbtCloudCredentials.load(\"dbt-token\")\n    dbt_cloud_job = DbtCloudJob.load(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        job_id=154217\n    )\n    dbt_cloud_job_run = dbt_cloud_job.trigger()\n    dbt_cloud_job_run.wait_for_completion()\n    dbt_cloud_job_run.fetch_result()\n    return dbt_cloud_job_run\n\ndbt_cloud_job_flow()\n</code></pre> Retry a subset of models in a dbt Cloud job run and wait for completion: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import retry_dbt_cloud_job_run_subset_and_wait_for_completion\n\n@flow\ndef retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow():\n    credentials = DbtCloudCredentials.load(\"MY_BLOCK_NAME\")\n    retry_dbt_cloud_job_run_subset_and_wait_for_completion(\n        dbt_cloud_credentials=credentials,\n        run_id=88640123,\n    )\n\nretry_dbt_cloud_job_run_subset_and_wait_for_completion_flow()\n</code></pre> <pre><code>from prefect import flow\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run, get_run_id\n\n\n@flow\ndef trigger_run_and_get_id():\n    dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        )\n\n    triggered_run_data = trigger_dbt_cloud_job_run(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        job_id=job_id,\n        options=trigger_job_run_options,\n    )\n    run_id = get_run_id.submit(triggered_run_data)\n    return run_id\n\ntrigger_run_and_get_id()\n</code></pre> Trigger a dbt Cloud job and wait for completion as a stand alone flow: <pre><code>import asyncio\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n\nasyncio.run(\n    trigger_dbt_cloud_job_run_and_wait_for_completion(\n        dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        ),\n        job_id=1\n    )\n)\n</code></pre></p> <p>Trigger a dbt Cloud job and wait for completion as a sub-flow: <pre><code>from prefect import flow\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n\n@flow\ndef my_flow():\n    ...\n    run_result = trigger_dbt_cloud_job_run_and_wait_for_completion(\n        dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        ),\n        job_id=1\n    )\n    ...\n\nmy_flow()\n</code></pre></p> <p>Trigger a dbt Cloud job with overrides: <pre><code>import asyncio\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\nfrom prefect_dbt.cloud.models import TriggerJobRunOptions\n\nasyncio.run(\n    trigger_dbt_cloud_job_run_and_wait_for_completion(\n        dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        ),\n        job_id=1,\n        trigger_job_run_options=TriggerJobRunOptions(\n            git_branch=\"staging\",\n            schema_override=\"dbt_cloud_pr_123\",\n            dbt_version_override=\"0.18.0\",\n            target_name_override=\"staging\",\n            timeout_seconds_override=3000,\n            generate_docs_override=True,\n            threads_override=8,\n            steps_override=[\n                \"dbt seed\",\n                \"dbt run --fail-fast\",\n                \"dbt test --fail fast\",\n            ],\n        ),\n    )\n)\n</code></pre></p>"},{"location":"examples_catalog/#cloudruns-module","title":"Cloud.Runs Module","text":"<p>Get an artifact of a dbt Cloud job run: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact\n\n@flow\ndef get_artifact_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    return get_dbt_cloud_run_artifact(\n        dbt_cloud_credentials=credentials,\n        run_id=42,\n        path=\"manifest.json\"\n    )\n\nget_artifact_flow()\n</code></pre></p> <p>Get an artifact of a dbt Cloud job run and write it to a file: <pre><code>import json\n\nfrom prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact\n\n@flow\ndef get_artifact_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    get_run_artifact_result = get_dbt_cloud_run_artifact(\n        dbt_cloud_credentials=credentials,\n        run_id=42,\n        path=\"manifest.json\"\n    )\n\n    with open(\"manifest.json\", \"w\") as file:\n        json.dump(get_run_artifact_result, file)\n\nget_artifact_flow()\n</code></pre> List artifacts of a dbt Cloud job run: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts\n\n@flow\ndef list_artifacts_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    return list_dbt_cloud_run_artifacts(\n        dbt_cloud_credentials=credentials,\n        run_id=42\n    )\n\nlist_artifacts_flow()\n</code></pre> Get status of a dbt Cloud job run: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import get_run\n\n@flow\ndef get_run_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    return get_run(\n        dbt_cloud_credentials=credentials,\n        run_id=42\n    )\n\nget_run_flow()\n</code></pre></p>"},{"location":"examples_catalog/#cloudutils-module","title":"Cloud.Utils Module","text":"<p>List projects for an account: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint\n\n@flow\ndef get_projects_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    result = call_dbt_cloud_administrative_api_endpoint(\n        dbt_cloud_credentials=credentials,\n        path=\"/projects/\",\n        http_method=\"GET\",\n    )\n    return result[\"data\"]\n\nget_projects_flow()\n</code></pre></p> <p>Create a new job: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint\n\n\n@flow\ndef create_job_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    result = call_dbt_cloud_administrative_api_endpoint(\n        dbt_cloud_credentials=credentials,\n        path=\"/jobs/\",\n        http_method=\"POST\",\n        json={\n            \"id\": None,\n            \"account_id\": 123456789,\n            \"project_id\": 100,\n            \"environment_id\": 10,\n            \"name\": \"Nightly run\",\n            \"dbt_version\": None,\n            \"triggers\": {\"github_webhook\": True, \"schedule\": True},\n            \"execute_steps\": [\"dbt run\", \"dbt test\", \"dbt source snapshot-freshness\"],\n            \"settings\": {\"threads\": 4, \"target_name\": \"prod\"},\n            \"state\": 1,\n            \"schedule\": {\n                \"date\": {\"type\": \"every_day\"},\n                \"time\": {\"type\": \"every_hour\", \"interval\": 1},\n            },\n        },\n    )\n    return result[\"data\"]\n\ncreate_job_flow()\n</code></pre></p>"},{"location":"cli/commands/","title":"Commands","text":""},{"location":"cli/commands/#prefect_dbt.cli.commands","title":"<code>prefect_dbt.cli.commands</code>","text":"<p>Module containing tasks and flows for interacting with dbt CLI</p>"},{"location":"cli/commands/#prefect_dbt.cli.commands-classes","title":"Classes","text":""},{"location":"cli/commands/#prefect_dbt.cli.commands.DbtCoreOperation","title":"<code>DbtCoreOperation</code>","text":"<p>             Bases: <code>ShellOperation</code></p> <p>A block representing a dbt operation, containing multiple dbt and shell commands.</p> <p>For long-lasting operations, use the trigger method and utilize the block as a context manager for automatic closure of processes when context is exited. If not, manually call the close method to close processes.</p> <p>For short-lasting operations, use the run method. Context is automatically managed with this method.</p> <p>Attributes:</p> Name Type Description <code>commands</code> <p>A list of commands to execute sequentially.</p> <code>stream_output</code> <p>Whether to stream output.</p> <code>env</code> <p>A dictionary of environment variables to set for the shell operation.</p> <code>working_directory</code> <p>The working directory context the commands will be executed within.</p> <code>shell</code> <p>The shell to use to execute the commands.</p> <code>extension</code> <p>The extension to use for the temporary file. if unset defaults to <code>.ps1</code> on Windows and <code>.sh</code> on other platforms.</p> <code>profiles_dir</code> <code>Optional[Path]</code> <p>The directory to search for the profiles.yml file. Setting this appends the <code>--profiles-dir</code> option to the dbt commands provided. If this is not set, will try using the DBT_PROFILES_DIR environment variable, but if that's also not set, will use the default directory <code>$HOME/.dbt/</code>.</p> <code>project_dir</code> <code>Optional[Path]</code> <p>The directory to search for the dbt_project.yml file. Default is the current working directory and its parents.</p> <code>overwrite_profiles</code> <code>bool</code> <p>Whether the existing profiles.yml file under profiles_dir should be overwritten with a new profile.</p> <code>dbt_cli_profile</code> <code>Optional[DbtCliProfile]</code> <p>Profiles class containing the profile written to profiles.yml. Note! This is optional and will raise an error if profiles.yml already exists under profile_dir and overwrite_profiles is set to False.</p> <p>Examples:</p> <p>Load a configured block. <pre><code>from prefect_dbt import DbtCoreOperation\n\ndbt_op = DbtCoreOperation.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Execute short-lasting dbt debug and list with a custom DbtCliProfile. <pre><code>from prefect_dbt import DbtCoreOperation, DbtCliProfile\nfrom prefect_dbt.cli.configs import SnowflakeTargetConfigs\nfrom prefect_snowflake import SnowflakeConnector\n\nsnowflake_connector = await SnowflakeConnector.load(\"snowflake-connector\")\ntarget_configs = SnowflakeTargetConfigs(connector=snowflake_connector)\ndbt_cli_profile = DbtCliProfile(\n    name=\"jaffle_shop\",\n    target=\"dev\",\n    target_configs=target_configs,\n)\ndbt_init = DbtCoreOperation(\n    commands=[\"dbt debug\", \"dbt list\"],\n    dbt_cli_profile=dbt_cli_profile,\n    overwrite_profiles=True\n)\ndbt_init.run()\n</code></pre></p> <p>Execute a longer-lasting dbt run as a context manager. <pre><code>with DbtCoreOperation(commands=[\"dbt run\"]) as dbt_run:\n    dbt_process = dbt_run.trigger()\n    # do other things\n    dbt_process.wait_for_completion()\n    dbt_output = dbt_process.fetch_result()\n</code></pre></p> Source code in <code>prefect_dbt/cli/commands.py</code> <pre><code>class DbtCoreOperation(ShellOperation):\n    \"\"\"\n    A block representing a dbt operation, containing multiple dbt and shell commands.\n\n    For long-lasting operations, use the trigger method and utilize the block as a\n    context manager for automatic closure of processes when context is exited.\n    If not, manually call the close method to close processes.\n\n    For short-lasting operations, use the run method. Context is automatically managed\n    with this method.\n\n    Attributes:\n        commands: A list of commands to execute sequentially.\n        stream_output: Whether to stream output.\n        env: A dictionary of environment variables to set for the shell operation.\n        working_directory: The working directory context the commands\n            will be executed within.\n        shell: The shell to use to execute the commands.\n        extension: The extension to use for the temporary file.\n            if unset defaults to `.ps1` on Windows and `.sh` on other platforms.\n        profiles_dir: The directory to search for the profiles.yml file.\n            Setting this appends the `--profiles-dir` option to the dbt commands\n            provided. If this is not set, will try using the DBT_PROFILES_DIR\n            environment variable, but if that's also not\n            set, will use the default directory `$HOME/.dbt/`.\n        project_dir: The directory to search for the dbt_project.yml file.\n            Default is the current working directory and its parents.\n        overwrite_profiles: Whether the existing profiles.yml file under profiles_dir\n            should be overwritten with a new profile.\n        dbt_cli_profile: Profiles class containing the profile written to profiles.yml.\n            Note! This is optional and will raise an error if profiles.yml already\n            exists under profile_dir and overwrite_profiles is set to False.\n\n    Examples:\n        Load a configured block.\n        ```python\n        from prefect_dbt import DbtCoreOperation\n\n        dbt_op = DbtCoreOperation.load(\"BLOCK_NAME\")\n        ```\n\n        Execute short-lasting dbt debug and list with a custom DbtCliProfile.\n        ```python\n        from prefect_dbt import DbtCoreOperation, DbtCliProfile\n        from prefect_dbt.cli.configs import SnowflakeTargetConfigs\n        from prefect_snowflake import SnowflakeConnector\n\n        snowflake_connector = await SnowflakeConnector.load(\"snowflake-connector\")\n        target_configs = SnowflakeTargetConfigs(connector=snowflake_connector)\n        dbt_cli_profile = DbtCliProfile(\n            name=\"jaffle_shop\",\n            target=\"dev\",\n            target_configs=target_configs,\n        )\n        dbt_init = DbtCoreOperation(\n            commands=[\"dbt debug\", \"dbt list\"],\n            dbt_cli_profile=dbt_cli_profile,\n            overwrite_profiles=True\n        )\n        dbt_init.run()\n        ```\n\n        Execute a longer-lasting dbt run as a context manager.\n        ```python\n        with DbtCoreOperation(commands=[\"dbt run\"]) as dbt_run:\n            dbt_process = dbt_run.trigger()\n            # do other things\n            dbt_process.wait_for_completion()\n            dbt_output = dbt_process.fetch_result()\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt Core Operation\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/commands/#prefect_dbt.cli.commands.DbtCoreOperation\"  # noqa\n\n    profiles_dir: Optional[Path] = Field(\n        default=None,\n        description=(\n            \"The directory to search for the profiles.yml file. \"\n            \"Setting this appends the `--profiles-dir` option to the dbt commands \"\n            \"provided. If this is not set, will try using the DBT_PROFILES_DIR \"\n            \"environment variable, but if that's also not \"\n            \"set, will use the default directory `$HOME/.dbt/`.\"\n        ),\n    )\n    project_dir: Optional[Path] = Field(\n        default=None,\n        description=(\n            \"The directory to search for the dbt_project.yml file. \"\n            \"Default is the current working directory and its parents.\"\n        ),\n    )\n    overwrite_profiles: bool = Field(\n        default=False,\n        description=(\n            \"Whether the existing profiles.yml file under profiles_dir \"\n            \"should be overwritten with a new profile.\"\n        ),\n    )\n    dbt_cli_profile: Optional[DbtCliProfile] = Field(\n        default=None,\n        description=(\n            \"Profiles class containing the profile written to profiles.yml. \"\n            \"Note! This is optional and will raise an error if profiles.yml already \"\n            \"exists under profile_dir and overwrite_profiles is set to False.\"\n        ),\n    )\n\n    @validator(\"commands\", always=True)\n    def _has_a_dbt_command(cls, commands):\n        \"\"\"\n        Check that the commands contain a dbt command.\n        \"\"\"\n        if not any(\"dbt \" in command for command in commands):\n            raise ValueError(\n                \"None of the commands are a valid dbt sub-command; see dbt --help, \"\n                \"or use prefect_shell.ShellOperation for non-dbt related \"\n                \"commands instead\"\n            )\n        return commands\n\n    def _find_valid_profiles_dir(self) -&gt; PosixPath:\n        \"\"\"\n        Ensure that there is a profiles.yml available for use.\n        \"\"\"\n        profiles_dir = self.profiles_dir\n        if profiles_dir is None:\n            if self.env.get(\"DBT_PROFILES_DIR\") is not None:\n                # get DBT_PROFILES_DIR from the user input env\n                profiles_dir = self.env[\"DBT_PROFILES_DIR\"]\n            else:\n                # get DBT_PROFILES_DIR from the system env, or default to ~/.dbt\n                profiles_dir = os.getenv(\"DBT_PROFILES_DIR\", Path.home() / \".dbt\")\n        profiles_dir = relative_path_to_current_platform(\n            Path(profiles_dir).expanduser()\n        )\n\n        # https://docs.getdbt.com/dbt-cli/configure-your-profile\n        # Note that the file always needs to be called profiles.yml,\n        # regardless of which directory it is in.\n        profiles_path = profiles_dir / \"profiles.yml\"\n        overwrite_profiles = self.overwrite_profiles\n        dbt_cli_profile = self.dbt_cli_profile\n        if not profiles_path.exists() or overwrite_profiles:\n            if dbt_cli_profile is None:\n                raise ValueError(\n                    \"Since overwrite_profiles is True or profiles_path is empty, \"\n                    \"need `dbt_cli_profile` to write a profile\"\n                )\n            profile = dbt_cli_profile.get_profile()\n            profiles_dir.mkdir(exist_ok=True)\n            with open(profiles_path, \"w+\") as f:\n                yaml.dump(profile, f, default_flow_style=False)\n        elif dbt_cli_profile is not None:\n            raise ValueError(\n                f\"Since overwrite_profiles is False and profiles_path {profiles_path} \"\n                f\"already exists, the profile within dbt_cli_profile couldn't be used; \"\n                f\"if the existing profile is satisfactory, do not set dbt_cli_profile\"\n            )\n        return profiles_dir\n\n    def _append_dirs_to_commands(self, profiles_dir) -&gt; List[str]:\n        \"\"\"\n        Append profiles_dir and project_dir options to dbt commands.\n        \"\"\"\n        project_dir = self.project_dir\n\n        commands = []\n        for command in self.commands:\n            command += f\" --profiles-dir {profiles_dir}\"\n            if project_dir is not None:\n                project_dir = Path(project_dir).expanduser()\n                command += f\" --project-dir {project_dir}\"\n            commands.append(command)\n        return commands\n\n    def _compile_kwargs(self, **open_kwargs: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"\n        Helper method to compile the kwargs for `open_process` so it's not repeated\n        across the run and trigger methods.\n        \"\"\"\n        profiles_dir = self._find_valid_profiles_dir()\n        commands = self._append_dirs_to_commands(profiles_dir=profiles_dir)\n\n        # _compile_kwargs is called within trigger() and run(), prior to execution.\n        # However _compile_kwargs directly uses self.commands, but here we modified\n        # the commands without saving back to self.commands so we need to create a copy.\n        # was also thinking of using env vars but DBT_PROJECT_DIR is not supported yet.\n        modified_self = self.copy()\n        modified_self.commands = commands\n        return super(type(self), modified_self)._compile_kwargs(**open_kwargs)\n</code></pre>"},{"location":"cli/commands/#prefect_dbt.cli.commands-functions","title":"Functions","text":""},{"location":"cli/commands/#prefect_dbt.cli.commands.trigger_dbt_cli_command","title":"<code>trigger_dbt_cli_command</code>  <code>async</code>","text":"<p>Task for running dbt commands.</p> <p>If no profiles.yml file is found or if overwrite_profiles flag is set to True, this will first generate a profiles.yml file in the profiles_dir directory. Then run the dbt CLI shell command.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>str</code> <p>The dbt command to be executed.</p> required <code>profiles_dir</code> <code>Optional[Union[Path, str]]</code> <p>The directory to search for the profiles.yml file. Setting this appends the <code>--profiles-dir</code> option to the command provided. If this is not set, will try using the DBT_PROFILES_DIR environment variable, but if that's also not set, will use the default directory <code>$HOME/.dbt/</code>.</p> <code>None</code> <code>project_dir</code> <code>Optional[Union[Path, str]]</code> <p>The directory to search for the dbt_project.yml file. Default is the current working directory and its parents.</p> <code>None</code> <code>overwrite_profiles</code> <code>bool</code> <p>Whether the existing profiles.yml file under profiles_dir should be overwritten with a new profile.</p> <code>False</code> <code>dbt_cli_profile</code> <code>Optional[DbtCliProfile]</code> <p>Profiles class containing the profile written to profiles.yml. Note! This is optional and will raise an error if profiles.yml already exists under profile_dir and overwrite_profiles is set to False.</p> <code>None</code> <code>**shell_run_command_kwargs</code> <code>Dict[str, Any]</code> <p>Additional keyword arguments to pass to shell_run_command.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>last_line_cli_output</code> <code>str</code> <p>The last line of the CLI output will be returned if <code>return_all</code> in <code>shell_run_command_kwargs</code> is False. This is the default behavior.</p> <code>full_cli_output</code> <code>List[str]</code> <p>Full CLI output will be returned if <code>return_all</code> in <code>shell_run_command_kwargs</code> is True.</p> <p>Examples:</p> <p>Execute <code>dbt debug</code> with a pre-populated profiles.yml. <pre><code>from prefect import flow\nfrom prefect_dbt.cli.commands import trigger_dbt_cli_command\n\n@flow\ndef trigger_dbt_cli_command_flow():\n    result = trigger_dbt_cli_command(\"dbt debug\")\n    return result\n\ntrigger_dbt_cli_command_flow()\n</code></pre></p> <p>Execute <code>dbt debug</code> without a pre-populated profiles.yml. <pre><code>from prefect import flow\nfrom prefect_dbt.cli.credentials import DbtCliProfile\nfrom prefect_dbt.cli.commands import trigger_dbt_cli_command\nfrom prefect_dbt.cli.configs import SnowflakeTargetConfigs\nfrom prefect_snowflake.credentials import SnowflakeCredentials\n\n@flow\ndef trigger_dbt_cli_command_flow():\n    credentials = SnowflakeCredentials(\n        user=\"user\",\n        password=\"password\",\n        account=\"account.region.aws\",\n        role=\"role\",\n    )\n    connector = SnowflakeConnector(\n        schema=\"public\",\n        database=\"database\",\n        warehouse=\"warehouse\",\n        credentials=credentials,\n    )\n    target_configs = SnowflakeTargetConfigs(\n        connector=connector\n    )\n    dbt_cli_profile = DbtCliProfile(\n        name=\"jaffle_shop\",\n        target=\"dev\",\n        target_configs=target_configs,\n    )\n    result = trigger_dbt_cli_command(\n        \"dbt debug\",\n        overwrite_profiles=True,\n        dbt_cli_profile=dbt_cli_profile\n    )\n    return result\n\ntrigger_dbt_cli_command_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cli/commands.py</code> <pre><code>@task\nasync def trigger_dbt_cli_command(\n    command: str,\n    profiles_dir: Optional[Union[Path, str]] = None,\n    project_dir: Optional[Union[Path, str]] = None,\n    overwrite_profiles: bool = False,\n    dbt_cli_profile: Optional[DbtCliProfile] = None,\n    **shell_run_command_kwargs: Dict[str, Any],\n) -&gt; Union[List[str], str]:\n    \"\"\"\n    Task for running dbt commands.\n\n    If no profiles.yml file is found or if overwrite_profiles flag is set to True, this\n    will first generate a profiles.yml file in the profiles_dir directory. Then run the dbt\n    CLI shell command.\n\n    Args:\n        command: The dbt command to be executed.\n        profiles_dir: The directory to search for the profiles.yml file. Setting this\n            appends the `--profiles-dir` option to the command provided. If this is not set,\n            will try using the DBT_PROFILES_DIR environment variable, but if that's also not\n            set, will use the default directory `$HOME/.dbt/`.\n        project_dir: The directory to search for the dbt_project.yml file.\n            Default is the current working directory and its parents.\n        overwrite_profiles: Whether the existing profiles.yml file under profiles_dir\n            should be overwritten with a new profile.\n        dbt_cli_profile: Profiles class containing the profile written to profiles.yml.\n            Note! This is optional and will raise an error if profiles.yml already exists\n            under profile_dir and overwrite_profiles is set to False.\n        **shell_run_command_kwargs: Additional keyword arguments to pass to\n            [shell_run_command](https://prefecthq.github.io/prefect-shell/commands/#prefect_shell.commands.shell_run_command).\n\n    Returns:\n        last_line_cli_output (str): The last line of the CLI output will be returned\n            if `return_all` in `shell_run_command_kwargs` is False. This is the default\n            behavior.\n        full_cli_output (List[str]): Full CLI output will be returned if `return_all`\n            in `shell_run_command_kwargs` is True.\n\n    Examples:\n        Execute `dbt debug` with a pre-populated profiles.yml.\n        ```python\n        from prefect import flow\n        from prefect_dbt.cli.commands import trigger_dbt_cli_command\n\n        @flow\n        def trigger_dbt_cli_command_flow():\n            result = trigger_dbt_cli_command(\"dbt debug\")\n            return result\n\n        trigger_dbt_cli_command_flow()\n        ```\n\n        Execute `dbt debug` without a pre-populated profiles.yml.\n        ```python\n        from prefect import flow\n        from prefect_dbt.cli.credentials import DbtCliProfile\n        from prefect_dbt.cli.commands import trigger_dbt_cli_command\n        from prefect_dbt.cli.configs import SnowflakeTargetConfigs\n        from prefect_snowflake.credentials import SnowflakeCredentials\n\n        @flow\n        def trigger_dbt_cli_command_flow():\n            credentials = SnowflakeCredentials(\n                user=\"user\",\n                password=\"password\",\n                account=\"account.region.aws\",\n                role=\"role\",\n            )\n            connector = SnowflakeConnector(\n                schema=\"public\",\n                database=\"database\",\n                warehouse=\"warehouse\",\n                credentials=credentials,\n            )\n            target_configs = SnowflakeTargetConfigs(\n                connector=connector\n            )\n            dbt_cli_profile = DbtCliProfile(\n                name=\"jaffle_shop\",\n                target=\"dev\",\n                target_configs=target_configs,\n            )\n            result = trigger_dbt_cli_command(\n                \"dbt debug\",\n                overwrite_profiles=True,\n                dbt_cli_profile=dbt_cli_profile\n            )\n            return result\n\n        trigger_dbt_cli_command_flow()\n        ```\n    \"\"\"  # noqa\n    # check if variable is set, if not check env, if not use expected default\n    logger = get_run_logger()\n    if not command.startswith(\"dbt\"):\n        await shell_run_command.fn(command=\"dbt --help\")\n        raise ValueError(\n            \"Command is not a valid dbt sub-command; see dbt --help above,\"\n            \"or use prefect_shell.commands.shell_run_command for non-dbt related \"\n            \"commands instead\"\n        )\n\n    if profiles_dir is None:\n        profiles_dir = os.getenv(\"DBT_PROFILES_DIR\", Path.home() / \".dbt\")\n    profiles_dir = Path(profiles_dir).expanduser()\n\n    # https://docs.getdbt.com/dbt-cli/configure-your-profile\n    # Note that the file always needs to be called profiles.yml,\n    # regardless of which directory it is in.\n    profiles_path = profiles_dir / \"profiles.yml\"\n    logger.debug(f\"Using this profiles path: {profiles_path}\")\n\n    # write the profile if overwrite or no profiles exist\n    if overwrite_profiles or not profiles_path.exists():\n        if dbt_cli_profile is None:\n            raise ValueError(\"Provide `dbt_cli_profile` keyword for writing profiles\")\n        profile = dbt_cli_profile.get_profile()\n        profiles_dir.mkdir(exist_ok=True)\n        with open(profiles_path, \"w+\") as f:\n            yaml.dump(profile, f, default_flow_style=False)\n        logger.info(f\"Wrote profile to {profiles_path}\")\n    elif dbt_cli_profile is not None:\n        raise ValueError(\n            f\"Since overwrite_profiles is False and profiles_path ({profiles_path}) \"\n            f\"already exists, the profile within dbt_cli_profile could not be used; \"\n            f\"if the existing profile is satisfactory, do not pass dbt_cli_profile\"\n        )\n\n    # append the options\n    command += f\" --profiles-dir {profiles_dir}\"\n    if project_dir is not None:\n        project_dir = Path(project_dir).expanduser()\n        command += f\" --project-dir {project_dir}\"\n\n    # fix up empty shell_run_command_kwargs\n    shell_run_command_kwargs = shell_run_command_kwargs or {}\n\n    logger.info(f\"Running dbt command: {command}\")\n    result = await shell_run_command.fn(command=command, **shell_run_command_kwargs)\n    return result\n</code></pre>"},{"location":"cli/credentials/","title":"Credentials","text":""},{"location":"cli/credentials/#prefect_dbt.cli.credentials","title":"<code>prefect_dbt.cli.credentials</code>","text":"<p>Module containing credentials for interacting with dbt CLI</p>"},{"location":"cli/credentials/#prefect_dbt.cli.credentials-classes","title":"Classes","text":""},{"location":"cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile","title":"<code>DbtCliProfile</code>","text":"<p>             Bases: <code>Block</code></p> <p>Profile for use across dbt CLI tasks and flows.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Profile name used for populating profiles.yml.</p> <code>target</code> <code>str</code> <p>The default target your dbt project will use.</p> <code>target_configs</code> <code>TargetConfigs</code> <p>Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink.</p> <code>global_configs</code> <code>GlobalConfigs</code> <p>Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Valid keys can be found here.</p> <p>Examples:</p> <p>Load stored dbt CLI profile: <pre><code>from prefect_dbt.cli import DbtCliProfile\ndbt_cli_profile = DbtCliProfile.load(\"BLOCK_NAME\").get_profile()\n</code></pre></p> <p>Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs: <pre><code>from prefect_dbt.cli import DbtCliProfile\nfrom prefect_dbt.cli.configs import SnowflakeTargetConfigs\nfrom prefect_snowflake.credentials import SnowflakeCredentials\nfrom prefect_snowflake.database import SnowflakeConnector\n\ncredentials = SnowflakeCredentials(\n    user=\"user\",\n    password=\"password\",\n    account=\"account.region.aws\",\n    role=\"role\",\n)\nconnector = SnowflakeConnector(\n    schema=\"public\",\n    database=\"database\",\n    warehouse=\"warehouse\",\n    credentials=credentials,\n)\ntarget_configs = SnowflakeTargetConfigs(\n    connector=connector\n)\ndbt_cli_profile = DbtCliProfile(\n    name=\"jaffle_shop\",\n    target=\"dev\",\n    target_configs=target_configs,\n)\nprofile = dbt_cli_profile.get_profile()\n</code></pre></p> <p>Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs: <pre><code>from prefect_dbt.cli import DbtCliProfile\nfrom prefect_dbt.cli.configs import GlobalConfigs, TargetConfigs\n\ntarget_configs_extras = dict(\n    host=\"hostname.region.redshift.amazonaws.com\",\n    user=\"username\",\n    password=\"password1\",\n    port=5439,\n    dbname=\"analytics\",\n)\ntarget_configs = TargetConfigs(\n    type=\"redshift\",\n    schema=\"schema\",\n    threads=4,\n    extras=target_configs_extras\n)\ndbt_cli_profile = DbtCliProfile(\n    name=\"jaffle_shop\",\n    target=\"dev\",\n    target_configs=target_configs,\n)\nprofile = dbt_cli_profile.get_profile()\n</code></pre></p> Source code in <code>prefect_dbt/cli/credentials.py</code> <pre><code>class DbtCliProfile(Block):\n    \"\"\"\n    Profile for use across dbt CLI tasks and flows.\n\n    Attributes:\n        name (str): Profile name used for populating profiles.yml.\n        target (str): The default target your dbt project will use.\n        target_configs (TargetConfigs): Target configs contain credentials and\n            settings, specific to the warehouse you're connecting to.\n            To find valid keys, head to the [Available adapters](\n            https://docs.getdbt.com/docs/available-adapters) page and\n            click the desired adapter's \"Profile Setup\" hyperlink.\n        global_configs (GlobalConfigs): Global configs control\n            things like the visual output of logs, the manner\n            in which dbt parses your project, and what to do when\n            dbt finds a version mismatch or a failing model.\n            Valid keys can be found [here](\n            https://docs.getdbt.com/reference/global-configs).\n\n    Examples:\n        Load stored dbt CLI profile:\n        ```python\n        from prefect_dbt.cli import DbtCliProfile\n        dbt_cli_profile = DbtCliProfile.load(\"BLOCK_NAME\").get_profile()\n        ```\n\n        Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs:\n        ```python\n        from prefect_dbt.cli import DbtCliProfile\n        from prefect_dbt.cli.configs import SnowflakeTargetConfigs\n        from prefect_snowflake.credentials import SnowflakeCredentials\n        from prefect_snowflake.database import SnowflakeConnector\n\n        credentials = SnowflakeCredentials(\n            user=\"user\",\n            password=\"password\",\n            account=\"account.region.aws\",\n            role=\"role\",\n        )\n        connector = SnowflakeConnector(\n            schema=\"public\",\n            database=\"database\",\n            warehouse=\"warehouse\",\n            credentials=credentials,\n        )\n        target_configs = SnowflakeTargetConfigs(\n            connector=connector\n        )\n        dbt_cli_profile = DbtCliProfile(\n            name=\"jaffle_shop\",\n            target=\"dev\",\n            target_configs=target_configs,\n        )\n        profile = dbt_cli_profile.get_profile()\n        ```\n\n        Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs:\n        ```python\n        from prefect_dbt.cli import DbtCliProfile\n        from prefect_dbt.cli.configs import GlobalConfigs, TargetConfigs\n\n        target_configs_extras = dict(\n            host=\"hostname.region.redshift.amazonaws.com\",\n            user=\"username\",\n            password=\"password1\",\n            port=5439,\n            dbname=\"analytics\",\n        )\n        target_configs = TargetConfigs(\n            type=\"redshift\",\n            schema=\"schema\",\n            threads=4,\n            extras=target_configs_extras\n        )\n        dbt_cli_profile = DbtCliProfile(\n            name=\"jaffle_shop\",\n            target=\"dev\",\n            target_configs=target_configs,\n        )\n        profile = dbt_cli_profile.get_profile()\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt CLI Profile\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile\"  # noqa\n\n    name: str = Field(\n        default=..., description=\"Profile name used for populating profiles.yml.\"\n    )\n    target: str = Field(\n        default=..., description=\"The default target your dbt project will use.\"\n    )\n    target_configs: Union[\n        SnowflakeTargetConfigs,\n        BigQueryTargetConfigs,\n        PostgresTargetConfigs,\n        TargetConfigs,\n    ] = Field(\n        default=...,\n        description=(\n            \"Target configs contain credentials and settings, specific to the \"\n            \"warehouse you're connecting to.\"\n        ),\n    )\n    global_configs: Optional[GlobalConfigs] = Field(\n        default=None,\n        description=(\n            \"Global configs control things like the visual output of logs, the manner \"\n            \"in which dbt parses your project, and what to do when dbt finds a version \"\n            \"mismatch or a failing model.\"\n        ),\n    )\n\n    def get_profile(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Returns the dbt profile, likely used for writing to profiles.yml.\n\n        Returns:\n            A JSON compatible dictionary with the expected format of profiles.yml.\n        \"\"\"\n        profile = {\n            \"config\": self.global_configs.get_configs() if self.global_configs else {},\n            self.name: {\n                \"target\": self.target,\n                \"outputs\": {self.target: self.target_configs.get_configs()},\n            },\n        }\n        return profile\n</code></pre>"},{"location":"cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile-functions","title":"Functions","text":""},{"location":"cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile.get_profile","title":"<code>get_profile</code>","text":"<p>Returns the dbt profile, likely used for writing to profiles.yml.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A JSON compatible dictionary with the expected format of profiles.yml.</p> Source code in <code>prefect_dbt/cli/credentials.py</code> <pre><code>def get_profile(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Returns the dbt profile, likely used for writing to profiles.yml.\n\n    Returns:\n        A JSON compatible dictionary with the expected format of profiles.yml.\n    \"\"\"\n    profile = {\n        \"config\": self.global_configs.get_configs() if self.global_configs else {},\n        self.name: {\n            \"target\": self.target,\n            \"outputs\": {self.target: self.target_configs.get_configs()},\n        },\n    }\n    return profile\n</code></pre>"},{"location":"cli/configs/base/","title":"Base","text":""},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base","title":"<code>prefect_dbt.cli.configs.base</code>","text":"<p>Module containing models for base configs</p>"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base-classes","title":"Classes","text":""},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs","title":"<code>DbtConfigs</code>","text":"<p>             Bases: <code>Block</code>, <code>ABC</code></p> <p>Abstract class for other dbt Configs.</p> <p>Attributes:</p> Name Type Description <code>extras</code> <code>Optional[Dict[str, Any]]</code> <p>Extra target configs' keywords, not yet exposed in prefect-dbt, but available in dbt; if there are duplicate keys between extras and TargetConfigs, an error will be raised.</p> Source code in <code>prefect_dbt/cli/configs/base.py</code> <pre><code>class DbtConfigs(Block, abc.ABC):\n    \"\"\"\n    Abstract class for other dbt Configs.\n\n    Attributes:\n        extras: Extra target configs' keywords, not yet exposed\n            in prefect-dbt, but available in dbt; if there are\n            duplicate keys between extras and TargetConfigs,\n            an error will be raised.\n    \"\"\"\n\n    extras: Optional[Dict[str, Any]] = Field(\n        default=None,\n        description=(\n            \"Extra target configs' keywords, not yet exposed in prefect-dbt, \"\n            \"but available in dbt.\"\n        ),\n    )\n    allow_field_overrides: bool = Field(\n        default=False,\n        description=(\n            \"If enabled, fields from dbt target configs will override \"\n            \"fields provided in extras and credentials.\"\n        ),\n    )\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs\"  # noqa\n\n    def _populate_configs_json(\n        self,\n        configs_json: Dict[str, Any],\n        fields: Dict[str, Any],\n        model: BaseModel = None,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Recursively populate configs_json.\n        \"\"\"\n        # if allow_field_overrides is True keys from TargetConfigs take precedence\n        override_configs_json = {}\n\n        for field_name, field in fields.items():\n            if model is not None:\n                # get actual value from model\n                try:\n                    field_value = getattr(model, field_name)\n                except AttributeError:\n                    field_value = getattr(model, field.alias)\n                # override the name with alias so dbt parser can recognize the keyword;\n                # e.g. schema_ -&gt; schema, returns the original name if no alias is set\n                field_name = field.alias\n            else:\n                field_value = field\n\n            if field_value is None or field_name == \"allow_field_overrides\":\n                # do not add to configs json if no value or default is set\n                continue\n\n            if isinstance(field_value, BaseModel):\n                configs_json = self._populate_configs_json(\n                    configs_json, field_value.__fields__, model=field_value\n                )\n            elif field_name == \"extras\":\n                configs_json = self._populate_configs_json(\n                    configs_json,\n                    field_value,\n                )\n                override_configs_json.update(configs_json)\n            else:\n                if field_name in configs_json.keys() and not self.allow_field_overrides:\n                    raise ValueError(\n                        f\"The keyword, {field_name}, has already been provided in \"\n                        f\"TargetConfigs; remove duplicated keywords to continue\"\n                    )\n                if isinstance(field_value, SecretField):\n                    field_value = field_value.get_secret_value()\n                elif isinstance(field_value, Path):\n                    field_value = str(field_value)\n                configs_json[field_name] = field_value\n\n                if self.allow_field_overrides and model is self or model is None:\n                    override_configs_json[field_name] = field_value\n\n        configs_json.update(override_configs_json)\n        return configs_json\n\n    def get_configs(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Returns the dbt configs, likely used eventually for writing to profiles.yml.\n\n        Returns:\n            A configs JSON.\n        \"\"\"\n        return self._populate_configs_json({}, self.__fields__, model=self)\n</code></pre>"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs-functions","title":"Functions","text":""},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs.get_configs","title":"<code>get_configs</code>","text":"<p>Returns the dbt configs, likely used eventually for writing to profiles.yml.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A configs JSON.</p> Source code in <code>prefect_dbt/cli/configs/base.py</code> <pre><code>def get_configs(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Returns the dbt configs, likely used eventually for writing to profiles.yml.\n\n    Returns:\n        A configs JSON.\n    \"\"\"\n    return self._populate_configs_json({}, self.__fields__, model=self)\n</code></pre>"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.GlobalConfigs","title":"<code>GlobalConfigs</code>","text":"<p>             Bases: <code>DbtConfigs</code></p> <p>Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Docs can be found here.</p> <p>Attributes:</p> Name Type Description <code>send_anonymous_usage_stats</code> <code>Optional[bool]</code> <p>Whether usage stats are sent to dbt.</p> <code>use_colors</code> <code>Optional[bool]</code> <p>Colorize the output it prints in your terminal.</p> <code>partial_parse</code> <code>Optional[bool]</code> <p>When partial parsing is enabled, dbt will use an stored internal manifest to determine which files have been changed (if any) since it last parsed the project.</p> <code>printer_width</code> <code>Optional[int]</code> <p>Length of characters before starting a new line.</p> <code>write_json</code> <code>Optional[bool]</code> <p>Determines whether dbt writes JSON artifacts to the target/ directory.</p> <code>warn_error</code> <code>Optional[bool]</code> <p>Whether to convert dbt warnings into errors.</p> <code>log_format</code> <code>Optional[str]</code> <p>The LOG_FORMAT config specifies how dbt's logs should be formatted. If the value of this config is json, dbt will output fully structured logs in JSON format.</p> <code>debug</code> <code>Optional[bool]</code> <p>Whether to redirect dbt's debug logs to standard out.</p> <code>version_check</code> <code>Optional[bool]</code> <p>Whether to raise an error if a project's version is used with an incompatible dbt version.</p> <code>fail_fast</code> <code>Optional[bool]</code> <p>Make dbt exit immediately if a single resource fails to build.</p> <code>use_experimental_parser</code> <code>Optional[bool]</code> <p>Opt into the latest experimental version of the static parser.</p> <code>static_parser</code> <code>Optional[bool]</code> <p>Whether to use the static parser.</p> <p>Examples:</p> <p>Load stored GlobalConfigs: <pre><code>from prefect_dbt.cli.configs import GlobalConfigs\n\ndbt_cli_global_configs = GlobalConfigs.load(\"BLOCK_NAME\")\n</code></pre></p> Source code in <code>prefect_dbt/cli/configs/base.py</code> <pre><code>class GlobalConfigs(DbtConfigs):\n    \"\"\"\n    Global configs control things like the visual output\n    of logs, the manner in which dbt parses your project,\n    and what to do when dbt finds a version mismatch\n    or a failing model. Docs can be found [here](\n    https://docs.getdbt.com/reference/global-configs).\n\n    Attributes:\n        send_anonymous_usage_stats: Whether usage stats are sent to dbt.\n        use_colors: Colorize the output it prints in your terminal.\n        partial_parse: When partial parsing is enabled, dbt will use an\n            stored internal manifest to determine which files have been changed\n            (if any) since it last parsed the project.\n        printer_width: Length of characters before starting a new line.\n        write_json: Determines whether dbt writes JSON artifacts to\n            the target/ directory.\n        warn_error: Whether to convert dbt warnings into errors.\n        log_format: The LOG_FORMAT config specifies how dbt's logs should\n            be formatted. If the value of this config is json, dbt will\n            output fully structured logs in JSON format.\n        debug: Whether to redirect dbt's debug logs to standard out.\n        version_check: Whether to raise an error if a project's version\n            is used with an incompatible dbt version.\n        fail_fast: Make dbt exit immediately if a single resource fails to build.\n        use_experimental_parser: Opt into the latest experimental version\n            of the static parser.\n        static_parser: Whether to use the [static parser](\n            https://docs.getdbt.com/reference/parsing#static-parser).\n\n    Examples:\n        Load stored GlobalConfigs:\n        ```python\n        from prefect_dbt.cli.configs import GlobalConfigs\n\n        dbt_cli_global_configs = GlobalConfigs.load(\"BLOCK_NAME\")\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt CLI Global Configs\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/configs/base/#prefect_dbt.cli.configs.base.GlobalConfigs\"  # noqa\n\n    send_anonymous_usage_stats: Optional[bool] = Field(\n        default=None,\n        description=\"Whether usage stats are sent to dbt.\",\n    )\n    use_colors: Optional[bool] = Field(\n        default=None,\n        description=\"Colorize the output it prints in your terminal.\",\n    )\n    partial_parse: Optional[bool] = Field(\n        default=None,\n        description=(\n            \"When partial parsing is enabled, dbt will use an \"\n            \"stored internal manifest to determine which files have been changed \"\n            \"(if any) since it last parsed the project.\"\n        ),\n    )\n    printer_width: Optional[int] = Field(\n        default=None,\n        description=\"Length of characters before starting a new line.\",\n    )\n    write_json: Optional[bool] = Field(\n        default=None,\n        description=(\n            \"Determines whether dbt writes JSON artifacts to \" \"the target/ directory.\"\n        ),\n    )\n    warn_error: Optional[bool] = Field(\n        default=None,\n        description=\"Whether to convert dbt warnings into errors.\",\n    )\n    log_format: Optional[str] = Field(\n        default=None,\n        description=(\n            \"The LOG_FORMAT config specifies how dbt's logs should \"\n            \"be formatted. If the value of this config is json, dbt will \"\n            \"output fully structured logs in JSON format.\"\n        ),\n    )\n    debug: Optional[bool] = Field(\n        default=None,\n        description=\"Whether to redirect dbt's debug logs to standard out.\",\n    )\n    version_check: Optional[bool] = Field(\n        default=None,\n        description=(\n            \"Whether to raise an error if a project's version \"\n            \"is used with an incompatible dbt version.\"\n        ),\n    )\n    fail_fast: Optional[bool] = Field(\n        default=None,\n        description=(\"Make dbt exit immediately if a single resource fails to build.\"),\n    )\n    use_experimental_parser: Optional[bool] = Field(\n        default=None,\n        description=(\n            \"Opt into the latest experimental version \" \"of the static parser.\"\n        ),\n    )\n    static_parser: Optional[bool] = Field(\n        default=None,\n        description=(\n            \"Whether to use the [static parser](https://docs.getdbt.com/reference/parsing#static-parser).\"  # noqa\n        ),\n    )\n</code></pre>"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.TargetConfigs","title":"<code>TargetConfigs</code>","text":"<p>             Bases: <code>BaseTargetConfigs</code></p> <p>Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink.</p> <p>Attributes:</p> Name Type Description <code>type</code> <p>The name of the database warehouse.</p> <code>schema</code> <p>The schema that dbt will build objects into; in BigQuery, a schema is actually a dataset.</p> <code>threads</code> <p>The number of threads representing the max number of paths through the graph dbt may work on at once.</p> <p>Examples:</p> <p>Load stored TargetConfigs: <pre><code>from prefect_dbt.cli.configs import TargetConfigs\n\ndbt_cli_target_configs = TargetConfigs.load(\"BLOCK_NAME\")\n</code></pre></p> Source code in <code>prefect_dbt/cli/configs/base.py</code> <pre><code>class TargetConfigs(BaseTargetConfigs):\n    \"\"\"\n    Target configs contain credentials and\n    settings, specific to the warehouse you're connecting to.\n    To find valid keys, head to the [Available adapters](\n    https://docs.getdbt.com/docs/available-adapters) page and\n    click the desired adapter's \"Profile Setup\" hyperlink.\n\n    Attributes:\n        type: The name of the database warehouse.\n        schema: The schema that dbt will build objects into;\n            in BigQuery, a schema is actually a dataset.\n        threads: The number of threads representing the max number\n            of paths through the graph dbt may work on at once.\n\n    Examples:\n        Load stored TargetConfigs:\n        ```python\n        from prefect_dbt.cli.configs import TargetConfigs\n\n        dbt_cli_target_configs = TargetConfigs.load(\"BLOCK_NAME\")\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt CLI Target Configs\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/configs/base/#prefect_dbt.cli.configs.base.TargetConfigs\"  # noqa\n</code></pre>"},{"location":"cli/configs/bigquery/","title":"BigQuery","text":""},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery","title":"<code>prefect_dbt.cli.configs.bigquery</code>","text":"<p>Module containing models for BigQuery configs</p>"},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery-classes","title":"Classes","text":""},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs","title":"<code>BigQueryTargetConfigs</code>","text":"<p>             Bases: <code>BaseTargetConfigs</code></p> <p>Target configs contain credentials and settings, specific to BigQuery. To find valid keys, head to the BigQuery Profile page.</p> <p>Attributes:</p> Name Type Description <code>credentials</code> <code>GcpCredentials</code> <p>The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised.</p> <p>Examples:</p> <p>Load stored BigQueryTargetConfigs. <pre><code>from prefect_dbt.cli.configs import BigQueryTargetConfigs\n\nbigquery_target_configs = BigQueryTargetConfigs.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Instantiate BigQueryTargetConfigs. <pre><code>from prefect_dbt.cli.configs import BigQueryTargetConfigs\nfrom prefect_gcp.credentials import GcpCredentials\n\ncredentials = GcpCredentials.load(\"BLOCK-NAME-PLACEHOLDER\")\ntarget_configs = BigQueryTargetConfigs(\n    schema=\"schema\",  # also known as dataset\n    credentials=credentials,\n)\n</code></pre></p> Source code in <code>prefect_dbt/cli/configs/bigquery.py</code> <pre><code>class BigQueryTargetConfigs(BaseTargetConfigs):\n    \"\"\"\n    Target configs contain credentials and\n    settings, specific to BigQuery.\n    To find valid keys, head to the [BigQuery Profile](\n    https://docs.getdbt.com/reference/warehouse-profiles/bigquery-profile)\n    page.\n\n    Attributes:\n        credentials: The credentials to use to authenticate; if there are\n            duplicate keys between credentials and TargetConfigs,\n            e.g. schema, an error will be raised.\n\n    Examples:\n        Load stored BigQueryTargetConfigs.\n        ```python\n        from prefect_dbt.cli.configs import BigQueryTargetConfigs\n\n        bigquery_target_configs = BigQueryTargetConfigs.load(\"BLOCK_NAME\")\n        ```\n\n        Instantiate BigQueryTargetConfigs.\n        ```python\n        from prefect_dbt.cli.configs import BigQueryTargetConfigs\n        from prefect_gcp.credentials import GcpCredentials\n\n        credentials = GcpCredentials.load(\"BLOCK-NAME-PLACEHOLDER\")\n        target_configs = BigQueryTargetConfigs(\n            schema=\"schema\",  # also known as dataset\n            credentials=credentials,\n        )\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt CLI BigQuery Target Configs\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _description = \"dbt CLI target configs containing credentials and settings, specific to BigQuery.\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs\"  # noqa\n\n    type: Literal[\"bigquery\"] = Field(\n        default=\"bigquery\", description=\"The type of target.\"\n    )\n    project: Optional[str] = Field(default=None, description=\"The project to use.\")\n    credentials: GcpCredentials = Field(\n        default_factory=GcpCredentials,\n        description=\"The credentials to use to authenticate.\",\n    )\n\n    def get_configs(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Returns the dbt configs specific to BigQuery profile.\n\n        Returns:\n            A configs JSON.\n        \"\"\"\n        # since GcpCredentials will always define a project\n        self_copy = self.copy()\n        if self_copy.project is not None:\n            self_copy.credentials.project = None\n        all_configs_json = self._populate_configs_json(\n            {}, self_copy.__fields__, model=self_copy\n        )\n\n        # decouple prefect-gcp from prefect-dbt\n        # by mapping all the keys dbt gcp accepts\n        # https://docs.getdbt.com/reference/warehouse-setups/bigquery-setup\n        rename_keys = {\n            # dbt\n            \"type\": \"type\",\n            \"schema\": \"schema\",\n            \"threads\": \"threads\",\n            # general\n            \"dataset\": \"schema\",\n            \"method\": \"method\",\n            \"project\": \"project\",\n            # service-account\n            \"service_account_file\": \"keyfile\",\n            # service-account json\n            \"service_account_info\": \"keyfile_json\",\n            # oauth secrets\n            \"refresh_token\": \"refresh_token\",\n            \"client_id\": \"client_id\",\n            \"client_secret\": \"client_secret\",\n            \"token_uri\": \"token_uri\",\n            # optional\n            \"priority\": \"priority\",\n            \"timeout_seconds\": \"timeout_seconds\",\n            \"location\": \"location\",\n            \"maximum_bytes_billed\": \"maximum_bytes_billed\",\n            \"scopes\": \"scopes\",\n            \"impersonate_service_account\": \"impersonate_service_account\",\n            \"execution_project\": \"execution_project\",\n        }\n        configs_json = {}\n        extras = self.extras or {}\n        for key in all_configs_json.keys():\n            if key not in rename_keys and key not in extras:\n                # skip invalid keys\n                continue\n            # rename key to something dbt profile expects\n            dbt_key = rename_keys.get(key) or key\n            configs_json[dbt_key] = all_configs_json[key]\n\n        if \"keyfile_json\" in configs_json:\n            configs_json[\"method\"] = \"service-account-json\"\n        elif \"keyfile\" in configs_json:\n            configs_json[\"method\"] = \"service-account\"\n            configs_json[\"keyfile\"] = str(configs_json[\"keyfile\"])\n        else:\n            configs_json[\"method\"] = \"oauth-secrets\"\n            # through gcloud application-default login\n            google_credentials = (\n                self_copy.credentials.get_credentials_from_service_account()\n            )\n            if hasattr(google_credentials, \"token\"):\n                request = Request()\n                google_credentials.refresh(request)\n                configs_json[\"token\"] = google_credentials.token\n            else:\n                for key in (\"refresh_token\", \"client_id\", \"client_secret\", \"token_uri\"):\n                    configs_json[key] = getattr(google_credentials, key)\n\n        if \"project\" not in configs_json:\n            raise ValueError(\n                \"The keyword, project, must be provided in either \"\n                \"GcpCredentials or BigQueryTargetConfigs\"\n            )\n        return configs_json\n</code></pre>"},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs-functions","title":"Functions","text":""},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs.get_configs","title":"<code>get_configs</code>","text":"<p>Returns the dbt configs specific to BigQuery profile.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A configs JSON.</p> Source code in <code>prefect_dbt/cli/configs/bigquery.py</code> <pre><code>def get_configs(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Returns the dbt configs specific to BigQuery profile.\n\n    Returns:\n        A configs JSON.\n    \"\"\"\n    # since GcpCredentials will always define a project\n    self_copy = self.copy()\n    if self_copy.project is not None:\n        self_copy.credentials.project = None\n    all_configs_json = self._populate_configs_json(\n        {}, self_copy.__fields__, model=self_copy\n    )\n\n    # decouple prefect-gcp from prefect-dbt\n    # by mapping all the keys dbt gcp accepts\n    # https://docs.getdbt.com/reference/warehouse-setups/bigquery-setup\n    rename_keys = {\n        # dbt\n        \"type\": \"type\",\n        \"schema\": \"schema\",\n        \"threads\": \"threads\",\n        # general\n        \"dataset\": \"schema\",\n        \"method\": \"method\",\n        \"project\": \"project\",\n        # service-account\n        \"service_account_file\": \"keyfile\",\n        # service-account json\n        \"service_account_info\": \"keyfile_json\",\n        # oauth secrets\n        \"refresh_token\": \"refresh_token\",\n        \"client_id\": \"client_id\",\n        \"client_secret\": \"client_secret\",\n        \"token_uri\": \"token_uri\",\n        # optional\n        \"priority\": \"priority\",\n        \"timeout_seconds\": \"timeout_seconds\",\n        \"location\": \"location\",\n        \"maximum_bytes_billed\": \"maximum_bytes_billed\",\n        \"scopes\": \"scopes\",\n        \"impersonate_service_account\": \"impersonate_service_account\",\n        \"execution_project\": \"execution_project\",\n    }\n    configs_json = {}\n    extras = self.extras or {}\n    for key in all_configs_json.keys():\n        if key not in rename_keys and key not in extras:\n            # skip invalid keys\n            continue\n        # rename key to something dbt profile expects\n        dbt_key = rename_keys.get(key) or key\n        configs_json[dbt_key] = all_configs_json[key]\n\n    if \"keyfile_json\" in configs_json:\n        configs_json[\"method\"] = \"service-account-json\"\n    elif \"keyfile\" in configs_json:\n        configs_json[\"method\"] = \"service-account\"\n        configs_json[\"keyfile\"] = str(configs_json[\"keyfile\"])\n    else:\n        configs_json[\"method\"] = \"oauth-secrets\"\n        # through gcloud application-default login\n        google_credentials = (\n            self_copy.credentials.get_credentials_from_service_account()\n        )\n        if hasattr(google_credentials, \"token\"):\n            request = Request()\n            google_credentials.refresh(request)\n            configs_json[\"token\"] = google_credentials.token\n        else:\n            for key in (\"refresh_token\", \"client_id\", \"client_secret\", \"token_uri\"):\n                configs_json[key] = getattr(google_credentials, key)\n\n    if \"project\" not in configs_json:\n        raise ValueError(\n            \"The keyword, project, must be provided in either \"\n            \"GcpCredentials or BigQueryTargetConfigs\"\n        )\n    return configs_json\n</code></pre>"},{"location":"cli/configs/postgres/","title":"Postgres","text":""},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres","title":"<code>prefect_dbt.cli.configs.postgres</code>","text":"<p>Module containing models for Postgres configs</p>"},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres-classes","title":"Classes","text":""},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs","title":"<code>PostgresTargetConfigs</code>","text":"<p>             Bases: <code>BaseTargetConfigs</code></p> <p>Target configs contain credentials and settings, specific to Postgres. To find valid keys, head to the Postgres Profile page.</p> <p>Attributes:</p> Name Type Description <code>credentials</code> <code>Union[SqlAlchemyConnector, DatabaseCredentials]</code> <p>The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised.</p> <p>Examples:</p> <p>Load stored PostgresTargetConfigs: <pre><code>from prefect_dbt.cli.configs import PostgresTargetConfigs\n\npostgres_target_configs = PostgresTargetConfigs.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Instantiate PostgresTargetConfigs with DatabaseCredentials. <pre><code>from prefect_dbt.cli.configs import PostgresTargetConfigs\nfrom prefect_sqlalchemy import DatabaseCredentials, SyncDriver\n\ncredentials = DatabaseCredentials(\n    driver=SyncDriver.POSTGRESQL_PSYCOPG2,\n    username=\"prefect\",\n    password=\"prefect_password\",\n    database=\"postgres\",\n    host=\"host\",\n    port=8080\n)\ntarget_configs = PostgresTargetConfigs(credentials=credentials, schema=\"schema\")\n</code></pre></p> Source code in <code>prefect_dbt/cli/configs/postgres.py</code> <pre><code>class PostgresTargetConfigs(BaseTargetConfigs):\n    \"\"\"\n    Target configs contain credentials and\n    settings, specific to Postgres.\n    To find valid keys, head to the [Postgres Profile](\n    https://docs.getdbt.com/reference/warehouse-profiles/postgres-profile)\n    page.\n\n    Attributes:\n        credentials: The credentials to use to authenticate; if there are\n            duplicate keys between credentials and TargetConfigs,\n            e.g. schema, an error will be raised.\n\n    Examples:\n        Load stored PostgresTargetConfigs:\n        ```python\n        from prefect_dbt.cli.configs import PostgresTargetConfigs\n\n        postgres_target_configs = PostgresTargetConfigs.load(\"BLOCK_NAME\")\n        ```\n\n        Instantiate PostgresTargetConfigs with DatabaseCredentials.\n        ```python\n        from prefect_dbt.cli.configs import PostgresTargetConfigs\n        from prefect_sqlalchemy import DatabaseCredentials, SyncDriver\n\n        credentials = DatabaseCredentials(\n            driver=SyncDriver.POSTGRESQL_PSYCOPG2,\n            username=\"prefect\",\n            password=\"prefect_password\",\n            database=\"postgres\",\n            host=\"host\",\n            port=8080\n        )\n        target_configs = PostgresTargetConfigs(credentials=credentials, schema=\"schema\")\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt CLI Postgres Target Configs\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _description = \"dbt CLI target configs containing credentials and settings specific to Postgres.\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs\"  # noqa\n\n    type: Literal[\"postgres\"] = Field(\n        default=\"postgres\", description=\"The type of the target.\"\n    )\n    credentials: Union[SqlAlchemyConnector, DatabaseCredentials] = Field(\n        default=...,\n        description=(\n            \"The credentials to use to authenticate; if there are duplicate keys \"\n            \"between credentials and TargetConfigs, e.g. schema, \"\n            \"an error will be raised.\"\n        ),\n    )  # noqa\n\n    def get_configs(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Returns the dbt configs specific to Postgres profile.\n\n        Returns:\n            A configs JSON.\n        \"\"\"\n        if isinstance(self.credentials, DatabaseCredentials):\n            warnings.warn(\n                \"Using DatabaseCredentials is deprecated and will be removed \"\n                \"on May 7th, 2023, use SqlAlchemyConnector instead.\",\n                DeprecationWarning,\n            )\n        all_configs_json = super().get_configs()\n\n        rename_keys = {\n            # dbt\n            \"type\": \"type\",\n            \"schema\": \"schema\",\n            \"threads\": \"threads\",\n            # general\n            \"host\": \"host\",\n            \"username\": \"user\",\n            \"password\": \"password\",\n            \"port\": \"port\",\n            \"database\": \"dbname\",\n            # optional\n            \"keepalives_idle\": \"keepalives_idle\",\n            \"connect_timeout\": \"connect_timeout\",\n            \"retries\": \"retries\",\n            \"search_path\": \"search_path\",\n            \"role\": \"role\",\n            \"sslmode\": \"sslmode\",\n        }\n\n        configs_json = {}\n        extras = self.extras or {}\n        for key in all_configs_json.keys():\n            if key not in rename_keys and key not in extras:\n                # skip invalid keys, like fetch_size + poll_frequency_s\n                continue\n            # rename key to something dbt profile expects\n            dbt_key = rename_keys.get(key) or key\n            configs_json[dbt_key] = all_configs_json[key]\n        port = configs_json.get(\"port\")\n        if port is not None:\n            configs_json[\"port\"] = int(port)\n        return configs_json\n</code></pre>"},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs-functions","title":"Functions","text":""},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs.get_configs","title":"<code>get_configs</code>","text":"<p>Returns the dbt configs specific to Postgres profile.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A configs JSON.</p> Source code in <code>prefect_dbt/cli/configs/postgres.py</code> <pre><code>def get_configs(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Returns the dbt configs specific to Postgres profile.\n\n    Returns:\n        A configs JSON.\n    \"\"\"\n    if isinstance(self.credentials, DatabaseCredentials):\n        warnings.warn(\n            \"Using DatabaseCredentials is deprecated and will be removed \"\n            \"on May 7th, 2023, use SqlAlchemyConnector instead.\",\n            DeprecationWarning,\n        )\n    all_configs_json = super().get_configs()\n\n    rename_keys = {\n        # dbt\n        \"type\": \"type\",\n        \"schema\": \"schema\",\n        \"threads\": \"threads\",\n        # general\n        \"host\": \"host\",\n        \"username\": \"user\",\n        \"password\": \"password\",\n        \"port\": \"port\",\n        \"database\": \"dbname\",\n        # optional\n        \"keepalives_idle\": \"keepalives_idle\",\n        \"connect_timeout\": \"connect_timeout\",\n        \"retries\": \"retries\",\n        \"search_path\": \"search_path\",\n        \"role\": \"role\",\n        \"sslmode\": \"sslmode\",\n    }\n\n    configs_json = {}\n    extras = self.extras or {}\n    for key in all_configs_json.keys():\n        if key not in rename_keys and key not in extras:\n            # skip invalid keys, like fetch_size + poll_frequency_s\n            continue\n        # rename key to something dbt profile expects\n        dbt_key = rename_keys.get(key) or key\n        configs_json[dbt_key] = all_configs_json[key]\n    port = configs_json.get(\"port\")\n    if port is not None:\n        configs_json[\"port\"] = int(port)\n    return configs_json\n</code></pre>"},{"location":"cli/configs/snowflake/","title":"Snowflake","text":""},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake","title":"<code>prefect_dbt.cli.configs.snowflake</code>","text":"<p>Module containing models for Snowflake configs</p>"},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake-classes","title":"Classes","text":""},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs","title":"<code>SnowflakeTargetConfigs</code>","text":"<p>             Bases: <code>BaseTargetConfigs</code></p> <p>Target configs contain credentials and settings, specific to Snowflake. To find valid keys, head to the Snowflake Profile page.</p> <p>Attributes:</p> Name Type Description <code>connector</code> <code>SnowflakeConnector</code> <p>The connector to use.</p> <p>Examples:</p> <p>Load stored SnowflakeTargetConfigs: <pre><code>from prefect_dbt.cli.configs import SnowflakeTargetConfigs\n\nsnowflake_target_configs = SnowflakeTargetConfigs.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Instantiate SnowflakeTargetConfigs. <pre><code>from prefect_dbt.cli.configs import SnowflakeTargetConfigs\nfrom prefect_snowflake.credentials import SnowflakeCredentials\nfrom prefect_snowflake.database import SnowflakeConnector\n\ncredentials = SnowflakeCredentials(\n    user=\"user\",\n    password=\"password\",\n    account=\"account.region.aws\",\n    role=\"role\",\n)\nconnector = SnowflakeConnector(\n    schema=\"public\",\n    database=\"database\",\n    warehouse=\"warehouse\",\n    credentials=credentials,\n)\ntarget_configs = SnowflakeTargetConfigs(\n    connector=connector,\n    extras={\"retry_on_database_errors\": True},\n)\n</code></pre></p> Source code in <code>prefect_dbt/cli/configs/snowflake.py</code> <pre><code>class SnowflakeTargetConfigs(BaseTargetConfigs):\n    \"\"\"\n    Target configs contain credentials and\n    settings, specific to Snowflake.\n    To find valid keys, head to the [Snowflake Profile](\n    https://docs.getdbt.com/reference/warehouse-profiles/snowflake-profile)\n    page.\n\n    Attributes:\n        connector: The connector to use.\n\n    Examples:\n        Load stored SnowflakeTargetConfigs:\n        ```python\n        from prefect_dbt.cli.configs import SnowflakeTargetConfigs\n\n        snowflake_target_configs = SnowflakeTargetConfigs.load(\"BLOCK_NAME\")\n        ```\n\n        Instantiate SnowflakeTargetConfigs.\n        ```python\n        from prefect_dbt.cli.configs import SnowflakeTargetConfigs\n        from prefect_snowflake.credentials import SnowflakeCredentials\n        from prefect_snowflake.database import SnowflakeConnector\n\n        credentials = SnowflakeCredentials(\n            user=\"user\",\n            password=\"password\",\n            account=\"account.region.aws\",\n            role=\"role\",\n        )\n        connector = SnowflakeConnector(\n            schema=\"public\",\n            database=\"database\",\n            warehouse=\"warehouse\",\n            credentials=credentials,\n        )\n        target_configs = SnowflakeTargetConfigs(\n            connector=connector,\n            extras={\"retry_on_database_errors\": True},\n        )\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt CLI Snowflake Target Configs\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs\"  # noqa\n\n    type: Literal[\"snowflake\"] = Field(\n        default=\"snowflake\", description=\"The type of the target configs.\"\n    )\n    schema_: Optional[str] = Field(\n        default=None,\n        alias=\"schema\",\n        description=\"The schema to use for the target configs.\",\n    )\n    connector: SnowflakeConnector = Field(\n        default=..., description=\"The connector to use.\"\n    )\n\n    def get_configs(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Returns the dbt configs specific to Snowflake profile.\n\n        Returns:\n            A configs JSON.\n        \"\"\"\n        all_configs_json = super().get_configs()\n\n        # decouple prefect-snowflake from prefect-dbt\n        # by mapping all the keys dbt snowflake accepts\n        # https://docs.getdbt.com/reference/warehouse-setups/snowflake-setup\n        rename_keys = {\n            # dbt\n            \"type\": \"type\",\n            \"schema\": \"schema\",\n            \"threads\": \"threads\",\n            # general\n            \"account\": \"account\",\n            \"user\": \"user\",\n            \"role\": \"role\",\n            \"database\": \"database\",\n            \"warehouse\": \"warehouse\",\n            # user and password\n            \"password\": \"password\",\n            # duo mfa / sso\n            \"authenticator\": \"authenticator\",\n            # key pair\n            \"private_key_path\": \"private_key_path\",\n            \"private_key_passphrase\": \"private_key_passphrase\",\n            # optional\n            \"client_session_keep_alive\": \"client_session_keep_alive\",\n            \"query_tag\": \"query_tag\",\n            \"connect_retries\": \"connect_retries\",\n            \"connect_timeout\": \"connect_timeout\",\n            \"retry_on_database_errors\": \"retry_on_database_errors\",\n            \"retry_all\": \"retry_all\",\n        }\n        configs_json = {}\n        extras = self.extras or {}\n        for key in all_configs_json.keys():\n            if key not in rename_keys and key not in extras:\n                # skip invalid keys, like fetch_size + poll_frequency_s\n                continue\n            # rename key to something dbt profile expects\n            dbt_key = rename_keys.get(key) or key\n            configs_json[dbt_key] = all_configs_json[key]\n        return configs_json\n</code></pre>"},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs-functions","title":"Functions","text":""},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs.get_configs","title":"<code>get_configs</code>","text":"<p>Returns the dbt configs specific to Snowflake profile.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A configs JSON.</p> Source code in <code>prefect_dbt/cli/configs/snowflake.py</code> <pre><code>def get_configs(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Returns the dbt configs specific to Snowflake profile.\n\n    Returns:\n        A configs JSON.\n    \"\"\"\n    all_configs_json = super().get_configs()\n\n    # decouple prefect-snowflake from prefect-dbt\n    # by mapping all the keys dbt snowflake accepts\n    # https://docs.getdbt.com/reference/warehouse-setups/snowflake-setup\n    rename_keys = {\n        # dbt\n        \"type\": \"type\",\n        \"schema\": \"schema\",\n        \"threads\": \"threads\",\n        # general\n        \"account\": \"account\",\n        \"user\": \"user\",\n        \"role\": \"role\",\n        \"database\": \"database\",\n        \"warehouse\": \"warehouse\",\n        # user and password\n        \"password\": \"password\",\n        # duo mfa / sso\n        \"authenticator\": \"authenticator\",\n        # key pair\n        \"private_key_path\": \"private_key_path\",\n        \"private_key_passphrase\": \"private_key_passphrase\",\n        # optional\n        \"client_session_keep_alive\": \"client_session_keep_alive\",\n        \"query_tag\": \"query_tag\",\n        \"connect_retries\": \"connect_retries\",\n        \"connect_timeout\": \"connect_timeout\",\n        \"retry_on_database_errors\": \"retry_on_database_errors\",\n        \"retry_all\": \"retry_all\",\n    }\n    configs_json = {}\n    extras = self.extras or {}\n    for key in all_configs_json.keys():\n        if key not in rename_keys and key not in extras:\n            # skip invalid keys, like fetch_size + poll_frequency_s\n            continue\n        # rename key to something dbt profile expects\n        dbt_key = rename_keys.get(key) or key\n        configs_json[dbt_key] = all_configs_json[key]\n    return configs_json\n</code></pre>"},{"location":"cloud/clients/","title":"Clients","text":""},{"location":"cloud/clients/#prefect_dbt.cloud.clients","title":"<code>prefect_dbt.cloud.clients</code>","text":"<p>Module containing clients for interacting with the dbt Cloud API</p>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients-classes","title":"Classes","text":""},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient","title":"<code>DbtCloudAdministrativeClient</code>","text":"<p>Client for interacting with the dbt cloud Administrative API.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>API key to authenticate with the dbt Cloud administrative API.</p> required <code>account_id</code> <code>int</code> <p>ID of dbt Cloud account with which to interact.</p> required <code>domain</code> <code>str</code> <p>Domain at which the dbt Cloud API is hosted.</p> <code>'cloud.getdbt.com'</code> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>class DbtCloudAdministrativeClient:\n    \"\"\"\n    Client for interacting with the dbt cloud Administrative API.\n\n    Args:\n        api_key: API key to authenticate with the dbt Cloud administrative API.\n        account_id: ID of dbt Cloud account with which to interact.\n        domain: Domain at which the dbt Cloud API is hosted.\n    \"\"\"\n\n    def __init__(self, api_key: str, account_id: int, domain: str = \"cloud.getdbt.com\"):\n        self._closed = False\n        self._started = False\n\n        self._admin_client = AsyncClient(\n            headers={\n                \"Authorization\": f\"Bearer {api_key}\",\n                \"user-agent\": f\"prefect-{prefect.__version__}\",\n                \"x-dbt-partner-source\": \"prefect\",\n            },\n            base_url=f\"https://{domain}/api/v2/accounts/{account_id}\",\n        )\n\n    async def call_endpoint(\n        self,\n        http_method: str,\n        path: str,\n        params: Optional[Dict[str, Any]] = None,\n        json: Optional[Dict[str, Any]] = None,\n    ) -&gt; Response:\n        \"\"\"\n        Call an endpoint in the dbt Cloud API.\n\n        Args:\n            path: The partial path for the request (e.g. /projects/). Will be appended\n                onto the base URL as determined by the client configuration.\n            http_method: HTTP method to call on the endpoint.\n            params: Query parameters to include in the request.\n            json: JSON serializable body to send in the request.\n\n        Returns:\n            The response from the dbt Cloud administrative API.\n        \"\"\"\n        response = await self._admin_client.request(\n            method=http_method, url=path, params=params, json=json\n        )\n\n        response.raise_for_status()\n\n        return response\n\n    async def get_job(\n        self,\n        job_id: int,\n        order_by: Optional[str] = None,\n    ) -&gt; Response:\n        \"\"\"\n        Return job details for a job on an account.\n\n        Args:\n            job_id: Numeric ID of the job.\n            order_by: Field to order the result by. Use - to indicate reverse order.\n\n        Returns:\n            The response from the dbt Cloud administrative API.\n        \"\"\"  # noqa\n        params = {\"order_by\": order_by} if order_by else None\n        return await self.call_endpoint(\n            path=f\"/jobs/{job_id}/\", http_method=\"GET\", params=params\n        )\n\n    async def trigger_job_run(\n        self, job_id: int, options: Optional[TriggerJobRunOptions] = None\n    ) -&gt; Response:\n        \"\"\"\n        Sends a request to the [trigger job run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Jobs/operation/triggerRun)\n        to initiate a job run.\n\n        Args:\n            job_id: The ID of the job to trigger.\n            options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run.\n\n        Returns:\n            The response from the dbt Cloud administrative API.\n        \"\"\"  # noqa\n        if options is None:\n            options = TriggerJobRunOptions()\n\n        return await self.call_endpoint(\n            path=f\"/jobs/{job_id}/run/\",\n            http_method=\"POST\",\n            json=options.dict(exclude_none=True),\n        )\n\n    async def get_run(\n        self,\n        run_id: int,\n        include_related: Optional[\n            List[Literal[\"trigger\", \"job\", \"debug_logs\", \"run_steps\"]]\n        ] = None,\n    ) -&gt; Response:\n        \"\"\"\n        Sends a request to the [get run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getRunById)\n        to get details about a job run.\n\n        Args:\n            run_id: The ID of the run to get details for.\n            include_related: List of related fields to pull with the run.\n                Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\".\n                If \"debug_logs\" is not provided in a request, then the included debug\n                logs will be truncated to the last 1,000 lines of the debug log output file.\n\n        Returns:\n            The response from the dbt Cloud administrative API.\n        \"\"\"  # noqa\n        params = {\"include_related\": include_related} if include_related else None\n        return await self.call_endpoint(\n            path=f\"/runs/{run_id}/\", http_method=\"GET\", params=params\n        )\n\n    async def list_run_artifacts(\n        self, run_id: int, step: Optional[int] = None\n    ) -&gt; Response:\n        \"\"\"\n        Sends a request to the [list run artifacts endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/listArtifactsByRunId)\n        to fetch a list of paths of artifacts generated for a completed run.\n\n        Args:\n            run_id: The ID of the run to list run artifacts for.\n            step: The index of the step in the run to query for artifacts. The\n                first step in the run has the index 1. If the step parameter is\n                omitted, then this method will return the artifacts compiled\n                for the last step in the run.\n\n        Returns:\n            The response from the dbt Cloud administrative API.\n        \"\"\"  # noqa\n        params = {\"step\": step} if step else None\n        return await self.call_endpoint(\n            path=f\"/runs/{run_id}/artifacts/\", http_method=\"GET\", params=params\n        )\n\n    async def get_run_artifact(\n        self, run_id: int, path: str, step: Optional[int] = None\n    ) -&gt; Response:\n        \"\"\"\n        Sends a request to the [get run artifact endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getArtifactsByRunId)\n        to fetch an artifact generated for a completed run.\n\n        Args:\n            run_id: The ID of the run to list run artifacts for.\n            path: The relative path to the run artifact (e.g. manifest.json, catalog.json,\n                run_results.json)\n            step: The index of the step in the run to query for artifacts. The\n                first step in the run has the index 1. If the step parameter is\n                omitted, then this method will return the artifacts compiled\n                for the last step in the run.\n\n        Returns:\n            The response from the dbt Cloud administrative API.\n        \"\"\"  # noqa\n        params = {\"step\": step} if step else None\n        return await self.call_endpoint(\n            path=f\"/runs/{run_id}/artifacts/{path}\", http_method=\"GET\", params=params\n        )\n\n    async def __aenter__(self):\n        if self._closed:\n            raise RuntimeError(\n                \"The client cannot be started again after it has been closed.\"\n            )\n        if self._started:\n            raise RuntimeError(\"The client cannot be started more than once.\")\n\n        self._started = True\n\n        return self\n\n    async def __aexit__(self, *exc):\n        self._closed = True\n        await self._admin_client.__aexit__()\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient-functions","title":"Functions","text":""},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.call_endpoint","title":"<code>call_endpoint</code>  <code>async</code>","text":"<p>Call an endpoint in the dbt Cloud API.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration.</p> required <code>http_method</code> <code>str</code> <p>HTTP method to call on the endpoint.</p> required <code>params</code> <code>Optional[Dict[str, Any]]</code> <p>Query parameters to include in the request.</p> <code>None</code> <code>json</code> <code>Optional[Dict[str, Any]]</code> <p>JSON serializable body to send in the request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>The response from the dbt Cloud administrative API.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>async def call_endpoint(\n    self,\n    http_method: str,\n    path: str,\n    params: Optional[Dict[str, Any]] = None,\n    json: Optional[Dict[str, Any]] = None,\n) -&gt; Response:\n    \"\"\"\n    Call an endpoint in the dbt Cloud API.\n\n    Args:\n        path: The partial path for the request (e.g. /projects/). Will be appended\n            onto the base URL as determined by the client configuration.\n        http_method: HTTP method to call on the endpoint.\n        params: Query parameters to include in the request.\n        json: JSON serializable body to send in the request.\n\n    Returns:\n        The response from the dbt Cloud administrative API.\n    \"\"\"\n    response = await self._admin_client.request(\n        method=http_method, url=path, params=params, json=json\n    )\n\n    response.raise_for_status()\n\n    return response\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.get_job","title":"<code>get_job</code>  <code>async</code>","text":"<p>Return job details for a job on an account.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>int</code> <p>Numeric ID of the job.</p> required <code>order_by</code> <code>Optional[str]</code> <p>Field to order the result by. Use - to indicate reverse order.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>The response from the dbt Cloud administrative API.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>async def get_job(\n    self,\n    job_id: int,\n    order_by: Optional[str] = None,\n) -&gt; Response:\n    \"\"\"\n    Return job details for a job on an account.\n\n    Args:\n        job_id: Numeric ID of the job.\n        order_by: Field to order the result by. Use - to indicate reverse order.\n\n    Returns:\n        The response from the dbt Cloud administrative API.\n    \"\"\"  # noqa\n    params = {\"order_by\": order_by} if order_by else None\n    return await self.call_endpoint(\n        path=f\"/jobs/{job_id}/\", http_method=\"GET\", params=params\n    )\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.get_run","title":"<code>get_run</code>  <code>async</code>","text":"<p>Sends a request to the get run endpoint to get details about a job run.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>int</code> <p>The ID of the run to get details for.</p> required <code>include_related</code> <code>Optional[List[Literal['trigger', 'job', 'debug_logs', 'run_steps']]]</code> <p>List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>The response from the dbt Cloud administrative API.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>async def get_run(\n    self,\n    run_id: int,\n    include_related: Optional[\n        List[Literal[\"trigger\", \"job\", \"debug_logs\", \"run_steps\"]]\n    ] = None,\n) -&gt; Response:\n    \"\"\"\n    Sends a request to the [get run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getRunById)\n    to get details about a job run.\n\n    Args:\n        run_id: The ID of the run to get details for.\n        include_related: List of related fields to pull with the run.\n            Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\".\n            If \"debug_logs\" is not provided in a request, then the included debug\n            logs will be truncated to the last 1,000 lines of the debug log output file.\n\n    Returns:\n        The response from the dbt Cloud administrative API.\n    \"\"\"  # noqa\n    params = {\"include_related\": include_related} if include_related else None\n    return await self.call_endpoint(\n        path=f\"/runs/{run_id}/\", http_method=\"GET\", params=params\n    )\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.get_run_artifact","title":"<code>get_run_artifact</code>  <code>async</code>","text":"<p>Sends a request to the get run artifact endpoint to fetch an artifact generated for a completed run.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>int</code> <p>The ID of the run to list run artifacts for.</p> required <code>path</code> <code>str</code> <p>The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json)</p> required <code>step</code> <code>Optional[int]</code> <p>The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>The response from the dbt Cloud administrative API.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>async def get_run_artifact(\n    self, run_id: int, path: str, step: Optional[int] = None\n) -&gt; Response:\n    \"\"\"\n    Sends a request to the [get run artifact endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getArtifactsByRunId)\n    to fetch an artifact generated for a completed run.\n\n    Args:\n        run_id: The ID of the run to list run artifacts for.\n        path: The relative path to the run artifact (e.g. manifest.json, catalog.json,\n            run_results.json)\n        step: The index of the step in the run to query for artifacts. The\n            first step in the run has the index 1. If the step parameter is\n            omitted, then this method will return the artifacts compiled\n            for the last step in the run.\n\n    Returns:\n        The response from the dbt Cloud administrative API.\n    \"\"\"  # noqa\n    params = {\"step\": step} if step else None\n    return await self.call_endpoint(\n        path=f\"/runs/{run_id}/artifacts/{path}\", http_method=\"GET\", params=params\n    )\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.list_run_artifacts","title":"<code>list_run_artifacts</code>  <code>async</code>","text":"<p>Sends a request to the list run artifacts endpoint to fetch a list of paths of artifacts generated for a completed run.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>int</code> <p>The ID of the run to list run artifacts for.</p> required <code>step</code> <code>Optional[int]</code> <p>The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>The response from the dbt Cloud administrative API.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>async def list_run_artifacts(\n    self, run_id: int, step: Optional[int] = None\n) -&gt; Response:\n    \"\"\"\n    Sends a request to the [list run artifacts endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/listArtifactsByRunId)\n    to fetch a list of paths of artifacts generated for a completed run.\n\n    Args:\n        run_id: The ID of the run to list run artifacts for.\n        step: The index of the step in the run to query for artifacts. The\n            first step in the run has the index 1. If the step parameter is\n            omitted, then this method will return the artifacts compiled\n            for the last step in the run.\n\n    Returns:\n        The response from the dbt Cloud administrative API.\n    \"\"\"  # noqa\n    params = {\"step\": step} if step else None\n    return await self.call_endpoint(\n        path=f\"/runs/{run_id}/artifacts/\", http_method=\"GET\", params=params\n    )\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.trigger_job_run","title":"<code>trigger_job_run</code>  <code>async</code>","text":"<p>Sends a request to the trigger job run endpoint to initiate a job run.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>int</code> <p>The ID of the job to trigger.</p> required <code>options</code> <code>Optional[TriggerJobRunOptions]</code> <p>An optional TriggerJobRunOptions instance to specify overrides for the triggered job run.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>The response from the dbt Cloud administrative API.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>async def trigger_job_run(\n    self, job_id: int, options: Optional[TriggerJobRunOptions] = None\n) -&gt; Response:\n    \"\"\"\n    Sends a request to the [trigger job run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Jobs/operation/triggerRun)\n    to initiate a job run.\n\n    Args:\n        job_id: The ID of the job to trigger.\n        options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run.\n\n    Returns:\n        The response from the dbt Cloud administrative API.\n    \"\"\"  # noqa\n    if options is None:\n        options = TriggerJobRunOptions()\n\n    return await self.call_endpoint(\n        path=f\"/jobs/{job_id}/run/\",\n        http_method=\"POST\",\n        json=options.dict(exclude_none=True),\n    )\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudMetadataClient","title":"<code>DbtCloudMetadataClient</code>","text":"<p>Client for interacting with the dbt cloud Administrative API.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>API key to authenticate with the dbt Cloud administrative API.</p> required <code>domain</code> <code>str</code> <p>Domain at which the dbt Cloud API is hosted.</p> <code>'metadata.cloud.getdbt.com'</code> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>class DbtCloudMetadataClient:\n    \"\"\"\n    Client for interacting with the dbt cloud Administrative API.\n\n    Args:\n        api_key: API key to authenticate with the dbt Cloud administrative API.\n        domain: Domain at which the dbt Cloud API is hosted.\n    \"\"\"\n\n    def __init__(self, api_key: str, domain: str = \"metadata.cloud.getdbt.com\"):\n        self._http_endpoint = HTTPEndpoint(\n            base_headers={\n                \"Authorization\": f\"Bearer {api_key}\",\n                \"user-agent\": f\"prefect-{prefect.__version__}\",\n                \"x-dbt-partner-source\": \"prefect\",\n                \"content-type\": \"application/json\",\n            },\n            url=f\"https://{domain}/graphql\",\n        )\n\n    def query(\n        self,\n        query: str,\n        variables: Optional[Dict] = None,\n        operation_name: Optional[str] = None,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Run a GraphQL query against the dbt Cloud metadata API.\n\n        Args:\n            query: The GraphQL query to run.\n            variables: The values of any variables defined in the GraphQL query.\n            operation_name: The name of the operation to run if multiple operations\n                are defined in the provided query.\n\n        Returns:\n            The result of the GraphQL query.\n        \"\"\"\n        return self._http_endpoint(\n            query=query, variables=variables, operation_name=operation_name\n        )\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudMetadataClient-functions","title":"Functions","text":""},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudMetadataClient.query","title":"<code>query</code>","text":"<p>Run a GraphQL query against the dbt Cloud metadata API.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The GraphQL query to run.</p> required <code>variables</code> <code>Optional[Dict]</code> <p>The values of any variables defined in the GraphQL query.</p> <code>None</code> <code>operation_name</code> <code>Optional[str]</code> <p>The name of the operation to run if multiple operations are defined in the provided query.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The result of the GraphQL query.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>def query(\n    self,\n    query: str,\n    variables: Optional[Dict] = None,\n    operation_name: Optional[str] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Run a GraphQL query against the dbt Cloud metadata API.\n\n    Args:\n        query: The GraphQL query to run.\n        variables: The values of any variables defined in the GraphQL query.\n        operation_name: The name of the operation to run if multiple operations\n            are defined in the provided query.\n\n    Returns:\n        The result of the GraphQL query.\n    \"\"\"\n    return self._http_endpoint(\n        query=query, variables=variables, operation_name=operation_name\n    )\n</code></pre>"},{"location":"cloud/credentials/","title":"Credentials","text":""},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials","title":"<code>prefect_dbt.cloud.credentials</code>","text":"<p>Module containing credentials for interacting with dbt Cloud</p>"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials-classes","title":"Classes","text":""},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials","title":"<code>DbtCloudCredentials</code>","text":"<p>             Bases: <code>CredentialsBlock</code></p> <p>Credentials block for credential use across dbt Cloud tasks and flows.</p> <p>Attributes:</p> Name Type Description <code>api_key</code> <code>SecretStr</code> <p>API key to authenticate with the dbt Cloud administrative API. Refer to the Authentication docs for retrieving the API key.</p> <code>account_id</code> <code>int</code> <p>ID of dbt Cloud account with which to interact.</p> <code>domain</code> <code>Optional[str]</code> <p>Domain at which the dbt Cloud API is hosted.</p> <p>Examples:</p> <p>Load stored dbt Cloud credentials: <pre><code>from prefect_dbt.cloud import DbtCloudCredentials\n\ndbt_cloud_credentials = DbtCloudCredentials.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Use DbtCloudCredentials instance to trigger a job run: <pre><code>from prefect_dbt.cloud import DbtCloudCredentials\n\ncredentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\nasync with dbt_cloud_credentials.get_administrative_client() as client:\n    client.trigger_job_run(job_id=1)\n</code></pre></p> <p>Load saved dbt Cloud credentials within a flow: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n\n\n@flow\ndef trigger_dbt_cloud_job_run_flow():\n    credentials = DbtCloudCredentials.load(\"my-dbt-credentials\")\n    trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1)\n\ntrigger_dbt_cloud_job_run_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/credentials.py</code> <pre><code>class DbtCloudCredentials(CredentialsBlock):\n    \"\"\"\n    Credentials block for credential use across dbt Cloud tasks and flows.\n\n    Attributes:\n        api_key (SecretStr): API key to authenticate with the dbt Cloud\n            administrative API. Refer to the [Authentication docs](\n            https://docs.getdbt.com/dbt-cloud/api-v2#section/Authentication)\n            for retrieving the API key.\n        account_id (int): ID of dbt Cloud account with which to interact.\n        domain (Optional[str]): Domain at which the dbt Cloud API is hosted.\n\n    Examples:\n        Load stored dbt Cloud credentials:\n        ```python\n        from prefect_dbt.cloud import DbtCloudCredentials\n\n        dbt_cloud_credentials = DbtCloudCredentials.load(\"BLOCK_NAME\")\n        ```\n\n        Use DbtCloudCredentials instance to trigger a job run:\n        ```python\n        from prefect_dbt.cloud import DbtCloudCredentials\n\n        credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            client.trigger_job_run(job_id=1)\n        ```\n\n        Load saved dbt Cloud credentials within a flow:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n\n\n        @flow\n        def trigger_dbt_cloud_job_run_flow():\n            credentials = DbtCloudCredentials.load(\"my-dbt-credentials\")\n            trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1)\n\n        trigger_dbt_cloud_job_run_flow()\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt Cloud Credentials\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials\"  # noqa\n\n    api_key: SecretStr = Field(\n        default=...,\n        title=\"API Key\",\n        description=\"A dbt Cloud API key to use for authentication.\",\n    )\n    account_id: int = Field(\n        default=..., title=\"Account ID\", description=\"The ID of your dbt Cloud account.\"\n    )\n    domain: str = Field(\n        default=\"cloud.getdbt.com\",\n        description=\"The base domain of your dbt Cloud instance.\",\n    )\n\n    def get_administrative_client(self) -&gt; DbtCloudAdministrativeClient:\n        \"\"\"\n        Returns a newly instantiated client for working with the dbt Cloud\n        administrative API.\n\n        Returns:\n            An authenticated dbt Cloud administrative API client.\n        \"\"\"\n        return DbtCloudAdministrativeClient(\n            api_key=self.api_key.get_secret_value(),\n            account_id=self.account_id,\n            domain=self.domain,\n        )\n\n    def get_metadata_client(self) -&gt; DbtCloudMetadataClient:\n        \"\"\"\n        Returns a newly instantiated client for working with the dbt Cloud\n        metadata API.\n\n        Example:\n            Sending queries via the returned metadata client:\n            ```python\n            from prefect_dbt import DbtCloudCredentials\n\n            credentials_block = DbtCloudCredentials.load(\"test-account\")\n            metadata_client = credentials_block.get_metadata_client()\n            query = \\\"\\\"\\\"\n            {\n                metrics(jobId: 123) {\n                    uniqueId\n                    name\n                    packageName\n                    tags\n                    label\n                    runId\n                    description\n                    type\n                    sql\n                    timestamp\n                    timeGrains\n                    dimensions\n                    meta\n                    resourceType\n                    filters {\n                        field\n                        operator\n                        value\n                    }\n                    model {\n                        name\n                    }\n                }\n            }\n            \\\"\\\"\\\"\n            metadata_client.query(query)\n            # Result:\n            # {\n            #   \"data\": {\n            #     \"metrics\": [\n            #       {\n            #         \"uniqueId\": \"metric.tpch.total_revenue\",\n            #         \"name\": \"total_revenue\",\n            #         \"packageName\": \"tpch\",\n            #         \"tags\": [],\n            #         \"label\": \"Total Revenue ($)\",\n            #         \"runId\": 108952046,\n            #         \"description\": \"\",\n            #         \"type\": \"sum\",\n            #         \"sql\": \"net_item_sales_amount\",\n            #         \"timestamp\": \"order_date\",\n            #         \"timeGrains\": [\"day\", \"week\", \"month\"],\n            #         \"dimensions\": [\"status_code\", \"priority_code\"],\n            #         \"meta\": {},\n            #         \"resourceType\": \"metric\",\n            #         \"filters\": [],\n            #         \"model\": { \"name\": \"fct_orders\" }\n            #       }\n            #     ]\n            #   }\n            # }\n            ```\n\n        Returns:\n            An authenticated dbt Cloud metadata API client.\n        \"\"\"\n        return DbtCloudMetadataClient(\n            api_key=self.api_key.get_secret_value(),\n            domain=f\"metadata.{self.domain}\",\n        )\n\n    def get_client(\n        self, client_type: Literal[\"administrative\", \"metadata\"]\n    ) -&gt; Union[DbtCloudAdministrativeClient, DbtCloudMetadataClient]:\n        \"\"\"\n        Returns a newly instantiated client for working with the dbt Cloud API.\n\n        Args:\n            client_type: Type of client to return. Accepts either 'administrative'\n                or 'metadata'.\n\n        Returns:\n            The authenticated client of the requested type.\n        \"\"\"\n        get_client_method = getattr(self, f\"get_{client_type}_client\", None)\n        if get_client_method is None:\n            raise ValueError(f\"'{client_type}' is not a supported client type.\")\n        return get_client_method()\n</code></pre>"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials-functions","title":"Functions","text":""},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials.get_administrative_client","title":"<code>get_administrative_client</code>","text":"<p>Returns a newly instantiated client for working with the dbt Cloud administrative API.</p> <p>Returns:</p> Type Description <code>DbtCloudAdministrativeClient</code> <p>An authenticated dbt Cloud administrative API client.</p> Source code in <code>prefect_dbt/cloud/credentials.py</code> <pre><code>def get_administrative_client(self) -&gt; DbtCloudAdministrativeClient:\n    \"\"\"\n    Returns a newly instantiated client for working with the dbt Cloud\n    administrative API.\n\n    Returns:\n        An authenticated dbt Cloud administrative API client.\n    \"\"\"\n    return DbtCloudAdministrativeClient(\n        api_key=self.api_key.get_secret_value(),\n        account_id=self.account_id,\n        domain=self.domain,\n    )\n</code></pre>"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials.get_client","title":"<code>get_client</code>","text":"<p>Returns a newly instantiated client for working with the dbt Cloud API.</p> <p>Parameters:</p> Name Type Description Default <code>client_type</code> <code>Literal['administrative', 'metadata']</code> <p>Type of client to return. Accepts either 'administrative' or 'metadata'.</p> required <p>Returns:</p> Type Description <code>Union[DbtCloudAdministrativeClient, DbtCloudMetadataClient]</code> <p>The authenticated client of the requested type.</p> Source code in <code>prefect_dbt/cloud/credentials.py</code> <pre><code>def get_client(\n    self, client_type: Literal[\"administrative\", \"metadata\"]\n) -&gt; Union[DbtCloudAdministrativeClient, DbtCloudMetadataClient]:\n    \"\"\"\n    Returns a newly instantiated client for working with the dbt Cloud API.\n\n    Args:\n        client_type: Type of client to return. Accepts either 'administrative'\n            or 'metadata'.\n\n    Returns:\n        The authenticated client of the requested type.\n    \"\"\"\n    get_client_method = getattr(self, f\"get_{client_type}_client\", None)\n    if get_client_method is None:\n        raise ValueError(f\"'{client_type}' is not a supported client type.\")\n    return get_client_method()\n</code></pre>"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials.get_metadata_client","title":"<code>get_metadata_client</code>","text":"<p>Returns a newly instantiated client for working with the dbt Cloud metadata API.</p> Example <p>Sending queries via the returned metadata client: <pre><code>from prefect_dbt import DbtCloudCredentials\n\ncredentials_block = DbtCloudCredentials.load(\"test-account\")\nmetadata_client = credentials_block.get_metadata_client()\nquery = \"\"\"\n{\n    metrics(jobId: 123) {\n        uniqueId\n        name\n        packageName\n        tags\n        label\n        runId\n        description\n        type\n        sql\n        timestamp\n        timeGrains\n        dimensions\n        meta\n        resourceType\n        filters {\n            field\n            operator\n            value\n        }\n        model {\n            name\n        }\n    }\n}\n\"\"\"\nmetadata_client.query(query)\n# Result:\n# {\n#   \"data\": {\n#     \"metrics\": [\n#       {\n#         \"uniqueId\": \"metric.tpch.total_revenue\",\n#         \"name\": \"total_revenue\",\n#         \"packageName\": \"tpch\",\n#         \"tags\": [],\n#         \"label\": \"Total Revenue ($)\",\n#         \"runId\": 108952046,\n#         \"description\": \"\",\n#         \"type\": \"sum\",\n#         \"sql\": \"net_item_sales_amount\",\n#         \"timestamp\": \"order_date\",\n#         \"timeGrains\": [\"day\", \"week\", \"month\"],\n#         \"dimensions\": [\"status_code\", \"priority_code\"],\n#         \"meta\": {},\n#         \"resourceType\": \"metric\",\n#         \"filters\": [],\n#         \"model\": { \"name\": \"fct_orders\" }\n#       }\n#     ]\n#   }\n# }\n</code></pre></p> <p>Returns:</p> Type Description <code>DbtCloudMetadataClient</code> <p>An authenticated dbt Cloud metadata API client.</p> Source code in <code>prefect_dbt/cloud/credentials.py</code> <pre><code>def get_metadata_client(self) -&gt; DbtCloudMetadataClient:\n    \"\"\"\n    Returns a newly instantiated client for working with the dbt Cloud\n    metadata API.\n\n    Example:\n        Sending queries via the returned metadata client:\n        ```python\n        from prefect_dbt import DbtCloudCredentials\n\n        credentials_block = DbtCloudCredentials.load(\"test-account\")\n        metadata_client = credentials_block.get_metadata_client()\n        query = \\\"\\\"\\\"\n        {\n            metrics(jobId: 123) {\n                uniqueId\n                name\n                packageName\n                tags\n                label\n                runId\n                description\n                type\n                sql\n                timestamp\n                timeGrains\n                dimensions\n                meta\n                resourceType\n                filters {\n                    field\n                    operator\n                    value\n                }\n                model {\n                    name\n                }\n            }\n        }\n        \\\"\\\"\\\"\n        metadata_client.query(query)\n        # Result:\n        # {\n        #   \"data\": {\n        #     \"metrics\": [\n        #       {\n        #         \"uniqueId\": \"metric.tpch.total_revenue\",\n        #         \"name\": \"total_revenue\",\n        #         \"packageName\": \"tpch\",\n        #         \"tags\": [],\n        #         \"label\": \"Total Revenue ($)\",\n        #         \"runId\": 108952046,\n        #         \"description\": \"\",\n        #         \"type\": \"sum\",\n        #         \"sql\": \"net_item_sales_amount\",\n        #         \"timestamp\": \"order_date\",\n        #         \"timeGrains\": [\"day\", \"week\", \"month\"],\n        #         \"dimensions\": [\"status_code\", \"priority_code\"],\n        #         \"meta\": {},\n        #         \"resourceType\": \"metric\",\n        #         \"filters\": [],\n        #         \"model\": { \"name\": \"fct_orders\" }\n        #       }\n        #     ]\n        #   }\n        # }\n        ```\n\n    Returns:\n        An authenticated dbt Cloud metadata API client.\n    \"\"\"\n    return DbtCloudMetadataClient(\n        api_key=self.api_key.get_secret_value(),\n        domain=f\"metadata.{self.domain}\",\n    )\n</code></pre>"},{"location":"cloud/jobs/","title":"Jobs","text":""},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs","title":"<code>prefect_dbt.cloud.jobs</code>","text":"<p>Module containing tasks and flows for interacting with dbt Cloud jobs</p>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs-classes","title":"Classes","text":""},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJob","title":"<code>DbtCloudJob</code>","text":"<p>             Bases: <code>JobBlock</code></p> <p>Block that holds the information and methods to interact with a dbt Cloud job.</p> <p>Attributes:</p> Name Type Description <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>The credentials to use to authenticate with dbt Cloud.</p> <code>job_id</code> <code>int</code> <p>The id of the dbt Cloud job.</p> <code>timeout_seconds</code> <code>int</code> <p>The number of seconds to wait for the job to complete.</p> <code>interval_seconds</code> <code>int</code> <p>The number of seconds to wait between polling for job completion.</p> <code>trigger_job_run_options</code> <code>TriggerJobRunOptions</code> <p>The options to use when triggering a job run.</p> <p>Examples:</p> <p>Load a configured dbt Cloud job block. <pre><code>from prefect_dbt.cloud import DbtCloudJob\n\ndbt_cloud_job = DbtCloudJob.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Triggers a dbt Cloud job, waits for completion, and fetches the results. <pre><code>from prefect import flow\nfrom prefect_dbt.cloud import DbtCloudCredentials, DbtCloudJob\n\n@flow\ndef dbt_cloud_job_flow():\n    dbt_cloud_credentials = DbtCloudCredentials.load(\"dbt-token\")\n    dbt_cloud_job = DbtCloudJob.load(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        job_id=154217\n    )\n    dbt_cloud_job_run = dbt_cloud_job.trigger()\n    dbt_cloud_job_run.wait_for_completion()\n    dbt_cloud_job_run.fetch_result()\n    return dbt_cloud_job_run\n\ndbt_cloud_job_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>class DbtCloudJob(JobBlock):\n    \"\"\"\n    Block that holds the information and methods to interact with a dbt Cloud job.\n\n    Attributes:\n        dbt_cloud_credentials: The credentials to use to authenticate with dbt Cloud.\n        job_id: The id of the dbt Cloud job.\n        timeout_seconds: The number of seconds to wait for the job to complete.\n        interval_seconds:\n            The number of seconds to wait between polling for job completion.\n        trigger_job_run_options: The options to use when triggering a job run.\n\n    Examples:\n        Load a configured dbt Cloud job block.\n        ```python\n        from prefect_dbt.cloud import DbtCloudJob\n\n        dbt_cloud_job = DbtCloudJob.load(\"BLOCK_NAME\")\n        ```\n\n        Triggers a dbt Cloud job, waits for completion, and fetches the results.\n        ```python\n        from prefect import flow\n        from prefect_dbt.cloud import DbtCloudCredentials, DbtCloudJob\n\n        @flow\n        def dbt_cloud_job_flow():\n            dbt_cloud_credentials = DbtCloudCredentials.load(\"dbt-token\")\n            dbt_cloud_job = DbtCloudJob.load(\n                dbt_cloud_credentials=dbt_cloud_credentials,\n                job_id=154217\n            )\n            dbt_cloud_job_run = dbt_cloud_job.trigger()\n            dbt_cloud_job_run.wait_for_completion()\n            dbt_cloud_job_run.fetch_result()\n            return dbt_cloud_job_run\n\n        dbt_cloud_job_flow()\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt Cloud Job\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJob\"  # noqa\n\n    dbt_cloud_credentials: DbtCloudCredentials = Field(\n        default=...,\n        description=\"The dbt Cloud credentials to use to authenticate with dbt Cloud.\",\n    )  # noqa: E501\n    job_id: int = Field(\n        default=..., description=\"The id of the dbt Cloud job.\", title=\"Job ID\"\n    )\n    timeout_seconds: int = Field(\n        default=900,\n        description=\"The number of seconds to wait for the job to complete.\",\n    )\n    interval_seconds: int = Field(\n        default=10,\n        description=\"The number of seconds to wait between polling for job completion.\",\n    )\n    trigger_job_run_options: TriggerJobRunOptions = Field(\n        default_factory=TriggerJobRunOptions,\n        description=\"The options to use when triggering a job run.\",\n    )\n\n    @sync_compatible\n    async def get_job(self, order_by: Optional[str] = None) -&gt; Dict[str, Any]:\n        \"\"\"\n        Retrieve information about a dbt Cloud job.\n\n        Args:\n            order_by: The field to order the results by.\n\n        Returns:\n            The job data.\n        \"\"\"\n        try:\n            async with self.dbt_cloud_credentials.get_administrative_client() as client:\n                response = await client.get_job(\n                    job_id=self.job_id,\n                    order_by=order_by,\n                )\n        except HTTPStatusError as ex:\n            raise DbtCloudGetJobFailed(extract_user_message(ex)) from ex\n        return response.json()[\"data\"]\n\n    @sync_compatible\n    async def trigger(\n        self, trigger_job_run_options: Optional[TriggerJobRunOptions] = None\n    ) -&gt; DbtCloudJobRun:\n        \"\"\"\n        Triggers a dbt Cloud job.\n\n        Returns:\n            A representation of the dbt Cloud job run.\n        \"\"\"\n        try:\n            trigger_job_run_options = (\n                trigger_job_run_options or self.trigger_job_run_options\n            )\n            async with self.dbt_cloud_credentials.get_administrative_client() as client:\n                response = await client.trigger_job_run(\n                    job_id=self.job_id, options=trigger_job_run_options\n                )\n        except HTTPStatusError as ex:\n            raise DbtCloudJobRunTriggerFailed(extract_user_message(ex)) from ex\n\n        run_data = response.json()[\"data\"]\n        run_id = run_data.get(\"id\")\n        run = DbtCloudJobRun(\n            dbt_cloud_job=self,\n            run_id=run_id,\n        )\n        self.logger.info(\n            f\"dbt Cloud job {self.job_id} run {run_id} successfully triggered. \"\n            f\"You can view the status of this run at \"\n            f\"https://{self.dbt_cloud_credentials.domain}/#/accounts/\"\n            f\"{self.dbt_cloud_credentials.account_id}/projects/\"\n            f\"{run_data['project_id']}/runs/{run_id}/\"\n        )\n        return run\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJob-functions","title":"Functions","text":""},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJob.get_job","title":"<code>get_job</code>  <code>async</code>","text":"<p>Retrieve information about a dbt Cloud job.</p> <p>Parameters:</p> Name Type Description Default <code>order_by</code> <code>Optional[str]</code> <p>The field to order the results by.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The job data.</p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@sync_compatible\nasync def get_job(self, order_by: Optional[str] = None) -&gt; Dict[str, Any]:\n    \"\"\"\n    Retrieve information about a dbt Cloud job.\n\n    Args:\n        order_by: The field to order the results by.\n\n    Returns:\n        The job data.\n    \"\"\"\n    try:\n        async with self.dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.get_job(\n                job_id=self.job_id,\n                order_by=order_by,\n            )\n    except HTTPStatusError as ex:\n        raise DbtCloudGetJobFailed(extract_user_message(ex)) from ex\n    return response.json()[\"data\"]\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJob.trigger","title":"<code>trigger</code>  <code>async</code>","text":"<p>Triggers a dbt Cloud job.</p> <p>Returns:</p> Type Description <code>DbtCloudJobRun</code> <p>A representation of the dbt Cloud job run.</p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@sync_compatible\nasync def trigger(\n    self, trigger_job_run_options: Optional[TriggerJobRunOptions] = None\n) -&gt; DbtCloudJobRun:\n    \"\"\"\n    Triggers a dbt Cloud job.\n\n    Returns:\n        A representation of the dbt Cloud job run.\n    \"\"\"\n    try:\n        trigger_job_run_options = (\n            trigger_job_run_options or self.trigger_job_run_options\n        )\n        async with self.dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.trigger_job_run(\n                job_id=self.job_id, options=trigger_job_run_options\n            )\n    except HTTPStatusError as ex:\n        raise DbtCloudJobRunTriggerFailed(extract_user_message(ex)) from ex\n\n    run_data = response.json()[\"data\"]\n    run_id = run_data.get(\"id\")\n    run = DbtCloudJobRun(\n        dbt_cloud_job=self,\n        run_id=run_id,\n    )\n    self.logger.info(\n        f\"dbt Cloud job {self.job_id} run {run_id} successfully triggered. \"\n        f\"You can view the status of this run at \"\n        f\"https://{self.dbt_cloud_credentials.domain}/#/accounts/\"\n        f\"{self.dbt_cloud_credentials.account_id}/projects/\"\n        f\"{run_data['project_id']}/runs/{run_id}/\"\n    )\n    return run\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJobRun","title":"<code>DbtCloudJobRun</code>","text":"<p>             Bases: <code>JobRun</code></p> <p>Class that holds the information and methods to interact with the resulting run of a dbt Cloud job.</p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>class DbtCloudJobRun(JobRun):  # NOT A BLOCK\n    \"\"\"\n    Class that holds the information and methods to interact\n    with the resulting run of a dbt Cloud job.\n    \"\"\"\n\n    def __init__(self, run_id: int, dbt_cloud_job: \"DbtCloudJob\"):\n        self.run_id = run_id\n        self._dbt_cloud_job = dbt_cloud_job\n        self._dbt_cloud_credentials = dbt_cloud_job.dbt_cloud_credentials\n\n    @property\n    def _log_prefix(self):\n        return f\"dbt Cloud job {self._dbt_cloud_job.job_id} run {self.run_id}.\"\n\n    async def _wait_until_state(\n        self,\n        in_final_state_fn: Awaitable[Callable],\n        get_state_fn: Awaitable[Callable],\n        log_state_fn: Callable = None,\n        timeout_seconds: int = 60,\n        interval_seconds: int = 1,\n    ):\n        \"\"\"\n        Wait until the job run reaches a specific state.\n\n        Args:\n            in_final_state_fn: An async function that accepts a run state\n                and returns a boolean indicating whether the job run is\n                in a final state.\n            get_state_fn: An async function that returns\n                the current state of the job run.\n            log_state_fn: A callable that accepts a run\n                state and makes it human readable.\n            timeout_seconds: The maximum amount of time, in seconds, to wait\n                for the job run to reach the final state.\n            interval_seconds: The number of seconds to wait between checks of\n                the job run's state.\n        \"\"\"\n        start_time = time.time()\n        last_state = run_state = None\n        while not in_final_state_fn(run_state):\n            run_state = await get_state_fn()\n            if run_state != last_state:\n                if self.logger is not None:\n                    self.logger.info(\n                        \"%s has new state: %s\",\n                        self._log_prefix,\n                        log_state_fn(run_state),\n                    )\n                last_state = run_state\n\n            elapsed_time_seconds = time.time() - start_time\n            if elapsed_time_seconds &gt; timeout_seconds:\n                raise DbtCloudJobRunTimedOut(\n                    f\"Max wait time of {timeout_seconds} \"\n                    \"seconds exceeded while waiting\"\n                )\n            await asyncio.sleep(interval_seconds)\n\n    @sync_compatible\n    async def get_run(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Makes a request to the dbt Cloud API to get the run data.\n\n        Returns:\n            The run data.\n        \"\"\"\n        try:\n            dbt_cloud_credentials = self._dbt_cloud_credentials\n            async with dbt_cloud_credentials.get_administrative_client() as client:\n                response = await client.get_run(self.run_id)\n        except HTTPStatusError as ex:\n            raise DbtCloudGetRunFailed(extract_user_message(ex)) from ex\n        run_data = response.json()[\"data\"]\n        return run_data\n\n    @sync_compatible\n    async def get_status_code(self) -&gt; int:\n        \"\"\"\n        Makes a request to the dbt Cloud API to get the run status.\n\n        Returns:\n            The run status code.\n        \"\"\"\n        run_data = await self.get_run()\n        run_status_code = run_data.get(\"status\")\n        return run_status_code\n\n    @sync_compatible\n    async def wait_for_completion(self) -&gt; None:\n        \"\"\"\n        Waits for the job run to reach a terminal state.\n        \"\"\"\n        await self._wait_until_state(\n            in_final_state_fn=DbtCloudJobRunStatus.is_terminal_status_code,\n            get_state_fn=self.get_status_code,\n            log_state_fn=DbtCloudJobRunStatus,\n            timeout_seconds=self._dbt_cloud_job.timeout_seconds,\n            interval_seconds=self._dbt_cloud_job.interval_seconds,\n        )\n\n    @sync_compatible\n    async def fetch_result(self, step: Optional[int] = None) -&gt; Dict[str, Any]:\n        \"\"\"\n        Gets the results from the job run. Since the results\n        may not be ready, use wait_for_completion before calling this method.\n\n        Args:\n            step: The index of the step in the run to query for artifacts. The\n                first step in the run has the index 1. If the step parameter is\n                omitted, then this method will return the artifacts compiled\n                for the last step in the run.\n        \"\"\"\n        run_data = await self.get_run()\n        run_status = DbtCloudJobRunStatus(run_data.get(\"status\"))\n        if run_status == DbtCloudJobRunStatus.SUCCESS:\n            try:\n                async with self._dbt_cloud_credentials.get_administrative_client() as client:  # noqa\n                    response = await client.list_run_artifacts(\n                        run_id=self.run_id, step=step\n                    )\n                run_data[\"artifact_paths\"] = response.json()[\"data\"]\n                self.logger.info(\"%s completed successfully!\", self._log_prefix)\n            except HTTPStatusError as ex:\n                raise DbtCloudListRunArtifactsFailed(extract_user_message(ex)) from ex\n            return run_data\n        elif run_status == DbtCloudJobRunStatus.CANCELLED:\n            raise DbtCloudJobRunCancelled(f\"{self._log_prefix} was cancelled.\")\n        elif run_status == DbtCloudJobRunStatus.FAILED:\n            raise DbtCloudJobRunFailed(f\"{self._log_prefix} has failed.\")\n        else:\n            raise DbtCloudJobRunIncomplete(\n                f\"{self._log_prefix} is still running; \"\n                \"use wait_for_completion() to wait until results are ready.\"\n            )\n\n    @sync_compatible\n    async def get_run_artifacts(\n        self,\n        path: Literal[\"manifest.json\", \"catalog.json\", \"run_results.json\"],\n        step: Optional[int] = None,\n    ) -&gt; Union[Dict[str, Any], str]:\n        \"\"\"\n        Get an artifact generated for a completed run.\n\n        Args:\n            path: The relative path to the run artifact.\n            step: The index of the step in the run to query for artifacts. The\n                first step in the run has the index 1. If the step parameter is\n                omitted, then this method will return the artifacts compiled\n                for the last step in the run.\n\n        Returns:\n            The contents of the requested manifest. Returns a `Dict` if the\n                requested artifact is a JSON file and a `str` otherwise.\n        \"\"\"\n        try:\n            dbt_cloud_credentials = self._dbt_cloud_credentials\n            async with dbt_cloud_credentials.get_administrative_client() as client:\n                response = await client.get_run_artifact(\n                    run_id=self.run_id, path=path, step=step\n                )\n        except HTTPStatusError as ex:\n            raise DbtCloudGetRunArtifactFailed(extract_user_message(ex)) from ex\n\n        if path.endswith(\".json\"):\n            artifact_contents = response.json()\n        else:\n            artifact_contents = response.text\n        return artifact_contents\n\n    def _select_unsuccessful_commands(\n        self,\n        run_results: List[Dict[str, Any]],\n        command_components: List[str],\n        command: str,\n        exe_command: str,\n    ) -&gt; List[str]:\n        \"\"\"\n        Select nodes that were not successful and rebuild a command.\n        \"\"\"\n        # note \"fail\" here instead of \"cancelled\" because\n        # nodes do not have a cancelled state\n        run_nodes = \" \".join(\n            run_result[\"unique_id\"].split(\".\")[2]\n            for run_result in run_results\n            if run_result[\"status\"] in (\"error\", \"skipped\", \"fail\")\n        )\n\n        select_arg = None\n        if \"-s\" in command_components:\n            select_arg = \"-s\"\n        elif \"--select\" in command_components:\n            select_arg = \"--select\"\n\n        # prevent duplicate --select/-s statements\n        if select_arg is not None:\n            # dbt --fail-fast run, -s, bad_mod --vars '{\"env\": \"prod\"}' to:\n            # dbt --fail-fast run -s other_mod bad_mod --vars '{\"env\": \"prod\"}'\n            command_start, select_arg, command_end = command.partition(select_arg)\n            modified_command = (\n                f\"{command_start} {select_arg} {run_nodes} {command_end}\"  # noqa\n            )\n        else:\n            # dbt --fail-fast, build, --vars '{\"env\": \"prod\"}' to:\n            # dbt --fail-fast build --select bad_model --vars '{\"env\": \"prod\"}'\n            dbt_global_args, exe_command, exe_args = command.partition(exe_command)\n            modified_command = (\n                f\"{dbt_global_args} {exe_command} -s {run_nodes} {exe_args}\"\n            )\n        return modified_command\n\n    async def _build_trigger_job_run_options(\n        self,\n        job: Dict[str, Any],\n        run: Dict[str, Any],\n    ) -&gt; TriggerJobRunOptions:\n        \"\"\"\n        Compiles a list of steps (commands) to retry, then either build trigger job\n        run options from scratch if it does not exist, else overrides the existing.\n        \"\"\"\n        generate_docs = job.get(\"generate_docs\", False)\n        generate_sources = job.get(\"generate_sources\", False)\n\n        steps_override = []\n        for run_step in run[\"run_steps\"]:\n            status = run_step[\"status_humanized\"].lower()\n            # Skipping cloning, profile setup, and dbt deps - always the first three\n            # steps in any run, and note, index starts at 1 instead of 0\n            if run_step[\"index\"] &lt;= 3 or status == \"success\":\n                continue\n            # get dbt build from \"Invoke dbt with `dbt build`\"\n            command = run_step[\"name\"].partition(\"`\")[2].partition(\"`\")[0]\n\n            # These steps will be re-run regardless if\n            # generate_docs or generate_sources are enabled for a given job\n            # so if we don't skip, it'll run twice\n            freshness_in_command = (\n                \"dbt source snapshot-freshness\" in command\n                or \"dbt source freshness\" in command\n            )\n            if \"dbt docs generate\" in command and generate_docs:\n                continue\n            elif freshness_in_command and generate_sources:\n                continue\n\n            # find an executable command like `build` or `run`\n            # search in a list so that there aren't false positives, like\n            # `\"run\" in \"dbt run-operation\"`, which is True; we actually want\n            # `\"run\" in [\"dbt\", \"run-operation\"]` which is False\n            command_components = shlex.split(command)\n            for exe_command in EXE_COMMANDS:\n                if exe_command in command_components:\n                    break\n            else:\n                exe_command = \"\"\n\n            is_exe_command = exe_command in EXE_COMMANDS\n            is_not_success = status in (\"error\", \"skipped\", \"cancelled\")\n            is_skipped = status == \"skipped\"\n            if (not is_exe_command and is_not_success) or (\n                is_exe_command and is_skipped\n            ):\n                # if no matches like `run-operation`, we will be rerunning entirely\n                # or if it's one of the expected commands and is skipped\n                steps_override.append(command)\n            else:\n                # errors and failures are when we need to inspect to figure\n                # out the point of failure\n                try:\n                    run_artifact = await self.get_run_artifacts(\n                        \"run_results.json\", run_step[\"index\"]\n                    )\n                except JSONDecodeError:\n                    # get the run results scoped to the step which had an error\n                    # an error here indicates that either:\n                    # 1) the fail-fast flag was set, in which case\n                    #    the run_results.json file was never created; or\n                    # 2) there was a problem on dbt Cloud's side saving\n                    #    this artifact\n                    steps_override.append(command)\n                else:\n                    # we only need to find the individual nodes\n                    # for those run commands\n                    run_results = run_artifact[\"results\"]\n                    modified_command = self._select_unsuccessful_commands(\n                        run_results=run_results,\n                        command_components=command_components,\n                        command=command,\n                        exe_command=exe_command,\n                    )\n                    steps_override.append(modified_command)\n\n        if self._dbt_cloud_job.trigger_job_run_options is None:\n            trigger_job_run_options_override = TriggerJobRunOptions(\n                steps_override=steps_override\n            )\n        else:\n            trigger_job_run_options_override = (\n                self._dbt_cloud_job.trigger_job_run_options.copy()\n            )\n            trigger_job_run_options_override.steps_override = steps_override\n        return trigger_job_run_options_override\n\n    @sync_compatible\n    async def retry_failed_steps(self) -&gt; \"DbtCloudJobRun\":  # noqa: F821\n        \"\"\"\n        Retries steps that did not complete successfully in a run.\n\n        Returns:\n            A representation of the dbt Cloud job run.\n        \"\"\"\n        job = await self._dbt_cloud_job.get_job()\n        run = await self.get_run()\n\n        trigger_job_run_options_override = await self._build_trigger_job_run_options(\n            job=job, run=run\n        )\n\n        num_steps = len(trigger_job_run_options_override.steps_override)\n        if num_steps == 0:\n            self.logger.info(f\"{self._log_prefix} does not have any steps to retry.\")\n        else:\n            self.logger.info(f\"{self._log_prefix} has {num_steps} steps to retry.\")\n            run = await self._dbt_cloud_job.trigger(\n                trigger_job_run_options=trigger_job_run_options_override,\n            )\n        return run\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJobRun-functions","title":"Functions","text":""},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJobRun.fetch_result","title":"<code>fetch_result</code>  <code>async</code>","text":"<p>Gets the results from the job run. Since the results may not be ready, use wait_for_completion before calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>step</code> <code>Optional[int]</code> <p>The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run.</p> <code>None</code> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@sync_compatible\nasync def fetch_result(self, step: Optional[int] = None) -&gt; Dict[str, Any]:\n    \"\"\"\n    Gets the results from the job run. Since the results\n    may not be ready, use wait_for_completion before calling this method.\n\n    Args:\n        step: The index of the step in the run to query for artifacts. The\n            first step in the run has the index 1. If the step parameter is\n            omitted, then this method will return the artifacts compiled\n            for the last step in the run.\n    \"\"\"\n    run_data = await self.get_run()\n    run_status = DbtCloudJobRunStatus(run_data.get(\"status\"))\n    if run_status == DbtCloudJobRunStatus.SUCCESS:\n        try:\n            async with self._dbt_cloud_credentials.get_administrative_client() as client:  # noqa\n                response = await client.list_run_artifacts(\n                    run_id=self.run_id, step=step\n                )\n            run_data[\"artifact_paths\"] = response.json()[\"data\"]\n            self.logger.info(\"%s completed successfully!\", self._log_prefix)\n        except HTTPStatusError as ex:\n            raise DbtCloudListRunArtifactsFailed(extract_user_message(ex)) from ex\n        return run_data\n    elif run_status == DbtCloudJobRunStatus.CANCELLED:\n        raise DbtCloudJobRunCancelled(f\"{self._log_prefix} was cancelled.\")\n    elif run_status == DbtCloudJobRunStatus.FAILED:\n        raise DbtCloudJobRunFailed(f\"{self._log_prefix} has failed.\")\n    else:\n        raise DbtCloudJobRunIncomplete(\n            f\"{self._log_prefix} is still running; \"\n            \"use wait_for_completion() to wait until results are ready.\"\n        )\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJobRun.get_run","title":"<code>get_run</code>  <code>async</code>","text":"<p>Makes a request to the dbt Cloud API to get the run data.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The run data.</p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@sync_compatible\nasync def get_run(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Makes a request to the dbt Cloud API to get the run data.\n\n    Returns:\n        The run data.\n    \"\"\"\n    try:\n        dbt_cloud_credentials = self._dbt_cloud_credentials\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.get_run(self.run_id)\n    except HTTPStatusError as ex:\n        raise DbtCloudGetRunFailed(extract_user_message(ex)) from ex\n    run_data = response.json()[\"data\"]\n    return run_data\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJobRun.get_run_artifacts","title":"<code>get_run_artifacts</code>  <code>async</code>","text":"<p>Get an artifact generated for a completed run.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Literal['manifest.json', 'catalog.json', 'run_results.json']</code> <p>The relative path to the run artifact.</p> required <code>step</code> <code>Optional[int]</code> <p>The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>The contents of the requested manifest. Returns a <code>Dict</code> if the requested artifact is a JSON file and a <code>str</code> otherwise.</p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@sync_compatible\nasync def get_run_artifacts(\n    self,\n    path: Literal[\"manifest.json\", \"catalog.json\", \"run_results.json\"],\n    step: Optional[int] = None,\n) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Get an artifact generated for a completed run.\n\n    Args:\n        path: The relative path to the run artifact.\n        step: The index of the step in the run to query for artifacts. The\n            first step in the run has the index 1. If the step parameter is\n            omitted, then this method will return the artifacts compiled\n            for the last step in the run.\n\n    Returns:\n        The contents of the requested manifest. Returns a `Dict` if the\n            requested artifact is a JSON file and a `str` otherwise.\n    \"\"\"\n    try:\n        dbt_cloud_credentials = self._dbt_cloud_credentials\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.get_run_artifact(\n                run_id=self.run_id, path=path, step=step\n            )\n    except HTTPStatusError as ex:\n        raise DbtCloudGetRunArtifactFailed(extract_user_message(ex)) from ex\n\n    if path.endswith(\".json\"):\n        artifact_contents = response.json()\n    else:\n        artifact_contents = response.text\n    return artifact_contents\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJobRun.get_status_code","title":"<code>get_status_code</code>  <code>async</code>","text":"<p>Makes a request to the dbt Cloud API to get the run status.</p> <p>Returns:</p> Type Description <code>int</code> <p>The run status code.</p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@sync_compatible\nasync def get_status_code(self) -&gt; int:\n    \"\"\"\n    Makes a request to the dbt Cloud API to get the run status.\n\n    Returns:\n        The run status code.\n    \"\"\"\n    run_data = await self.get_run()\n    run_status_code = run_data.get(\"status\")\n    return run_status_code\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJobRun.retry_failed_steps","title":"<code>retry_failed_steps</code>  <code>async</code>","text":"<p>Retries steps that did not complete successfully in a run.</p> <p>Returns:</p> Type Description <code>DbtCloudJobRun</code> <p>A representation of the dbt Cloud job run.</p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@sync_compatible\nasync def retry_failed_steps(self) -&gt; \"DbtCloudJobRun\":  # noqa: F821\n    \"\"\"\n    Retries steps that did not complete successfully in a run.\n\n    Returns:\n        A representation of the dbt Cloud job run.\n    \"\"\"\n    job = await self._dbt_cloud_job.get_job()\n    run = await self.get_run()\n\n    trigger_job_run_options_override = await self._build_trigger_job_run_options(\n        job=job, run=run\n    )\n\n    num_steps = len(trigger_job_run_options_override.steps_override)\n    if num_steps == 0:\n        self.logger.info(f\"{self._log_prefix} does not have any steps to retry.\")\n    else:\n        self.logger.info(f\"{self._log_prefix} has {num_steps} steps to retry.\")\n        run = await self._dbt_cloud_job.trigger(\n            trigger_job_run_options=trigger_job_run_options_override,\n        )\n    return run\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJobRun.wait_for_completion","title":"<code>wait_for_completion</code>  <code>async</code>","text":"<p>Waits for the job run to reach a terminal state.</p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@sync_compatible\nasync def wait_for_completion(self) -&gt; None:\n    \"\"\"\n    Waits for the job run to reach a terminal state.\n    \"\"\"\n    await self._wait_until_state(\n        in_final_state_fn=DbtCloudJobRunStatus.is_terminal_status_code,\n        get_state_fn=self.get_status_code,\n        log_state_fn=DbtCloudJobRunStatus,\n        timeout_seconds=self._dbt_cloud_job.timeout_seconds,\n        interval_seconds=self._dbt_cloud_job.interval_seconds,\n    )\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs-functions","title":"Functions","text":""},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.get_dbt_cloud_job_info","title":"<code>get_dbt_cloud_job_info</code>  <code>async</code>","text":"<p>A task to retrieve information about a dbt Cloud job.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>job_id</code> <code>int</code> <p>The ID of the job to get.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>The job data returned by the dbt Cloud administrative API.</p> Example <p>Get status of a dbt Cloud job: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import get_job\n\n@flow\ndef get_job_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    return get_job(\n        dbt_cloud_credentials=credentials,\n        job_id=42\n    )\n\nget_job_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@task(\n    name=\"Get dbt Cloud job details\",\n    description=\"Retrieves details of a dbt Cloud job \"\n    \"for the job with the given job_id.\",\n    retries=3,\n    retry_delay_seconds=10,\n)\nasync def get_dbt_cloud_job_info(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    job_id: int,\n    order_by: Optional[str] = None,\n) -&gt; Dict:\n    \"\"\"\n    A task to retrieve information about a dbt Cloud job.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        job_id: The ID of the job to get.\n\n    Returns:\n        The job data returned by the dbt Cloud administrative API.\n\n    Example:\n        Get status of a dbt Cloud job:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import get_job\n\n        @flow\n        def get_job_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            return get_job(\n                dbt_cloud_credentials=credentials,\n                job_id=42\n            )\n\n        get_job_flow()\n        ```\n    \"\"\"  # noqa\n    try:\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.get_job(\n                job_id=job_id,\n                order_by=order_by,\n            )\n    except HTTPStatusError as ex:\n        raise DbtCloudGetJobFailed(extract_user_message(ex)) from ex\n    return response.json()[\"data\"]\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.get_run_id","title":"<code>get_run_id</code>","text":"<p>Task that extracts the run ID from a trigger job run API response,</p> <p>This task is mainly used to maintain dependency tracking between the <code>trigger_dbt_cloud_job_run</code> task and downstream tasks/flows that use the run ID.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Dict</code> <p>The JSON body from the trigger job run response.</p> required Example <pre><code>from prefect import flow\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run, get_run_id\n\n\n@flow\ndef trigger_run_and_get_id():\n    dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        )\n\n    triggered_run_data = trigger_dbt_cloud_job_run(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        job_id=job_id,\n        options=trigger_job_run_options,\n    )\n    run_id = get_run_id.submit(triggered_run_data)\n    return run_id\n\ntrigger_run_and_get_id()\n</code></pre> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@task(\n    name=\"Get dbt Cloud job run ID\",\n    description=\"Extracts the run ID from a trigger job run API response\",\n)\ndef get_run_id(obj: Dict):\n    \"\"\"\n    Task that extracts the run ID from a trigger job run API response,\n\n    This task is mainly used to maintain dependency tracking between the\n    `trigger_dbt_cloud_job_run` task and downstream tasks/flows that use the run ID.\n\n    Args:\n        obj: The JSON body from the trigger job run response.\n\n    Example:\n        ```python\n        from prefect import flow\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run, get_run_id\n\n\n        @flow\n        def trigger_run_and_get_id():\n            dbt_cloud_credentials=DbtCloudCredentials(\n                    api_key=\"my_api_key\",\n                    account_id=123456789\n                )\n\n            triggered_run_data = trigger_dbt_cloud_job_run(\n                dbt_cloud_credentials=dbt_cloud_credentials,\n                job_id=job_id,\n                options=trigger_job_run_options,\n            )\n            run_id = get_run_id.submit(triggered_run_data)\n            return run_id\n\n        trigger_run_and_get_id()\n        ```\n    \"\"\"\n    id = obj.get(\"id\")\n    if id is None:\n        raise RuntimeError(\"Unable to determine run ID for triggered job.\")\n    return id\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.retry_dbt_cloud_job_run_subset_and_wait_for_completion","title":"<code>retry_dbt_cloud_job_run_subset_and_wait_for_completion</code>  <code>async</code>","text":"<p>Flow that retrys a subset of dbt Cloud job run, filtered by select statuses, and waits for the triggered retry to complete.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>trigger_job_run_options</code> <code>Optional[TriggerJobRunOptions]</code> <p>An optional TriggerJobRunOptions instance to specify overrides for the triggered job run.</p> <code>None</code> <code>max_wait_seconds</code> <code>int</code> <p>Maximum number of seconds to wait for job to complete</p> <code>900</code> <code>poll_frequency_seconds</code> <code>int</code> <p>Number of seconds to wait in between checks for run completion.</p> <code>10</code> <code>run_id</code> <code>int</code> <p>The ID of the job run to retry.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>trigger_job_run_options.steps_override</code> is set by the user.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>The run data returned by the dbt Cloud administrative API.</p> <p>Examples:</p> <p>Retry a subset of models in a dbt Cloud job run and wait for completion: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import retry_dbt_cloud_job_run_subset_and_wait_for_completion\n\n@flow\ndef retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow():\n    credentials = DbtCloudCredentials.load(\"MY_BLOCK_NAME\")\n    retry_dbt_cloud_job_run_subset_and_wait_for_completion(\n        dbt_cloud_credentials=credentials,\n        run_id=88640123,\n    )\n\nretry_dbt_cloud_job_run_subset_and_wait_for_completion_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@flow(\n    name=\"Retry subset of dbt Cloud job run and wait for completion\",\n    description=(\n        \"Retries a subset of dbt Cloud job run, filtered by select statuses, \"\n        \"and waits for the triggered retry to complete.\"\n    ),\n)\nasync def retry_dbt_cloud_job_run_subset_and_wait_for_completion(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    run_id: int,\n    trigger_job_run_options: Optional[TriggerJobRunOptions] = None,\n    max_wait_seconds: int = 900,\n    poll_frequency_seconds: int = 10,\n) -&gt; Dict:\n    \"\"\"\n    Flow that retrys a subset of dbt Cloud job run, filtered by select statuses,\n    and waits for the triggered retry to complete.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        trigger_job_run_options: An optional TriggerJobRunOptions instance to\n            specify overrides for the triggered job run.\n        max_wait_seconds: Maximum number of seconds to wait for job to complete\n        poll_frequency_seconds: Number of seconds to wait in between checks for\n            run completion.\n        run_id: The ID of the job run to retry.\n\n    Raises:\n        ValueError: If `trigger_job_run_options.steps_override` is set by the user.\n\n    Returns:\n        The run data returned by the dbt Cloud administrative API.\n\n    Examples:\n        Retry a subset of models in a dbt Cloud job run and wait for completion:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import retry_dbt_cloud_job_run_subset_and_wait_for_completion\n\n        @flow\n        def retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow():\n            credentials = DbtCloudCredentials.load(\"MY_BLOCK_NAME\")\n            retry_dbt_cloud_job_run_subset_and_wait_for_completion(\n                dbt_cloud_credentials=credentials,\n                run_id=88640123,\n            )\n\n        retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow()\n        ```\n    \"\"\"  # noqa\n    if trigger_job_run_options and trigger_job_run_options.steps_override is not None:\n        raise ValueError(\n            \"Do not set `steps_override` in `trigger_job_run_options` \"\n            \"because this flow will automatically set it\"\n        )\n\n    run_info_future = await get_dbt_cloud_run_info.submit(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        run_id=run_id,\n        include_related=[\"run_steps\"],\n    )\n    run_info = await run_info_future.result()\n\n    job_id = run_info[\"job_id\"]\n    job_info_future = await get_dbt_cloud_job_info.submit(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        job_id=job_id,\n    )\n    job_info = await job_info_future.result()\n\n    trigger_job_run_options_override = await _build_trigger_job_run_options(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        trigger_job_run_options=trigger_job_run_options,\n        run_id=run_id,\n        run_info=run_info,\n        job_info=job_info,\n    )\n\n    # to circumvent `RuntimeError: The task runner is already started!`\n    flow_run_context = FlowRunContext.get()\n    task_runner_type = type(flow_run_context.task_runner)\n\n    run_data = await trigger_dbt_cloud_job_run_and_wait_for_completion.with_options(\n        task_runner=task_runner_type()\n    )(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        job_id=job_id,\n        retry_filtered_models_attempts=0,\n        trigger_job_run_options=trigger_job_run_options_override,\n        max_wait_seconds=max_wait_seconds,\n        poll_frequency_seconds=poll_frequency_seconds,\n    )\n    return run_data\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.run_dbt_cloud_job","title":"<code>run_dbt_cloud_job</code>  <code>async</code>","text":"<p>Flow that triggers and waits for a dbt Cloud job run, retrying a subset of failed nodes if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_job</code> <code>DbtCloudJob</code> <p>Block that holds the information and methods to interact with a dbt Cloud job.</p> required <code>targeted_retries</code> <code>int</code> <p>The number of times to retry failed steps.</p> <code>3</code> <p>Examples:</p> <pre><code>from prefect import flow\nfrom prefect_dbt.cloud import DbtCloudCredentials, DbtCloudJob\nfrom prefect_dbt.cloud.jobs import run_dbt_cloud_job\n\n@flow\ndef run_dbt_cloud_job_flow():\n    dbt_cloud_credentials = DbtCloudCredentials.load(\"dbt-token\")\n    dbt_cloud_job = DbtCloudJob(\n        dbt_cloud_credentials=dbt_cloud_credentials, job_id=154217\n    )\n    return run_dbt_cloud_job(dbt_cloud_job=dbt_cloud_job)\n\nrun_dbt_cloud_job_flow()\n</code></pre> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@flow\nasync def run_dbt_cloud_job(\n    dbt_cloud_job: DbtCloudJob,\n    targeted_retries: int = 3,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Flow that triggers and waits for a dbt Cloud job run, retrying a\n    subset of failed nodes if necessary.\n\n    Args:\n        dbt_cloud_job: Block that holds the information and\n            methods to interact with a dbt Cloud job.\n        targeted_retries: The number of times to retry failed steps.\n\n    Examples:\n        ```python\n        from prefect import flow\n        from prefect_dbt.cloud import DbtCloudCredentials, DbtCloudJob\n        from prefect_dbt.cloud.jobs import run_dbt_cloud_job\n\n        @flow\n        def run_dbt_cloud_job_flow():\n            dbt_cloud_credentials = DbtCloudCredentials.load(\"dbt-token\")\n            dbt_cloud_job = DbtCloudJob(\n                dbt_cloud_credentials=dbt_cloud_credentials, job_id=154217\n            )\n            return run_dbt_cloud_job(dbt_cloud_job=dbt_cloud_job)\n\n        run_dbt_cloud_job_flow()\n        ```\n    \"\"\"\n    logger = get_run_logger()\n\n    run = await task(dbt_cloud_job.trigger.aio)(dbt_cloud_job)\n    while targeted_retries &gt; 0:\n        try:\n            await task(run.wait_for_completion.aio)(run)\n            result = await task(run.fetch_result.aio)(run)\n            return result\n        except DbtCloudJobRunFailed:\n            logger.info(\n                f\"Retrying job run with ID: {run.run_id} \"\n                f\"{targeted_retries} more times\"\n            )\n            run = await task(run.retry_failed_steps.aio)(run)\n            targeted_retries -= 1\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.trigger_dbt_cloud_job_run","title":"<code>trigger_dbt_cloud_job_run</code>  <code>async</code>","text":"<p>A task to trigger a dbt Cloud job run.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>job_id</code> <code>int</code> <p>The ID of the job to trigger.</p> required <code>options</code> <code>Optional[TriggerJobRunOptions]</code> <p>An optional TriggerJobRunOptions instance to specify overrides for the triggered job run.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict</code> <p>The run data returned from the dbt Cloud administrative API.</p> <p>Examples:</p> <p>Trigger a dbt Cloud job run: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n\n\n@flow\ndef trigger_dbt_cloud_job_run_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1)\n\n\ntrigger_dbt_cloud_job_run_flow()\n</code></pre></p> <p>Trigger a dbt Cloud job run with overrides: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\nfrom prefect_dbt.cloud.models import TriggerJobRunOptions\n\n\n@flow\ndef trigger_dbt_cloud_job_run_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    trigger_dbt_cloud_job_run(\n        dbt_cloud_credentials=credentials,\n        job_id=1,\n        options=TriggerJobRunOptions(\n            git_branch=\"staging\",\n            schema_override=\"dbt_cloud_pr_123\",\n            dbt_version_override=\"0.18.0\",\n            target_name_override=\"staging\",\n            timeout_seconds_override=3000,\n            generate_docs_override=True,\n            threads_override=8,\n            steps_override=[\n                \"dbt seed\",\n                \"dbt run --fail-fast\",\n                \"dbt test --fail-fast\",\n            ],\n        ),\n    )\n\n\ntrigger_dbt_cloud_job_run()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@task(\n    name=\"Trigger dbt Cloud job run\",\n    description=\"Triggers a dbt Cloud job run for the job \"\n    \"with the given job_id and optional overrides.\",\n    retries=3,\n    retry_delay_seconds=10,\n)\nasync def trigger_dbt_cloud_job_run(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    job_id: int,\n    options: Optional[TriggerJobRunOptions] = None,\n) -&gt; Dict:\n    \"\"\"\n    A task to trigger a dbt Cloud job run.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        job_id: The ID of the job to trigger.\n        options: An optional TriggerJobRunOptions instance to specify overrides\n            for the triggered job run.\n\n    Returns:\n        The run data returned from the dbt Cloud administrative API.\n\n    Examples:\n        Trigger a dbt Cloud job run:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n\n\n        @flow\n        def trigger_dbt_cloud_job_run_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1)\n\n\n        trigger_dbt_cloud_job_run_flow()\n        ```\n\n        Trigger a dbt Cloud job run with overrides:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n        from prefect_dbt.cloud.models import TriggerJobRunOptions\n\n\n        @flow\n        def trigger_dbt_cloud_job_run_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            trigger_dbt_cloud_job_run(\n                dbt_cloud_credentials=credentials,\n                job_id=1,\n                options=TriggerJobRunOptions(\n                    git_branch=\"staging\",\n                    schema_override=\"dbt_cloud_pr_123\",\n                    dbt_version_override=\"0.18.0\",\n                    target_name_override=\"staging\",\n                    timeout_seconds_override=3000,\n                    generate_docs_override=True,\n                    threads_override=8,\n                    steps_override=[\n                        \"dbt seed\",\n                        \"dbt run --fail-fast\",\n                        \"dbt test --fail-fast\",\n                    ],\n                ),\n            )\n\n\n        trigger_dbt_cloud_job_run()\n        ```\n    \"\"\"  # noqa\n    logger = get_run_logger()\n\n    logger.info(f\"Triggering run for job with ID {job_id}\")\n\n    try:\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.trigger_job_run(job_id=job_id, options=options)\n    except HTTPStatusError as ex:\n        raise DbtCloudJobRunTriggerFailed(extract_user_message(ex)) from ex\n\n    run_data = response.json()[\"data\"]\n\n    if \"project_id\" in run_data and \"id\" in run_data:\n        logger.info(\n            f\"Run successfully triggered for job with ID {job_id}. \"\n            \"You can view the status of this run at \"\n            f\"https://{dbt_cloud_credentials.domain}/#/accounts/\"\n            f\"{dbt_cloud_credentials.account_id}/projects/{run_data['project_id']}/\"\n            f\"runs/{run_data['id']}/\"\n        )\n\n    return run_data\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.trigger_dbt_cloud_job_run_and_wait_for_completion","title":"<code>trigger_dbt_cloud_job_run_and_wait_for_completion</code>  <code>async</code>","text":"<p>Flow that triggers a job run and waits for the triggered run to complete.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>job_id</code> <code>int</code> <p>The ID of the job to trigger.</p> required <code>trigger_job_run_options</code> <code>Optional[TriggerJobRunOptions]</code> <p>An optional TriggerJobRunOptions instance to specify overrides for the triggered job run.</p> <code>None</code> <code>max_wait_seconds</code> <code>int</code> <p>Maximum number of seconds to wait for job to complete</p> <code>900</code> <code>poll_frequency_seconds</code> <code>int</code> <p>Number of seconds to wait in between checks for run completion.</p> <code>10</code> <code>retry_filtered_models_attempts</code> <code>int</code> <p>Number of times to retry models selected by <code>retry_status_filters</code>.</p> <code>3</code> <p>Raises:</p> Type Description <code>DbtCloudJobRunCancelled</code> <p>The triggered dbt Cloud job run was cancelled.</p> <code>DbtCloudJobRunFailed</code> <p>The triggered dbt Cloud job run failed.</p> <code>RuntimeError</code> <p>The triggered dbt Cloud job run ended in an unexpected state.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>The run data returned by the dbt Cloud administrative API.</p> <p>Examples:</p> <p>Trigger a dbt Cloud job and wait for completion as a stand alone flow: <pre><code>import asyncio\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n\nasyncio.run(\n    trigger_dbt_cloud_job_run_and_wait_for_completion(\n        dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        ),\n        job_id=1\n    )\n)\n</code></pre></p> <p>Trigger a dbt Cloud job and wait for completion as a sub-flow: <pre><code>from prefect import flow\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n\n@flow\ndef my_flow():\n    ...\n    run_result = trigger_dbt_cloud_job_run_and_wait_for_completion(\n        dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        ),\n        job_id=1\n    )\n    ...\n\nmy_flow()\n</code></pre></p> <p>Trigger a dbt Cloud job with overrides: <pre><code>import asyncio\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\nfrom prefect_dbt.cloud.models import TriggerJobRunOptions\n\nasyncio.run(\n    trigger_dbt_cloud_job_run_and_wait_for_completion(\n        dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        ),\n        job_id=1,\n        trigger_job_run_options=TriggerJobRunOptions(\n            git_branch=\"staging\",\n            schema_override=\"dbt_cloud_pr_123\",\n            dbt_version_override=\"0.18.0\",\n            target_name_override=\"staging\",\n            timeout_seconds_override=3000,\n            generate_docs_override=True,\n            threads_override=8,\n            steps_override=[\n                \"dbt seed\",\n                \"dbt run --fail-fast\",\n                \"dbt test --fail fast\",\n            ],\n        ),\n    )\n)\n</code></pre></p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@flow(\n    name=\"Trigger dbt Cloud job run and wait for completion\",\n    description=\"Triggers a dbt Cloud job run and waits for the\"\n    \"triggered run to complete.\",\n)\nasync def trigger_dbt_cloud_job_run_and_wait_for_completion(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    job_id: int,\n    trigger_job_run_options: Optional[TriggerJobRunOptions] = None,\n    max_wait_seconds: int = 900,\n    poll_frequency_seconds: int = 10,\n    retry_filtered_models_attempts: int = 3,\n) -&gt; Dict:\n    \"\"\"\n    Flow that triggers a job run and waits for the triggered run to complete.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        job_id: The ID of the job to trigger.\n        trigger_job_run_options: An optional TriggerJobRunOptions instance to\n            specify overrides for the triggered job run.\n        max_wait_seconds: Maximum number of seconds to wait for job to complete\n        poll_frequency_seconds: Number of seconds to wait in between checks for\n            run completion.\n        retry_filtered_models_attempts: Number of times to retry models selected by `retry_status_filters`.\n\n    Raises:\n        DbtCloudJobRunCancelled: The triggered dbt Cloud job run was cancelled.\n        DbtCloudJobRunFailed: The triggered dbt Cloud job run failed.\n        RuntimeError: The triggered dbt Cloud job run ended in an unexpected state.\n\n    Returns:\n        The run data returned by the dbt Cloud administrative API.\n\n    Examples:\n        Trigger a dbt Cloud job and wait for completion as a stand alone flow:\n        ```python\n        import asyncio\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n\n        asyncio.run(\n            trigger_dbt_cloud_job_run_and_wait_for_completion(\n                dbt_cloud_credentials=DbtCloudCredentials(\n                    api_key=\"my_api_key\",\n                    account_id=123456789\n                ),\n                job_id=1\n            )\n        )\n        ```\n\n        Trigger a dbt Cloud job and wait for completion as a sub-flow:\n        ```python\n        from prefect import flow\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n\n        @flow\n        def my_flow():\n            ...\n            run_result = trigger_dbt_cloud_job_run_and_wait_for_completion(\n                dbt_cloud_credentials=DbtCloudCredentials(\n                    api_key=\"my_api_key\",\n                    account_id=123456789\n                ),\n                job_id=1\n            )\n            ...\n\n        my_flow()\n        ```\n\n        Trigger a dbt Cloud job with overrides:\n        ```python\n        import asyncio\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n        from prefect_dbt.cloud.models import TriggerJobRunOptions\n\n        asyncio.run(\n            trigger_dbt_cloud_job_run_and_wait_for_completion(\n                dbt_cloud_credentials=DbtCloudCredentials(\n                    api_key=\"my_api_key\",\n                    account_id=123456789\n                ),\n                job_id=1,\n                trigger_job_run_options=TriggerJobRunOptions(\n                    git_branch=\"staging\",\n                    schema_override=\"dbt_cloud_pr_123\",\n                    dbt_version_override=\"0.18.0\",\n                    target_name_override=\"staging\",\n                    timeout_seconds_override=3000,\n                    generate_docs_override=True,\n                    threads_override=8,\n                    steps_override=[\n                        \"dbt seed\",\n                        \"dbt run --fail-fast\",\n                        \"dbt test --fail fast\",\n                    ],\n                ),\n            )\n        )\n        ```\n    \"\"\"  # noqa\n    logger = get_run_logger()\n\n    triggered_run_data_future = await trigger_dbt_cloud_job_run.submit(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        job_id=job_id,\n        options=trigger_job_run_options,\n    )\n    run_id = (await triggered_run_data_future.result()).get(\"id\")\n    if run_id is None:\n        raise RuntimeError(\"Unable to determine run ID for triggered job.\")\n\n    final_run_status, run_data = await wait_for_dbt_cloud_job_run(\n        run_id=run_id,\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        max_wait_seconds=max_wait_seconds,\n        poll_frequency_seconds=poll_frequency_seconds,\n    )\n\n    if final_run_status == DbtCloudJobRunStatus.SUCCESS:\n        try:\n            list_run_artifacts_future = await list_dbt_cloud_run_artifacts.submit(\n                dbt_cloud_credentials=dbt_cloud_credentials,\n                run_id=run_id,\n            )\n            run_data[\"artifact_paths\"] = await list_run_artifacts_future.result()\n        except DbtCloudListRunArtifactsFailed as ex:\n            logger.warning(\n                \"Unable to retrieve artifacts for job run with ID %s. Reason: %s\",\n                run_id,\n                ex,\n            )\n        logger.info(\n            \"dbt Cloud job run with ID %s completed successfully!\",\n            run_id,\n        )\n        return run_data\n    elif final_run_status == DbtCloudJobRunStatus.CANCELLED:\n        raise DbtCloudJobRunCancelled(\n            f\"Triggered job run with ID {run_id} was cancelled.\"\n        )\n    elif final_run_status == DbtCloudJobRunStatus.FAILED:\n        while retry_filtered_models_attempts &gt; 0:\n            logger.info(\n                f\"Retrying job run with ID: {run_id} \"\n                f\"{retry_filtered_models_attempts} more times\"\n            )\n            try:\n                retry_filtered_models_attempts -= 1\n                run_data = await (\n                    retry_dbt_cloud_job_run_subset_and_wait_for_completion(\n                        dbt_cloud_credentials=dbt_cloud_credentials,\n                        run_id=run_id,\n                        trigger_job_run_options=trigger_job_run_options,\n                        max_wait_seconds=max_wait_seconds,\n                        poll_frequency_seconds=poll_frequency_seconds,\n                    )\n                )\n                return run_data\n            except Exception:\n                pass\n        else:\n            raise DbtCloudJobRunFailed(f\"Triggered job run with ID: {run_id} failed.\")\n    else:\n        raise RuntimeError(\n            f\"Triggered job run with ID: {run_id} ended with unexpected\"\n            f\"status {final_run_status.value}.\"\n        )\n</code></pre>"},{"location":"cloud/models/","title":"Models","text":""},{"location":"cloud/models/#prefect_dbt.cloud.models","title":"<code>prefect_dbt.cloud.models</code>","text":"<p>Module containing models used for passing data to dbt Cloud</p>"},{"location":"cloud/models/#prefect_dbt.cloud.models-classes","title":"Classes","text":""},{"location":"cloud/models/#prefect_dbt.cloud.models.TriggerJobRunOptions","title":"<code>TriggerJobRunOptions</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Defines options that can be defined when triggering a dbt Cloud job run.</p> Source code in <code>prefect_dbt/cloud/models.py</code> <pre><code>class TriggerJobRunOptions(BaseModel):\n    \"\"\"\n    Defines options that can be defined when triggering a dbt Cloud job run.\n    \"\"\"\n\n    cause: str = Field(\n        default_factory=default_cause_factory,\n        description=\"A text description of the reason for running this job.\",\n    )\n    git_sha: Optional[str] = Field(\n        default=None, description=\"The git sha to check out before running this job.\"\n    )\n    git_branch: Optional[str] = Field(\n        default=None, description=\"The git branch to check out before running this job.\"\n    )\n    schema_override: Optional[str] = Field(\n        default=None,\n        description=\"Override the destination schema in the configured \"\n        \"target for this job.\",\n    )\n    dbt_version_override: Optional[str] = Field(\n        default=None, description=\"Override the version of dbt used to run this job.\"\n    )\n    threads_override: Optional[int] = Field(\n        default=None, description=\"Override the number of threads used to run this job.\"\n    )\n    target_name_override: Optional[str] = Field(\n        default=None,\n        description=\"Override the target.name context variable used when \"\n        \"running this job\",\n    )\n    generate_docs_override: Optional[bool] = Field(\n        default=None,\n        description=\"Override whether or not this job generates docs \"\n        \"(true=yes, false=no).\",\n    )\n    timeout_seconds_override: Optional[int] = Field(\n        default=None, description=\"Override the timeout in seconds for this job.\"\n    )\n    steps_override: Optional[List[str]] = Field(\n        default=None, description=\"Override the list of steps for this job.\"\n    )\n</code></pre>"},{"location":"cloud/models/#prefect_dbt.cloud.models-functions","title":"Functions","text":""},{"location":"cloud/models/#prefect_dbt.cloud.models.default_cause_factory","title":"<code>default_cause_factory</code>","text":"<p>Factory function to populate the default cause for a job run to include information from the Prefect run context.</p> Source code in <code>prefect_dbt/cloud/models.py</code> <pre><code>def default_cause_factory():\n    \"\"\"\n    Factory function to populate the default cause for a job run to include information\n    from the Prefect run context.\n    \"\"\"\n    cause = \"Triggered via Prefect\"\n\n    try:\n        context = get_run_context()\n        if isinstance(context, FlowRunContext):\n            cause = f\"{cause} in flow run {context.flow_run.name}\"\n        elif isinstance(context, TaskRunContext):\n            cause = f\"{cause} in task run {context.task_run.name}\"\n    except RuntimeError:\n        pass\n\n    return cause\n</code></pre>"},{"location":"cloud/runs/","title":"Runs","text":""},{"location":"cloud/runs/#prefect_dbt.cloud.runs","title":"<code>prefect_dbt.cloud.runs</code>","text":"<p>Module containing tasks and flows for interacting with dbt Cloud job runs</p>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs-classes","title":"Classes","text":""},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunStatus","title":"<code>DbtCloudJobRunStatus</code>","text":"<p>             Bases: <code>Enum</code></p> <p>dbt Cloud Job statuses.</p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>class DbtCloudJobRunStatus(Enum):\n    \"\"\"dbt Cloud Job statuses.\"\"\"\n\n    QUEUED = 1\n    STARTING = 2\n    RUNNING = 3\n    SUCCESS = 10\n    FAILED = 20\n    CANCELLED = 30\n\n    @classmethod\n    def is_terminal_status_code(cls, status_code: Any) -&gt; bool:\n        \"\"\"\n        Returns True if a status code is terminal for a job run.\n        Returns False otherwise.\n        \"\"\"\n        return status_code in [cls.SUCCESS.value, cls.FAILED.value, cls.CANCELLED.value]\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunStatus-functions","title":"Functions","text":""},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunStatus.is_terminal_status_code","title":"<code>is_terminal_status_code</code>  <code>classmethod</code>","text":"<p>Returns True if a status code is terminal for a job run. Returns False otherwise.</p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>@classmethod\ndef is_terminal_status_code(cls, status_code: Any) -&gt; bool:\n    \"\"\"\n    Returns True if a status code is terminal for a job run.\n    Returns False otherwise.\n    \"\"\"\n    return status_code in [cls.SUCCESS.value, cls.FAILED.value, cls.CANCELLED.value]\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs-functions","title":"Functions","text":""},{"location":"cloud/runs/#prefect_dbt.cloud.runs.get_dbt_cloud_run_artifact","title":"<code>get_dbt_cloud_run_artifact</code>  <code>async</code>","text":"<p>A task to get an artifact generated for a completed run. The requested artifact is saved to a file in the current working directory.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>run_id</code> <code>int</code> <p>The ID of the run to list run artifacts for.</p> required <code>path</code> <code>str</code> <p>The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json)</p> required <code>step</code> <code>Optional[int]</code> <p>The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Dict, str]</code> <p>The contents of the requested manifest. Returns a <code>Dict</code> if the requested artifact is a JSON file and a <code>str</code> otherwise.</p> <p>Examples:</p> <p>Get an artifact of a dbt Cloud job run: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact\n\n@flow\ndef get_artifact_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    return get_dbt_cloud_run_artifact(\n        dbt_cloud_credentials=credentials,\n        run_id=42,\n        path=\"manifest.json\"\n    )\n\nget_artifact_flow()\n</code></pre></p> <p>Get an artifact of a dbt Cloud job run and write it to a file: <pre><code>import json\n\nfrom prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact\n\n@flow\ndef get_artifact_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    get_run_artifact_result = get_dbt_cloud_run_artifact(\n        dbt_cloud_credentials=credentials,\n        run_id=42,\n        path=\"manifest.json\"\n    )\n\n    with open(\"manifest.json\", \"w\") as file:\n        json.dump(get_run_artifact_result, file)\n\nget_artifact_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>@task(\n    name=\"Get dbt Cloud job artifact\",\n    description=\"Fetches an artifact from a completed run.\",\n    retries=3,\n    retry_delay_seconds=10,\n)\nasync def get_dbt_cloud_run_artifact(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    run_id: int,\n    path: str,\n    step: Optional[int] = None,\n) -&gt; Union[Dict, str]:\n    \"\"\"\n    A task to get an artifact generated for a completed run. The requested artifact\n    is saved to a file in the current working directory.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        run_id: The ID of the run to list run artifacts for.\n        path: The relative path to the run artifact (e.g. manifest.json, catalog.json,\n            run_results.json)\n        step: The index of the step in the run to query for artifacts. The\n            first step in the run has the index 1. If the step parameter is\n            omitted, then this method will return the artifacts compiled\n            for the last step in the run.\n\n    Returns:\n        The contents of the requested manifest. Returns a `Dict` if the\n            requested artifact is a JSON file and a `str` otherwise.\n\n    Examples:\n        Get an artifact of a dbt Cloud job run:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact\n\n        @flow\n        def get_artifact_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            return get_dbt_cloud_run_artifact(\n                dbt_cloud_credentials=credentials,\n                run_id=42,\n                path=\"manifest.json\"\n            )\n\n        get_artifact_flow()\n        ```\n\n        Get an artifact of a dbt Cloud job run and write it to a file:\n        ```python\n        import json\n\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact\n\n        @flow\n        def get_artifact_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            get_run_artifact_result = get_dbt_cloud_run_artifact(\n                dbt_cloud_credentials=credentials,\n                run_id=42,\n                path=\"manifest.json\"\n            )\n\n            with open(\"manifest.json\", \"w\") as file:\n                json.dump(get_run_artifact_result, file)\n\n        get_artifact_flow()\n        ```\n    \"\"\"  # noqa\n\n    try:\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.get_run_artifact(\n                run_id=run_id, path=path, step=step\n            )\n    except HTTPStatusError as ex:\n        raise DbtCloudGetRunArtifactFailed(extract_user_message(ex)) from ex\n\n    if path.endswith(\".json\"):\n        artifact_contents = response.json()\n    else:\n        artifact_contents = response.text\n\n    return artifact_contents\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.get_dbt_cloud_run_info","title":"<code>get_dbt_cloud_run_info</code>  <code>async</code>","text":"<p>A task to retrieve information about a dbt Cloud job run.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>run_id</code> <code>int</code> <p>The ID of the job to trigger.</p> required <code>include_related</code> <code>Optional[List[Literal['trigger', 'job', 'debug_logs', 'run_steps']]]</code> <p>List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict</code> <p>The run data returned by the dbt Cloud administrative API.</p> Example <p>Get status of a dbt Cloud job run: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import get_run\n\n@flow\ndef get_run_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    return get_run(\n        dbt_cloud_credentials=credentials,\n        run_id=42\n    )\n\nget_run_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>@task(\n    name=\"Get dbt Cloud job run details\",\n    description=\"Retrieves details of a dbt Cloud job run \"\n    \"for the run with the given run_id.\",\n    retries=3,\n    retry_delay_seconds=10,\n)\nasync def get_dbt_cloud_run_info(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    run_id: int,\n    include_related: Optional[\n        List[Literal[\"trigger\", \"job\", \"debug_logs\", \"run_steps\"]]\n    ] = None,\n) -&gt; Dict:\n    \"\"\"\n    A task to retrieve information about a dbt Cloud job run.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        run_id: The ID of the job to trigger.\n        include_related: List of related fields to pull with the run.\n            Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\".\n            If \"debug_logs\" is not provided in a request, then the included debug\n            logs will be truncated to the last 1,000 lines of the debug log output file.\n\n    Returns:\n        The run data returned by the dbt Cloud administrative API.\n\n    Example:\n        Get status of a dbt Cloud job run:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import get_run\n\n        @flow\n        def get_run_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            return get_run(\n                dbt_cloud_credentials=credentials,\n                run_id=42\n            )\n\n        get_run_flow()\n        ```\n    \"\"\"  # noqa\n    try:\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.get_run(\n                run_id=run_id, include_related=include_related\n            )\n    except HTTPStatusError as ex:\n        raise DbtCloudGetRunFailed(extract_user_message(ex)) from ex\n    return response.json()[\"data\"]\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.list_dbt_cloud_run_artifacts","title":"<code>list_dbt_cloud_run_artifacts</code>  <code>async</code>","text":"<p>A task to list the artifact files generated for a completed run.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>run_id</code> <code>int</code> <p>The ID of the run to list run artifacts for.</p> required <code>step</code> <code>Optional[int]</code> <p>The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of paths to artifact files that can be used to retrieve the generated artifacts.</p> Example <p>List artifacts of a dbt Cloud job run: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts\n\n@flow\ndef list_artifacts_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    return list_dbt_cloud_run_artifacts(\n        dbt_cloud_credentials=credentials,\n        run_id=42\n    )\n\nlist_artifacts_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>@task(\n    name=\"List dbt Cloud job artifacts\",\n    description=\"Fetches a list of artifact files generated for a completed run.\",\n    retries=3,\n    retry_delay_seconds=10,\n)\nasync def list_dbt_cloud_run_artifacts(\n    dbt_cloud_credentials: DbtCloudCredentials, run_id: int, step: Optional[int] = None\n) -&gt; List[str]:\n    \"\"\"\n    A task to list the artifact files generated for a completed run.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        run_id: The ID of the run to list run artifacts for.\n        step: The index of the step in the run to query for artifacts. The\n            first step in the run has the index 1. If the step parameter is\n            omitted, then this method will return the artifacts compiled\n            for the last step in the run.\n\n    Returns:\n        A list of paths to artifact files that can be used to retrieve the generated artifacts.\n\n    Example:\n        List artifacts of a dbt Cloud job run:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts\n\n        @flow\n        def list_artifacts_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            return list_dbt_cloud_run_artifacts(\n                dbt_cloud_credentials=credentials,\n                run_id=42\n            )\n\n        list_artifacts_flow()\n        ```\n    \"\"\"  # noqa\n    try:\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.list_run_artifacts(run_id=run_id, step=step)\n    except HTTPStatusError as ex:\n        raise DbtCloudListRunArtifactsFailed(extract_user_message(ex)) from ex\n    return response.json()[\"data\"]\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.wait_for_dbt_cloud_job_run","title":"<code>wait_for_dbt_cloud_job_run</code>  <code>async</code>","text":"<p>Waits for the given dbt Cloud job run to finish running.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>int</code> <p>The ID of the run to wait for.</p> required <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>max_wait_seconds</code> <code>int</code> <p>Maximum number of seconds to wait for job to complete</p> <code>900</code> <code>poll_frequency_seconds</code> <code>int</code> <p>Number of seconds to wait in between checks for run completion.</p> <code>10</code> <p>Raises:</p> Type Description <code>DbtCloudJobRunTimedOut</code> <p>When the elapsed wait time exceeds <code>max_wait_seconds</code>.</p> <p>Returns:</p> Name Type Description <code>run_status</code> <code>DbtCloudJobRunStatus</code> <p>An enum representing the final dbt Cloud job run status</p> <code>run_data</code> <code>Dict</code> <p>A dictionary containing information about the run after completion.</p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>@flow(\n    name=\"Wait for dbt Cloud job run\",\n    description=\"Waits for a dbt Cloud job run to finish running.\",\n)\nasync def wait_for_dbt_cloud_job_run(\n    run_id: int,\n    dbt_cloud_credentials: DbtCloudCredentials,\n    max_wait_seconds: int = 900,\n    poll_frequency_seconds: int = 10,\n) -&gt; Tuple[DbtCloudJobRunStatus, Dict]:\n    \"\"\"\n    Waits for the given dbt Cloud job run to finish running.\n\n    Args:\n        run_id: The ID of the run to wait for.\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        max_wait_seconds: Maximum number of seconds to wait for job to complete\n        poll_frequency_seconds: Number of seconds to wait in between checks for\n            run completion.\n\n    Raises:\n        DbtCloudJobRunTimedOut: When the elapsed wait time exceeds `max_wait_seconds`.\n\n    Returns:\n        run_status: An enum representing the final dbt Cloud job run status\n        run_data: A dictionary containing information about the run after completion.\n\n\n    Example:\n\n\n    \"\"\"\n    logger = get_run_logger()\n    seconds_waited_for_run_completion = 0\n    wait_for = []\n    while seconds_waited_for_run_completion &lt;= max_wait_seconds:\n        run_data_future = await get_dbt_cloud_run_info.submit(\n            dbt_cloud_credentials=dbt_cloud_credentials,\n            run_id=run_id,\n            wait_for=wait_for,\n        )\n        run_data = await run_data_future.result()\n        run_status_code = run_data.get(\"status\")\n\n        if DbtCloudJobRunStatus.is_terminal_status_code(run_status_code):\n            return DbtCloudJobRunStatus(run_status_code), run_data\n\n        wait_for = [run_data_future]\n        logger.debug(\n            \"dbt Cloud job run with ID %i has status %s. Waiting for %i seconds.\",\n            run_id,\n            DbtCloudJobRunStatus(run_status_code).name,\n            poll_frequency_seconds,\n        )\n        await asyncio.sleep(poll_frequency_seconds)\n        seconds_waited_for_run_completion += poll_frequency_seconds\n\n    raise DbtCloudJobRunTimedOut(\n        f\"Max wait time of {max_wait_seconds} seconds exceeded while waiting \"\n        \"for job run with ID {run_id}\"\n    )\n</code></pre>"},{"location":"cloud/utils/","title":"Utils","text":""},{"location":"cloud/utils/#prefect_dbt.cloud.utils","title":"<code>prefect_dbt.cloud.utils</code>","text":"<p>Utilities for common interactions with the dbt Cloud API</p>"},{"location":"cloud/utils/#prefect_dbt.cloud.utils-classes","title":"Classes","text":""},{"location":"cloud/utils/#prefect_dbt.cloud.utils.DbtCloudAdministrativeApiCallFailed","title":"<code>DbtCloudAdministrativeApiCallFailed</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Raised when a call to dbt Cloud administrative API fails.</p> Source code in <code>prefect_dbt/cloud/utils.py</code> <pre><code>class DbtCloudAdministrativeApiCallFailed(Exception):\n    \"\"\"Raised when a call to dbt Cloud administrative API fails.\"\"\"\n</code></pre>"},{"location":"cloud/utils/#prefect_dbt.cloud.utils-functions","title":"Functions","text":""},{"location":"cloud/utils/#prefect_dbt.cloud.utils.call_dbt_cloud_administrative_api_endpoint","title":"<code>call_dbt_cloud_administrative_api_endpoint</code>  <code>async</code>","text":"<p>Task that calls a specified endpoint in the dbt Cloud administrative API. Use this task if a prebuilt one is not yet available.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>path</code> <code>str</code> <p>The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration.</p> required <code>http_method</code> <code>str</code> <p>HTTP method to call on the endpoint.</p> required <code>params</code> <code>Optional[Dict[str, Any]]</code> <p>Query parameters to include in the request.</p> <code>None</code> <code>json</code> <code>Optional[Dict[str, Any]]</code> <p>JSON serializable body to send in the request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The body of the response. If the body is JSON serializable, then the result of <code>json.loads</code> with the body as the input will be returned. Otherwise, the body will be returned directly.</p> <p>Examples:</p> <p>List projects for an account: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint\n\n@flow\ndef get_projects_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    result = call_dbt_cloud_administrative_api_endpoint(\n        dbt_cloud_credentials=credentials,\n        path=\"/projects/\",\n        http_method=\"GET\",\n    )\n    return result[\"data\"]\n\nget_projects_flow()\n</code></pre></p> <p>Create a new job: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint\n\n\n@flow\ndef create_job_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    result = call_dbt_cloud_administrative_api_endpoint(\n        dbt_cloud_credentials=credentials,\n        path=\"/jobs/\",\n        http_method=\"POST\",\n        json={\n            \"id\": None,\n            \"account_id\": 123456789,\n            \"project_id\": 100,\n            \"environment_id\": 10,\n            \"name\": \"Nightly run\",\n            \"dbt_version\": None,\n            \"triggers\": {\"github_webhook\": True, \"schedule\": True},\n            \"execute_steps\": [\"dbt run\", \"dbt test\", \"dbt source snapshot-freshness\"],\n            \"settings\": {\"threads\": 4, \"target_name\": \"prod\"},\n            \"state\": 1,\n            \"schedule\": {\n                \"date\": {\"type\": \"every_day\"},\n                \"time\": {\"type\": \"every_hour\", \"interval\": 1},\n            },\n        },\n    )\n    return result[\"data\"]\n\ncreate_job_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/utils.py</code> <pre><code>@task(\n    name=\"Call dbt Cloud administrative API endpoint\",\n    description=\"Calls a dbt Cloud administrative API endpoint\",\n    retries=3,\n    retry_delay_seconds=10,\n)\nasync def call_dbt_cloud_administrative_api_endpoint(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    path: str,\n    http_method: str,\n    params: Optional[Dict[str, Any]] = None,\n    json: Optional[Dict[str, Any]] = None,\n) -&gt; Any:\n    \"\"\"\n    Task that calls a specified endpoint in the dbt Cloud administrative API. Use this\n    task if a prebuilt one is not yet available.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        path: The partial path for the request (e.g. /projects/). Will be appended\n            onto the base URL as determined by the client configuration.\n        http_method: HTTP method to call on the endpoint.\n        params: Query parameters to include in the request.\n        json: JSON serializable body to send in the request.\n\n    Returns:\n        The body of the response. If the body is JSON serializable, then the result of\n            `json.loads` with the body as the input will be returned. Otherwise, the\n            body will be returned directly.\n\n    Examples:\n        List projects for an account:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint\n\n        @flow\n        def get_projects_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            result = call_dbt_cloud_administrative_api_endpoint(\n                dbt_cloud_credentials=credentials,\n                path=\"/projects/\",\n                http_method=\"GET\",\n            )\n            return result[\"data\"]\n\n        get_projects_flow()\n        ```\n\n        Create a new job:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint\n\n\n        @flow\n        def create_job_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            result = call_dbt_cloud_administrative_api_endpoint(\n                dbt_cloud_credentials=credentials,\n                path=\"/jobs/\",\n                http_method=\"POST\",\n                json={\n                    \"id\": None,\n                    \"account_id\": 123456789,\n                    \"project_id\": 100,\n                    \"environment_id\": 10,\n                    \"name\": \"Nightly run\",\n                    \"dbt_version\": None,\n                    \"triggers\": {\"github_webhook\": True, \"schedule\": True},\n                    \"execute_steps\": [\"dbt run\", \"dbt test\", \"dbt source snapshot-freshness\"],\n                    \"settings\": {\"threads\": 4, \"target_name\": \"prod\"},\n                    \"state\": 1,\n                    \"schedule\": {\n                        \"date\": {\"type\": \"every_day\"},\n                        \"time\": {\"type\": \"every_hour\", \"interval\": 1},\n                    },\n                },\n            )\n            return result[\"data\"]\n\n        create_job_flow()\n        ```\n    \"\"\"  # noqa\n    try:\n\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.call_endpoint(\n                http_method=http_method, path=path, params=params, json=json\n            )\n    except HTTPStatusError as ex:\n        raise DbtCloudAdministrativeApiCallFailed(extract_developer_message(ex)) from ex\n    try:\n        return response.json()\n    except JSONDecodeError:\n        return response.text\n</code></pre>"},{"location":"cloud/utils/#prefect_dbt.cloud.utils.extract_developer_message","title":"<code>extract_developer_message</code>","text":"<p>Extracts developer message from a error response from the dbt Cloud administrative API.</p> <p>Parameters:</p> Name Type Description Default <code>ex</code> <code>HTTPStatusError</code> <p>An HTTPStatusError raised by httpx</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>developer_message from dbt Cloud administrative API response or None if a</p> <code>Optional[str]</code> <p>developer_message cannot be extracted</p> Source code in <code>prefect_dbt/cloud/utils.py</code> <pre><code>def extract_developer_message(ex: HTTPStatusError) -&gt; Optional[str]:\n    \"\"\"\n    Extracts developer message from a error response from the dbt Cloud\n    administrative API.\n\n    Args:\n        ex: An HTTPStatusError raised by httpx\n\n    Returns:\n        developer_message from dbt Cloud administrative API response or None if a\n        developer_message cannot be extracted\n    \"\"\"\n    response_payload = ex.response.json()\n    status = response_payload.get(\"status\", {})\n    return status.get(\"developer_message\")\n</code></pre>"},{"location":"cloud/utils/#prefect_dbt.cloud.utils.extract_user_message","title":"<code>extract_user_message</code>","text":"<p>Extracts user message from a error response from the dbt Cloud administrative API.</p> <p>Parameters:</p> Name Type Description Default <code>ex</code> <code>HTTPStatusError</code> <p>An HTTPStatusError raised by httpx</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>user_message from dbt Cloud administrative API response or None if a</p> <code>Optional[str]</code> <p>user_message cannot be extracted</p> Source code in <code>prefect_dbt/cloud/utils.py</code> <pre><code>def extract_user_message(ex: HTTPStatusError) -&gt; Optional[str]:\n    \"\"\"\n    Extracts user message from a error response from the dbt Cloud administrative API.\n\n    Args:\n        ex: An HTTPStatusError raised by httpx\n\n    Returns:\n        user_message from dbt Cloud administrative API response or None if a\n        user_message cannot be extracted\n    \"\"\"\n    response_payload = ex.response.json()\n    status = response_payload.get(\"status\", {})\n    return status.get(\"user_message\")\n</code></pre>"}]}