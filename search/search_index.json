{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"prefect-dbt","text":"<p><code>prefect-dbt</code> is a collection of Prefect integrations for working with dbt with your Prefect flows.</p>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#trigger-a-dbt-cloud-job-and-wait-for-completion","title":"Trigger a dbt Cloud job and wait for completion","text":"<pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n\n@flow\ndef run_dbt_job_flow():\n    run_result = trigger_dbt_cloud_job_run_and_wait_for_completion(\n        dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        ),\n        job_id=1\n    )\n\nrun_dbt_job_flow()\n</code></pre>"},{"location":"#execute-a-dbt-cli-command","title":"Execute a dbt CLI command","text":"<pre><code>from prefect import flow\nfrom prefect_dbt.cli.commands import trigger_dbt_cli_command\n\n@flow\ndef trigger_dbt_cli_command_flow() -&gt; str:\n    result = trigger_dbt_cli_command(\"dbt debug\")\n    return result # Returns the last line in the CLI output\n\ntrigger_dbt_cli_command_flow()\n</code></pre>"},{"location":"#execute-a-dbt-cli-command-without-a-pre-populated-profilesyml","title":"Execute a dbt CLI command without a pre-populated profiles.yml","text":"<pre><code>from prefect import flow\nfrom prefect_snowflake.credentials import SnowflakeCredentials\nfrom prefect_snowflake.database import SnowflakeConnector\n\nfrom prefect_dbt.cli.credentials import DbtCliProfile\nfrom prefect_dbt.cli.commands import trigger_dbt_cli_command\nfrom prefect_dbt.cli.configs import SnowflakeTargetConfigs\n\n@flow\ndef trigger_dbt_cli_command_flow():\n    connector = SnowflakeConnector(\n        schema=\"public\",\n        database=\"database\",\n        warehouse=\"warehouse\",\n        credentials=SnowflakeCredentials(\n            user=\"user\",\n            password=\"password\",\n            account=\"account.region.aws\",\n            role=\"role\",\n        ),\n    )\n    target_configs = SnowflakeTargetConfigs(\n        connector=connector\n    )\n    dbt_cli_profile = DbtCliProfile(\n        name=\"jaffle_shop\",\n        target=\"dev\",\n        target_configs=target_configs,\n    )\n    result = trigger_dbt_cli_command(\n        \"dbt debug\",\n        overwrite_profiles=True,\n        dbt_cli_profile=dbt_cli_profile\n    )\n    return result\n\ntrigger_dbt_cli_command_flow()\n</code></pre>"},{"location":"#idempotent-way-to-execute-multiple-dbt-cli-commands-without-prepopulated-profilesyml","title":"Idempotent way to execute multiple dbt CLI commands without prepopulated profiles.yml","text":"<pre><code>from prefect import flow\n\nfrom prefect_dbt.cli.credentials import DbtCliProfile\nfrom prefect_dbt.cli.commands import trigger_dbt_cli_command\n\n@flow\ndef trigger_dbt_cli_commands_flow():\n    dbt_cli_profile = DbtCliProfile.load(\"MY_BLOCK_NAME\")\n\n    trigger_kwargs = dict(\n        profiles_dir=\".\",\n        overwrite_profiles=True,\n        dbt_cli_profile=dbt_cli_profile,\n    )\n\n    trigger_dbt_cli_command(\n        \"dbt deps\",\n        **trigger_kwargs\n    )\n\n    result = trigger_dbt_cli_command(\n        \"dbt debug\",\n        **trigger_kwargs\n    )\n\n    return result\n\n\ntrigger_dbt_cli_commands_flow()\n</code></pre>"},{"location":"#resources","title":"Resources","text":"<p>If you need help getting started with or using dbt, please consult the dbt documentation.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install <code>prefect-dbt</code> with <code>pip</code>:</p> <pre><code>pip install prefect-dbt\n</code></pre> <p>Some dbt CLI profiles require additional installation; for example Databricks:</p> <pre><code>pip install dbt-databricks\n</code></pre> <p>Requires an installation of Python 3.7+.</p> <p>We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv.</p> <p>These tasks are designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the Prefect documentation.</p>"},{"location":"#saving-dbt-cloud-credentials-to-block","title":"Saving dbt Cloud credentials to block","text":"<p>Note, to use the <code>load</code> method on Blocks, you must already have a block document saved through code or saved through the UI.</p> <ol> <li>Head over to your dbt Cloud profile.</li> <li>Login to your dbt Cloud account.</li> <li>Scroll down to \"API\" or click \"API Access\" on the sidebar.</li> <li>Copy the API Key.</li> <li>Create a short script, replacing the placeholders (or do so in the UI).</li> </ol> <pre><code>from prefect_dbt.cloud import DbtCloudCredentials\nDbtCloudCredentials(\n    api_key=\"API_KEY_PLACEHOLDER\",\n    account_id=\"ACCOUNT_ID_PLACEHOLDER\"\n).save(\"BLOCK_NAME_PLACEHOLDER\")\n</code></pre> <p>Congrats! You can now easily load the saved block, which holds your credentials:</p> <pre><code>from prefect_dbt.cloud import DbtCloudCredentials\nDbtCloudCredentials.load(\"BLOCK_NAME_PLACEHOLDER\")\n</code></pre> <p>To view and edit the blocks on Prefect UI:</p> <pre><code>prefect block register -m prefect_dbt\n</code></pre>"},{"location":"#feedback","title":"Feedback","text":"<p>If you encounter any bugs while using <code>prefect-dbt</code>, feel free to open an issue in the prefect-dbt repository.</p> <p>If you have any questions or issues while using <code>prefect-dbt</code>, you can find help in either the Prefect Discourse forum or the Prefect Slack community.</p> <p>Feel free to star or watch <code>prefect-dbt</code> for updates too!</p>"},{"location":"#contributing","title":"Contributing","text":"<p>If you'd like to help contribute to fix an issue or add a feature to <code>prefect-dbt</code>, please propose changes through a pull request from a fork of the repository.</p> <p>Here are the steps:</p> <ol> <li>Fork the repository</li> <li>Clone the forked repository</li> <li>Install the repository and its dependencies: <pre><code>pip install -e \".[dev]\"\n</code></pre></li> <li>Make desired changes</li> <li>Add tests</li> <li>Insert an entry to CHANGELOG.md</li> <li>Install <code>pre-commit</code> to perform quality checks prior to commit: <pre><code>pre-commit install\n</code></pre></li> <li><code>git commit</code>, <code>git push</code>, and create a pull request</li> </ol>"},{"location":"blocks_catalog/","title":"Blocks Catalog","text":"<p>Below is a list of Blocks available for registration in <code>prefect-dbt</code>.</p> <p>To register blocks in this module to view and edit them on Prefect Cloud: <pre><code>prefect block register -m prefect_dbt\n</code></pre> Note, to use the <code>load</code> method on Blocks, you must already have a block document saved through code or saved through the UI.</p>"},{"location":"blocks_catalog/#cloudcredentials-module","title":"Cloud.Credentials Module","text":"<p>DbtCloudCredentials</p> <p>Credentials block for credential use across dbt Cloud tasks and flows.</p> <p>To load the DbtCloudCredentials: <pre><code>from prefect import flow\nfrom prefect_dbt.cloud.credentials import DbtCloudCredentials\n\n@flow\ndef my_flow():\n    my_block = DbtCloudCredentials.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cloud.Credentials Module under Examples Catalog.</p>"},{"location":"blocks_catalog/#cliconfigsbase-module","title":"Cli.Configs.Base Module","text":"<p>TargetConfigs</p> <p>Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink.</p> <p>To load the TargetConfigs: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.configs.base import TargetConfigs\n\n@flow\ndef my_flow():\n    my_block = TargetConfigs.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> GlobalConfigs</p> <p>Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Docs can be found here.</p> <p>To load the GlobalConfigs: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.configs.base import GlobalConfigs\n\n@flow\ndef my_flow():\n    my_block = GlobalConfigs.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cli.Configs.Base Module under Examples Catalog.</p>"},{"location":"blocks_catalog/#cliconfigssnowflake-module","title":"Cli.Configs.Snowflake Module","text":"<p>SnowflakeTargetConfigs</p> <p>Target configs contain credentials and settings, specific to Snowflake. To find valid keys, head to the Snowflake Profile page.</p> <p>To load the SnowflakeTargetConfigs: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.configs.snowflake import SnowflakeTargetConfigs\n\n@flow\ndef my_flow():\n    my_block = SnowflakeTargetConfigs.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cli.Configs.Snowflake Module under Examples Catalog.</p>"},{"location":"blocks_catalog/#cliconfigsbigquery-module","title":"Cli.Configs.Bigquery Module","text":"<p>BigQueryTargetConfigs</p> <p>dbt CLI target configs containing credentials and settings, specific to BigQuery.</p> <p>To load the BigQueryTargetConfigs: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.configs.bigquery import BigQueryTargetConfigs\n\n@flow\ndef my_flow():\n    my_block = BigQueryTargetConfigs.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cli.Configs.Bigquery Module under Examples Catalog.</p>"},{"location":"blocks_catalog/#cliconfigspostgres-module","title":"Cli.Configs.Postgres Module","text":"<p>PostgresTargetConfigs</p> <p>dbt CLI target configs containing credentials and settings specific to Postgres.</p> <p>To load the PostgresTargetConfigs: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.configs.postgres import PostgresTargetConfigs\n\n@flow\ndef my_flow():\n    my_block = PostgresTargetConfigs.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cli.Configs.Postgres Module under Examples Catalog.</p>"},{"location":"blocks_catalog/#clicredentials-module","title":"Cli.Credentials Module","text":"<p>DbtCliProfile</p> <p>Profile for use across dbt CLI tasks and flows.</p> <p>To load the DbtCliProfile: <pre><code>from prefect import flow\nfrom prefect_dbt.cli.credentials import DbtCliProfile\n\n@flow\ndef my_flow():\n    my_block = DbtCliProfile.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre> For additional examples, check out the Cli.Credentials Module under Examples Catalog.</p>"},{"location":"examples_catalog/","title":"Examples Catalog","text":"<p>Below is a list of examples for <code>prefect-dbt</code>.</p>"},{"location":"examples_catalog/#clicredentials-module","title":"Cli.Credentials Module","text":"<p>Load stored dbt CLI profile: <pre><code>from prefect_dbt.cli import DbtCliProfile\ndbt_cli_profile = DbtCliProfile.load(\"BLOCK_NAME\").get_profile()\n</code></pre></p> <p>Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs: <pre><code>from prefect_dbt.cli import DbtCliProfile\nfrom prefect_dbt.cli.configs import SnowflakeTargetConfigs\nfrom prefect_snowflake.credentials import SnowflakeCredentials\nfrom prefect_snowflake.database import SnowflakeConnector\n\ncredentials = SnowflakeCredentials(\n    user=\"user\",\n    password=\"password\",\n    account=\"account.region.aws\",\n    role=\"role\",\n)\nconnector = SnowflakeConnector(\n    schema=\"public\",\n    database=\"database\",\n    warehouse=\"warehouse\",\n    credentials=credentials,\n)\ntarget_configs = SnowflakeTargetConfigs(\n    connector=connector\n)\ndbt_cli_profile = DbtCliProfile(\n    name=\"jaffle_shop\",\n    target=\"dev\",\n    target_configs=target_configs,\n)\nprofile = dbt_cli_profile.get_profile()\n</code></pre></p> <p>Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs: <pre><code>from prefect_dbt.cli import DbtCliProfile\nfrom prefect_dbt.cli.configs import GlobalConfigs, TargetConfigs\n\ntarget_configs_extras = dict(\n    host=\"hostname.region.redshift.amazonaws.com\",\n    user=\"username\",\n    password=\"password1\",\n    port=5439,\n    dbname=\"analytics\",\n)\ntarget_configs = TargetConfigs(\n    type=\"redshift\",\n    schema=\"schema\",\n    threads=4,\n    extras=target_configs_extras\n)\ndbt_cli_profile = DbtCliProfile(\n    name=\"jaffle_shop\",\n    target=\"dev\",\n    target_configs=target_configs,\n)\nprofile = dbt_cli_profile.get_profile()\n</code></pre></p>"},{"location":"examples_catalog/#cloudcredentials-module","title":"Cloud.Credentials Module","text":"<p>Load stored dbt Cloud credentials: <pre><code>from prefect_dbt.cloud import DbtCloudCredentials\n\ndbt_cloud_credentials = DbtCloudCredentials.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Use DbtCloudCredentials instance to trigger a job run: <pre><code>from prefect_dbt.cloud import DbtCloudCredentials\n\ncredentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\nasync with dbt_cloud_credentials.get_administrative_client() as client:\n    client.trigger_job_run(job_id=1)\n</code></pre></p> <p>Load saved dbt Cloud credentials within a flow: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n\n\n@flow\ndef trigger_dbt_cloud_job_run_flow():\n    credentials = DbtCloudCredentials.load(\"my-dbt-credentials\")\n    trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1)\n\ntrigger_dbt_cloud_job_run_flow()\n</code></pre> Sending queries via the returned metadata client: <pre><code>from prefect_dbt import DbtCloudCredentials\n\ncredentials_block = DbtCloudCredentials.load(\"test-account\")\nmetadata_client = credentials_block.get_metadata_client()\nquery = \"\"\"\n{\n    metrics(jobId: 123) {\n        uniqueId\n        name\n        packageName\n        tags\n        label\n        runId\n        description\n        type\n        sql\n        timestamp\n        timeGrains\n        dimensions\n        meta\n        resourceType\n        filters {\n            field\n            operator\n            value\n        }\n        model {\n            name\n        }\n    }\n}\n\"\"\"\nmetadata_client.query(query)\n# Result:\n# {\n#   \"data\": {\n#     \"metrics\": [\n#       {\n#         \"uniqueId\": \"metric.tpch.total_revenue\",\n#         \"name\": \"total_revenue\",\n#         \"packageName\": \"tpch\",\n#         \"tags\": [],\n#         \"label\": \"Total Revenue ($)\",\n#         \"runId\": 108952046,\n#         \"description\": \"\",\n#         \"type\": \"sum\",\n#         \"sql\": \"net_item_sales_amount\",\n#         \"timestamp\": \"order_date\",\n#         \"timeGrains\": [\"day\", \"week\", \"month\"],\n#         \"dimensions\": [\"status_code\", \"priority_code\"],\n#         \"meta\": {},\n#         \"resourceType\": \"metric\",\n#         \"filters\": [],\n#         \"model\": { \"name\": \"fct_orders\" }\n#       }\n#     ]\n#   }\n# }\n</code></pre></p>"},{"location":"cli/commands/","title":"Commands","text":""},{"location":"cli/commands/#prefect_dbt.cli.commands","title":"<code>prefect_dbt.cli.commands</code>","text":"<p>Module containing tasks and flows for interacting with dbt CLI</p>"},{"location":"cli/commands/#prefect_dbt.cli.commands-classes","title":"Classes","text":""},{"location":"cli/commands/#prefect_dbt.cli.commands-functions","title":"Functions","text":""},{"location":"cli/commands/#prefect_dbt.cli.commands.trigger_dbt_cli_command","title":"<code>trigger_dbt_cli_command</code>  <code>async</code>","text":"<p>Task for running dbt commands.</p> <p>If no profiles.yml file is found or if overwrite_profiles flag is set to True, this will first generate a profiles.yml file in the profiles_dir directory. Then run the dbt CLI shell command.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>str</code> <p>The dbt command to be executed.</p> required <code>profiles_dir</code> <code>Optional[Union[Path, str]]</code> <p>The directory to search for the profiles.yml file. Setting this appends the <code>--profiles-dir</code> option to the command provided. If this is not set, will try using the DBT_PROFILES_DIR environment variable, but if that's also not set, will use the default directory <code>$HOME/.dbt/</code>.</p> <code>None</code> <code>project_dir</code> <code>Optional[Union[Path, str]]</code> <p>The directory to search for the dbt_project.yml file. Default is the current working directory and its parents.</p> <code>None</code> <code>overwrite_profiles</code> <code>bool</code> <p>Whether the existing profiles.yml file under profiles_dir should be overwritten with a new profile.</p> <code>False</code> <code>dbt_cli_profile</code> <code>Optional[DbtCliProfile]</code> <p>Profiles class containing the profile written to profiles.yml. Note! This is optional and will raise an error if profiles.yml already exists under profile_dir and overwrite_profiles is set to False.</p> <code>None</code> <code>**shell_run_command_kwargs</code> <code>Dict[str, Any]</code> <p>Additional keyword arguments to pass to shell_run_command.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>last_line_cli_output</code> <code>str</code> <p>The last line of the CLI output will be returned if <code>return_all</code> in <code>shell_run_command_kwargs</code> is False. This is the default behavior.</p> <code>full_cli_output</code> <code>List[str]</code> <p>Full CLI output will be returned if <code>return_all</code> in <code>shell_run_command_kwargs</code> is True.</p> <p>Examples:</p> <p>Execute <code>dbt debug</code> with a pre-populated profiles.yml. <pre><code>from prefect import flow\nfrom prefect_dbt.cli.commands import trigger_dbt_cli_command\n\n@flow\ndef trigger_dbt_cli_command_flow():\n    result = trigger_dbt_cli_command(\"dbt debug\")\n    return result\n\ntrigger_dbt_cli_command_flow()\n</code></pre></p> <p>Execute <code>dbt debug</code> without a pre-populated profiles.yml. <pre><code>from prefect import flow\nfrom prefect_dbt.cli.credentials import DbtCliProfile\nfrom prefect_dbt.cli.commands import trigger_dbt_cli_command\nfrom prefect_dbt.cli.configs import SnowflakeTargetConfigs\nfrom prefect_snowflake.credentials import SnowflakeCredentials\n\n@flow\ndef trigger_dbt_cli_command_flow():\n    credentials = SnowflakeCredentials(\n        user=\"user\",\n        password=\"password\",\n        account=\"account.region.aws\",\n        role=\"role\",\n    )\n    connector = SnowflakeConnector(\n        schema=\"public\",\n        database=\"database\",\n        warehouse=\"warehouse\",\n        credentials=credentials,\n    )\n    target_configs = SnowflakeTargetConfigs(\n        connector=connector\n    )\n    dbt_cli_profile = DbtCliProfile(\n        name=\"jaffle_shop\",\n        target=\"dev\",\n        target_configs=target_configs,\n    )\n    result = trigger_dbt_cli_command(\n        \"dbt debug\",\n        overwrite_profiles=True,\n        dbt_cli_profile=dbt_cli_profile\n    )\n    return result\n\ntrigger_dbt_cli_command_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cli/commands.py</code> <pre><code>@task\nasync def trigger_dbt_cli_command(\n    command: str,\n    profiles_dir: Optional[Union[Path, str]] = None,\n    project_dir: Optional[Union[Path, str]] = None,\n    overwrite_profiles: bool = False,\n    dbt_cli_profile: Optional[DbtCliProfile] = None,\n    **shell_run_command_kwargs: Dict[str, Any],\n) -&gt; Union[List[str], str]:\n\"\"\"\n    Task for running dbt commands.\n\n    If no profiles.yml file is found or if overwrite_profiles flag is set to True, this\n    will first generate a profiles.yml file in the profiles_dir directory. Then run the dbt\n    CLI shell command.\n\n    Args:\n        command: The dbt command to be executed.\n        profiles_dir: The directory to search for the profiles.yml file. Setting this\n            appends the `--profiles-dir` option to the command provided. If this is not set,\n            will try using the DBT_PROFILES_DIR environment variable, but if that's also not\n            set, will use the default directory `$HOME/.dbt/`.\n        project_dir: The directory to search for the dbt_project.yml file.\n            Default is the current working directory and its parents.\n        overwrite_profiles: Whether the existing profiles.yml file under profiles_dir\n            should be overwritten with a new profile.\n        dbt_cli_profile: Profiles class containing the profile written to profiles.yml.\n            Note! This is optional and will raise an error if profiles.yml already exists\n            under profile_dir and overwrite_profiles is set to False.\n        **shell_run_command_kwargs: Additional keyword arguments to pass to\n            [shell_run_command](https://prefecthq.github.io/prefect-shell/commands/#prefect_shell.commands.shell_run_command).\n\n    Returns:\n        last_line_cli_output (str): The last line of the CLI output will be returned\n            if `return_all` in `shell_run_command_kwargs` is False. This is the default\n            behavior.\n        full_cli_output (List[str]): Full CLI output will be returned if `return_all`\n            in `shell_run_command_kwargs` is True.\n\n    Examples:\n        Execute `dbt debug` with a pre-populated profiles.yml.\n        ```python\n        from prefect import flow\n        from prefect_dbt.cli.commands import trigger_dbt_cli_command\n\n        @flow\n        def trigger_dbt_cli_command_flow():\n            result = trigger_dbt_cli_command(\"dbt debug\")\n            return result\n\n        trigger_dbt_cli_command_flow()\n        ```\n\n        Execute `dbt debug` without a pre-populated profiles.yml.\n        ```python\n        from prefect import flow\n        from prefect_dbt.cli.credentials import DbtCliProfile\n        from prefect_dbt.cli.commands import trigger_dbt_cli_command\n        from prefect_dbt.cli.configs import SnowflakeTargetConfigs\n        from prefect_snowflake.credentials import SnowflakeCredentials\n\n        @flow\n        def trigger_dbt_cli_command_flow():\n            credentials = SnowflakeCredentials(\n                user=\"user\",\n                password=\"password\",\n                account=\"account.region.aws\",\n                role=\"role\",\n            )\n            connector = SnowflakeConnector(\n                schema=\"public\",\n                database=\"database\",\n                warehouse=\"warehouse\",\n                credentials=credentials,\n            )\n            target_configs = SnowflakeTargetConfigs(\n                connector=connector\n            )\n            dbt_cli_profile = DbtCliProfile(\n                name=\"jaffle_shop\",\n                target=\"dev\",\n                target_configs=target_configs,\n            )\n            result = trigger_dbt_cli_command(\n                \"dbt debug\",\n                overwrite_profiles=True,\n                dbt_cli_profile=dbt_cli_profile\n            )\n            return result\n\n        trigger_dbt_cli_command_flow()\n        ```\n    \"\"\"  # noqa\n    # check if variable is set, if not check env, if not use expected default\n    logger = get_run_logger()\n    if not which(\"dbt\"):\n        raise ImportError(\n            \"dbt-core needs to be installed to use this task; run \"\n            '`pip install \"prefect-dbt[cli]\"'\n        )\n    elif not command.startswith(\"dbt\"):\n        await shell_run_command.fn(command=\"dbt --help\")\n        raise ValueError(\n            \"Command is not a valid dbt sub-command; see dbt --help above,\"\n            \"or use prefect_shell.commands.shell_run_command for non-dbt related \"\n            \"commands instead\"\n        )\n\n    if profiles_dir is None:\n        profiles_dir = os.getenv(\"DBT_PROFILES_DIR\", Path.home() / \".dbt\")\n    profiles_dir = Path(profiles_dir).expanduser()\n\n    # https://docs.getdbt.com/dbt-cli/configure-your-profile\n    # Note that the file always needs to be called profiles.yml,\n    # regardless of which directory it is in.\n    profiles_path = profiles_dir / \"profiles.yml\"\n    logger.debug(f\"Using this profiles path: {profiles_path}\")\n\n    # write the profile if overwrite or no profiles exist\n    if overwrite_profiles or not profiles_path.exists():\n        if dbt_cli_profile is None:\n            raise ValueError(\"Provide `dbt_cli_profile` keyword for writing profiles\")\n        profile = dbt_cli_profile.get_profile()\n        profiles_dir.mkdir(exist_ok=True)\n        with open(profiles_path, \"w+\") as f:\n            yaml.dump(profile, f, default_flow_style=False)\n        logger.info(f\"Wrote profile to {profiles_path}\")\n    elif dbt_cli_profile is not None:\n        raise ValueError(\n            f\"Since overwrite_profiles is False and profiles_path ({profiles_path}) \"\n            f\"already exists, the profile within dbt_cli_profile could not be used; \"\n            f\"if the existing profile is satisfactory, do not pass dbt_cli_profile\"\n        )\n\n    # append the options\n    command += f\" --profiles-dir {profiles_dir}\"\n    if project_dir is not None:\n        project_dir = Path(project_dir).expanduser()\n        command += f\" --project-dir {project_dir}\"\n\n    # fix up empty shell_run_command_kwargs\n    shell_run_command_kwargs = shell_run_command_kwargs or {}\n\n    logger.info(f\"Running dbt command: {command}\")\n    result = await shell_run_command.fn(command=command, **shell_run_command_kwargs)\n    return result\n</code></pre>"},{"location":"cli/credentials/","title":"Credentials","text":""},{"location":"cli/credentials/#prefect_dbt.cli.credentials","title":"<code>prefect_dbt.cli.credentials</code>","text":"<p>Module containing credentials for interacting with dbt CLI</p>"},{"location":"cli/credentials/#prefect_dbt.cli.credentials-classes","title":"Classes","text":""},{"location":"cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile","title":"<code>DbtCliProfile</code>","text":"<p>         Bases: <code>Block</code></p> <p>Profile for use across dbt CLI tasks and flows.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Profile name used for populating profiles.yml.</p> <code>target</code> <code>str</code> <p>The default target your dbt project will use.</p> <code>target_configs</code> <code>TargetConfigs</code> <p>Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink.</p> <code>global_configs</code> <code>GlobalConfigs</code> <p>Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Valid keys can be found here.</p> <p>Examples:</p> <p>Load stored dbt CLI profile: <pre><code>from prefect_dbt.cli import DbtCliProfile\ndbt_cli_profile = DbtCliProfile.load(\"BLOCK_NAME\").get_profile()\n</code></pre></p> <p>Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs: <pre><code>from prefect_dbt.cli import DbtCliProfile\nfrom prefect_dbt.cli.configs import SnowflakeTargetConfigs\nfrom prefect_snowflake.credentials import SnowflakeCredentials\nfrom prefect_snowflake.database import SnowflakeConnector\n\ncredentials = SnowflakeCredentials(\n    user=\"user\",\n    password=\"password\",\n    account=\"account.region.aws\",\n    role=\"role\",\n)\nconnector = SnowflakeConnector(\n    schema=\"public\",\n    database=\"database\",\n    warehouse=\"warehouse\",\n    credentials=credentials,\n)\ntarget_configs = SnowflakeTargetConfigs(\n    connector=connector\n)\ndbt_cli_profile = DbtCliProfile(\n    name=\"jaffle_shop\",\n    target=\"dev\",\n    target_configs=target_configs,\n)\nprofile = dbt_cli_profile.get_profile()\n</code></pre></p> <p>Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs: <pre><code>from prefect_dbt.cli import DbtCliProfile\nfrom prefect_dbt.cli.configs import GlobalConfigs, TargetConfigs\n\ntarget_configs_extras = dict(\n    host=\"hostname.region.redshift.amazonaws.com\",\n    user=\"username\",\n    password=\"password1\",\n    port=5439,\n    dbname=\"analytics\",\n)\ntarget_configs = TargetConfigs(\n    type=\"redshift\",\n    schema=\"schema\",\n    threads=4,\n    extras=target_configs_extras\n)\ndbt_cli_profile = DbtCliProfile(\n    name=\"jaffle_shop\",\n    target=\"dev\",\n    target_configs=target_configs,\n)\nprofile = dbt_cli_profile.get_profile()\n</code></pre></p> Source code in <code>prefect_dbt/cli/credentials.py</code> <pre><code>class DbtCliProfile(Block):\n\"\"\"\n    Profile for use across dbt CLI tasks and flows.\n\n    Attributes:\n        name (str): Profile name used for populating profiles.yml.\n        target (str): The default target your dbt project will use.\n        target_configs (TargetConfigs): Target configs contain credentials and\n            settings, specific to the warehouse you're connecting to.\n            To find valid keys, head to the [Available adapters](\n            https://docs.getdbt.com/docs/available-adapters) page and\n            click the desired adapter's \"Profile Setup\" hyperlink.\n        global_configs (GlobalConfigs): Global configs control\n            things like the visual output of logs, the manner\n            in which dbt parses your project, and what to do when\n            dbt finds a version mismatch or a failing model.\n            Valid keys can be found [here](\n            https://docs.getdbt.com/reference/global-configs).\n\n    Examples:\n        Load stored dbt CLI profile:\n        ```python\n        from prefect_dbt.cli import DbtCliProfile\n        dbt_cli_profile = DbtCliProfile.load(\"BLOCK_NAME\").get_profile()\n        ```\n\n        Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs:\n        ```python\n        from prefect_dbt.cli import DbtCliProfile\n        from prefect_dbt.cli.configs import SnowflakeTargetConfigs\n        from prefect_snowflake.credentials import SnowflakeCredentials\n        from prefect_snowflake.database import SnowflakeConnector\n\n        credentials = SnowflakeCredentials(\n            user=\"user\",\n            password=\"password\",\n            account=\"account.region.aws\",\n            role=\"role\",\n        )\n        connector = SnowflakeConnector(\n            schema=\"public\",\n            database=\"database\",\n            warehouse=\"warehouse\",\n            credentials=credentials,\n        )\n        target_configs = SnowflakeTargetConfigs(\n            connector=connector\n        )\n        dbt_cli_profile = DbtCliProfile(\n            name=\"jaffle_shop\",\n            target=\"dev\",\n            target_configs=target_configs,\n        )\n        profile = dbt_cli_profile.get_profile()\n        ```\n\n        Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs:\n        ```python\n        from prefect_dbt.cli import DbtCliProfile\n        from prefect_dbt.cli.configs import GlobalConfigs, TargetConfigs\n\n        target_configs_extras = dict(\n            host=\"hostname.region.redshift.amazonaws.com\",\n            user=\"username\",\n            password=\"password1\",\n            port=5439,\n            dbname=\"analytics\",\n        )\n        target_configs = TargetConfigs(\n            type=\"redshift\",\n            schema=\"schema\",\n            threads=4,\n            extras=target_configs_extras\n        )\n        dbt_cli_profile = DbtCliProfile(\n            name=\"jaffle_shop\",\n            target=\"dev\",\n            target_configs=target_configs,\n        )\n        profile = dbt_cli_profile.get_profile()\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt CLI Profile\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile\"  # noqa\n\n    name: str = Field(\n        default=..., description=\"Profile name used for populating profiles.yml.\"\n    )\n    target: str = Field(\n        default=..., description=\"The default target your dbt project will use.\"\n    )\n    target_configs: Union[\n        SnowflakeTargetConfigs,\n        BigQueryTargetConfigs,\n        PostgresTargetConfigs,\n        TargetConfigs,\n    ] = Field(\n        default=...,\n        description=(\n            \"Target configs contain credentials and settings, specific to the \"\n            \"warehouse you're connecting to.\"\n        ),\n    )\n    global_configs: Optional[GlobalConfigs] = Field(\n        default=None,\n        description=(\n            \"Global configs control things like the visual output of logs, the manner \"\n            \"in which dbt parses your project, and what to do when dbt finds a version \"\n            \"mismatch or a failing model.\"\n        ),\n    )\n\n    def get_profile(self) -&gt; Dict[str, Any]:\n\"\"\"\n        Returns the dbt profile, likely used for writing to profiles.yml.\n\n        Returns:\n            A JSON compatible dictionary with the expected format of profiles.yml.\n        \"\"\"\n        profile = {\n            \"config\": self.global_configs.get_configs() if self.global_configs else {},\n            self.name: {\n                \"target\": self.target,\n                \"outputs\": {self.target: self.target_configs.get_configs()},\n            },\n        }\n        return profile\n</code></pre>"},{"location":"cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile-functions","title":"Functions","text":""},{"location":"cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile.get_profile","title":"<code>get_profile</code>","text":"<p>Returns the dbt profile, likely used for writing to profiles.yml.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A JSON compatible dictionary with the expected format of profiles.yml.</p> Source code in <code>prefect_dbt/cli/credentials.py</code> <pre><code>def get_profile(self) -&gt; Dict[str, Any]:\n\"\"\"\n    Returns the dbt profile, likely used for writing to profiles.yml.\n\n    Returns:\n        A JSON compatible dictionary with the expected format of profiles.yml.\n    \"\"\"\n    profile = {\n        \"config\": self.global_configs.get_configs() if self.global_configs else {},\n        self.name: {\n            \"target\": self.target,\n            \"outputs\": {self.target: self.target_configs.get_configs()},\n        },\n    }\n    return profile\n</code></pre>"},{"location":"cli/configs/base/","title":"Base","text":""},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base","title":"<code>prefect_dbt.cli.configs.base</code>","text":"<p>Module containing models for base configs</p>"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base-classes","title":"Classes","text":""},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs","title":"<code>DbtConfigs</code>","text":"<p>         Bases: <code>Block</code>, <code>abc.ABC</code></p> <p>Abstract class for other dbt Configs.</p> <p>Attributes:</p> Name Type Description <code>extras</code> <code>Optional[Dict[str, Any]]</code> <p>Extra target configs' keywords, not yet exposed in prefect-dbt, but available in dbt; if there are duplicate keys between extras and TargetConfigs, an error will be raised.</p> Source code in <code>prefect_dbt/cli/configs/base.py</code> <pre><code>class DbtConfigs(Block, abc.ABC):\n\"\"\"\n    Abstract class for other dbt Configs.\n\n    Attributes:\n        extras: Extra target configs' keywords, not yet exposed\n            in prefect-dbt, but available in dbt; if there are\n            duplicate keys between extras and TargetConfigs,\n            an error will be raised.\n    \"\"\"\n\n    extras: Optional[Dict[str, Any]] = Field(\n        default=None,\n        description=(\n            \"Extra target configs' keywords, not yet exposed in prefect-dbt, \"\n            \"but available in dbt.\"\n        ),\n    )\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs\"  # noqa\n\n    def _populate_configs_json(\n        self,\n        configs_json: Dict[str, Any],\n        fields: Dict[str, Any],\n        model: BaseModel = None,\n    ) -&gt; Dict[str, Any]:\n\"\"\"\n        Recursively populate configs_json.\n        \"\"\"\n        for field_name, field in fields.items():\n            if model is not None:\n                # get actual value from model\n                try:\n                    field_value = getattr(model, field_name)\n                except AttributeError:\n                    field_value = getattr(model, field.alias)\n                # override the name with alias so dbt parser can recognize the keyword;\n                # e.g. schema_ -&gt; schema, returns the original name if no alias is set\n                field_name = field.alias\n            else:\n                field_value = field\n\n            if field_value is None:\n                # do not add to configs json if no value or default is set\n                continue\n\n            if isinstance(field_value, BaseModel):\n                configs_json = self._populate_configs_json(\n                    configs_json, field_value.__fields__, model=field_value\n                )\n            elif field_name == \"extras\":\n                configs_json = self._populate_configs_json(configs_json, field_value)\n            else:\n                if field_name in configs_json.keys():\n                    raise ValueError(\n                        f\"The keyword, {field_name}, has already been provided in \"\n                        f\"TargetConfigs; remove duplicated keywords to continue\"\n                    )\n                if isinstance(field_value, SecretField):\n                    field_value = field_value.get_secret_value()\n                configs_json[field_name] = field_value\n\n        return configs_json\n\n    def get_configs(self) -&gt; Dict[str, Any]:\n\"\"\"\n        Returns the dbt configs, likely used eventually for writing to profiles.yml.\n\n        Returns:\n            A configs JSON.\n        \"\"\"\n        return self._populate_configs_json({}, self.__fields__, model=self)\n</code></pre>"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs-functions","title":"Functions","text":""},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs.get_configs","title":"<code>get_configs</code>","text":"<p>Returns the dbt configs, likely used eventually for writing to profiles.yml.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A configs JSON.</p> Source code in <code>prefect_dbt/cli/configs/base.py</code> <pre><code>def get_configs(self) -&gt; Dict[str, Any]:\n\"\"\"\n    Returns the dbt configs, likely used eventually for writing to profiles.yml.\n\n    Returns:\n        A configs JSON.\n    \"\"\"\n    return self._populate_configs_json({}, self.__fields__, model=self)\n</code></pre>"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.GlobalConfigs","title":"<code>GlobalConfigs</code>","text":"<p>         Bases: <code>DbtConfigs</code></p> <p>Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Docs can be found here.</p> <p>Attributes:</p> Name Type Description <code>send_anonymous_usage_stats</code> <code>Optional[bool]</code> <p>Whether usage stats are sent to dbt.</p> <code>use_colors</code> <code>Optional[bool]</code> <p>Colorize the output it prints in your terminal.</p> <code>partial_parse</code> <code>Optional[bool]</code> <p>When partial parsing is enabled, dbt will use an stored internal manifest to determine which files have been changed (if any) since it last parsed the project.</p> <code>printer_width</code> <code>Optional[int]</code> <p>Length of characters before starting a new line.</p> <code>write_json</code> <code>Optional[bool]</code> <p>Determines whether dbt writes JSON artifacts to the target/ directory.</p> <code>warn_error</code> <code>Optional[bool]</code> <p>Whether to convert dbt warnings into errors.</p> <code>log_format</code> <code>Optional[bool]</code> <p>The LOG_FORMAT config specifies how dbt's logs should be formatted. If the value of this config is json, dbt will output fully structured logs in JSON format.</p> <code>debug</code> <code>Optional[bool]</code> <p>Whether to redirect dbt's debug logs to standard out.</p> <code>version_check</code> <code>Optional[bool]</code> <p>Whether to raise an error if a project's version is used with an incompatible dbt version.</p> <code>fail_fast</code> <code>Optional[bool]</code> <p>Make dbt exit immediately if a single resource fails to build.</p> <code>use_experimental_parser</code> <code>Optional[bool]</code> <p>Opt into the latest experimental version of the static parser.</p> <code>static_parser</code> <code>Optional[bool]</code> <p>Whether to use the static parser.</p> <p>Examples:</p> <p>Load stored GlobalConfigs: <pre><code>from prefect_dbt.cli.configs import GlobalConfigs\n\ndbt_cli_global_configs = GlobalConfigs.load(\"BLOCK_NAME\")\n</code></pre></p> Source code in <code>prefect_dbt/cli/configs/base.py</code> <pre><code>class GlobalConfigs(DbtConfigs):\n\"\"\"\n    Global configs control things like the visual output\n    of logs, the manner in which dbt parses your project,\n    and what to do when dbt finds a version mismatch\n    or a failing model. Docs can be found [here](\n    https://docs.getdbt.com/reference/global-configs).\n\n    Attributes:\n        send_anonymous_usage_stats: Whether usage stats are sent to dbt.\n        use_colors: Colorize the output it prints in your terminal.\n        partial_parse: When partial parsing is enabled, dbt will use an\n            stored internal manifest to determine which files have been changed\n            (if any) since it last parsed the project.\n        printer_width: Length of characters before starting a new line.\n        write_json: Determines whether dbt writes JSON artifacts to\n            the target/ directory.\n        warn_error: Whether to convert dbt warnings into errors.\n        log_format: The LOG_FORMAT config specifies how dbt's logs should\n            be formatted. If the value of this config is json, dbt will\n            output fully structured logs in JSON format.\n        debug: Whether to redirect dbt's debug logs to standard out.\n        version_check: Whether to raise an error if a project's version\n            is used with an incompatible dbt version.\n        fail_fast: Make dbt exit immediately if a single resource fails to build.\n        use_experimental_parser: Opt into the latest experimental version\n            of the static parser.\n        static_parser: Whether to use the [static parser](\n            https://docs.getdbt.com/reference/parsing#static-parser).\n\n    Examples:\n        Load stored GlobalConfigs:\n        ```python\n        from prefect_dbt.cli.configs import GlobalConfigs\n\n        dbt_cli_global_configs = GlobalConfigs.load(\"BLOCK_NAME\")\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt CLI Global Configs\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/configs/base/#prefect_dbt.cli.configs.base.GlobalConfigs\"  # noqa\n\n    send_anonymous_usage_stats: Optional[bool] = Field(\n        default=None,\n        description=\"Whether usage stats are sent to dbt.\",\n    )\n    use_colors: Optional[bool] = Field(\n        default=None,\n        description=\"Colorize the output it prints in your terminal.\",\n    )\n    partial_parse: Optional[bool] = Field(\n        default=None,\n        description=(\n            \"When partial parsing is enabled, dbt will use an \"\n            \"stored internal manifest to determine which files have been changed \"\n            \"(if any) since it last parsed the project.\"\n        ),\n    )\n    printer_width: Optional[int] = Field(\n        default=None,\n        description=\"Length of characters before starting a new line.\",\n    )\n    write_json: Optional[bool] = Field(\n        default=None,\n        description=(\n            \"Determines whether dbt writes JSON artifacts to \" \"the target/ directory.\"\n        ),\n    )\n    warn_error: Optional[bool] = Field(\n        default=None,\n        description=\"Whether to convert dbt warnings into errors.\",\n    )\n    log_format: Optional[bool] = Field(\n        default=None,\n        description=(\n            \"The LOG_FORMAT config specifies how dbt's logs should \"\n            \"be formatted. If the value of this config is json, dbt will \"\n            \"output fully structured logs in JSON format.\"\n        ),\n    )\n    debug: Optional[bool] = Field(\n        default=None,\n        description=\"Whether to redirect dbt's debug logs to standard out.\",\n    )\n    version_check: Optional[bool] = Field(\n        default=None,\n        description=(\n            \"Whether to raise an error if a project's version \"\n            \"is used with an incompatible dbt version.\"\n        ),\n    )\n    fail_fast: Optional[bool] = Field(\n        default=None,\n        description=(\"Make dbt exit immediately if a single resource fails to build.\"),\n    )\n    use_experimental_parser: Optional[bool] = Field(\n        default=None,\n        description=(\n            \"Opt into the latest experimental version \" \"of the static parser.\"\n        ),\n    )\n    static_parser: Optional[bool] = Field(\n        default=None,\n        description=(\n            \"Whether to use the [static parser](https://docs.getdbt.com/reference/parsing#static-parser).\"  # noqa\n        ),\n    )\n</code></pre>"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.TargetConfigs","title":"<code>TargetConfigs</code>","text":"<p>         Bases: <code>BaseTargetConfigs</code></p> <p>Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink.</p> <p>Attributes:</p> Name Type Description <code>type</code> <p>The name of the database warehouse.</p> <code>schema</code> <p>The schema that dbt will build objects into; in BigQuery, a schema is actually a dataset.</p> <code>threads</code> <p>The number of threads representing the max number of paths through the graph dbt may work on at once.</p> <p>Examples:</p> <p>Load stored TargetConfigs: <pre><code>from prefect_dbt.cli.configs import TargetConfigs\n\ndbt_cli_target_configs = TargetConfigs.load(\"BLOCK_NAME\")\n</code></pre></p> Source code in <code>prefect_dbt/cli/configs/base.py</code> <pre><code>class TargetConfigs(BaseTargetConfigs):\n\"\"\"\n    Target configs contain credentials and\n    settings, specific to the warehouse you're connecting to.\n    To find valid keys, head to the [Available adapters](\n    https://docs.getdbt.com/docs/available-adapters) page and\n    click the desired adapter's \"Profile Setup\" hyperlink.\n\n    Attributes:\n        type: The name of the database warehouse.\n        schema: The schema that dbt will build objects into;\n            in BigQuery, a schema is actually a dataset.\n        threads: The number of threads representing the max number\n            of paths through the graph dbt may work on at once.\n\n    Examples:\n        Load stored TargetConfigs:\n        ```python\n        from prefect_dbt.cli.configs import TargetConfigs\n\n        dbt_cli_target_configs = TargetConfigs.load(\"BLOCK_NAME\")\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt CLI Target Configs\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/configs/base/#prefect_dbt.cli.configs.base.TargetConfigs\"  # noqa\n</code></pre>"},{"location":"cli/configs/bigquery/","title":"BigQuery","text":""},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery","title":"<code>prefect_dbt.cli.configs.bigquery</code>","text":"<p>Module containing models for BigQuery configs</p>"},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery-classes","title":"Classes","text":""},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs","title":"<code>BigQueryTargetConfigs</code>","text":"<p>         Bases: <code>BaseTargetConfigs</code></p> <p>Target configs contain credentials and settings, specific to BigQuery. To find valid keys, head to the BigQuery Profile page.</p> <p>Attributes:</p> Name Type Description <code>credentials</code> <code>GcpCredentials</code> <p>The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised.</p> <p>Examples:</p> <p>Load stored BigQueryTargetConfigs: <pre><code>from prefect_dbt.cli.configs import BigQueryTargetConfigs\n\nbigquery_target_configs = BigQueryTargetConfigs.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Instantiate BigQueryTargetConfigs with service account file. <pre><code>from prefect_dbt.cli.configs import BigQueryTargetConfigs\nfrom prefect_gcp.credentials import GcpCredentials\n\ncredentials = GcpCredentials(service_account_file=\"~/.secrets/gcp\")\ntarget_configs = BigQueryTargetConfigs(\n    schema=\"schema\",\n    project=\"project\",\n    credentials=credentials,\n)\n</code></pre></p> <p>Instantiate BigQueryTargetConfigs with service account info. <pre><code>import json\nfrom prefect_dbt.cli.configs import BigQueryTargetConfigs\nfrom prefect_gcp.credentials import GcpCredentials\n\ncredentials = GcpCredentials(\n    service_account_info=json.dumps({\n        \"type\": \"service_account\",\n        \"project_id\": \"project_id\",\n        \"private_key_id\": \"private_key_id\",\n        \"private_key\": \"private_key\",\n        \"client_email\": \"client_email\",\n        \"client_id\": \"client_id\",\n        \"auth_uri\": \"auth_uri\",\n        \"token_uri\": \"token_uri\",\n        \"auth_provider_x509_cert_url\": \"auth_provider_x509_cert_url\",\n        \"client_x509_cert_url\": \"client_x509_cert_url\"\n    })\n)\ntarget_configs = BigQueryTargetConfigs(\n    schema=\"schema\",\n    project=\"project\",\n    credentials=credentials,\n    extras={\"execution_project\": \"my_exe_project\"},\n)\n</code></pre></p> Source code in <code>prefect_dbt/cli/configs/bigquery.py</code> <pre><code>class BigQueryTargetConfigs(BaseTargetConfigs):\n\"\"\"\n    Target configs contain credentials and\n    settings, specific to BigQuery.\n    To find valid keys, head to the [BigQuery Profile](\n    https://docs.getdbt.com/reference/warehouse-profiles/bigquery-profile)\n    page.\n\n    Attributes:\n        credentials: The credentials to use to authenticate; if there are\n            duplicate keys between credentials and TargetConfigs,\n            e.g. schema, an error will be raised.\n\n    Examples:\n        Load stored BigQueryTargetConfigs:\n        ```python\n        from prefect_dbt.cli.configs import BigQueryTargetConfigs\n\n        bigquery_target_configs = BigQueryTargetConfigs.load(\"BLOCK_NAME\")\n        ```\n\n        Instantiate BigQueryTargetConfigs with service account file.\n        ```python\n        from prefect_dbt.cli.configs import BigQueryTargetConfigs\n        from prefect_gcp.credentials import GcpCredentials\n\n        credentials = GcpCredentials(service_account_file=\"~/.secrets/gcp\")\n        target_configs = BigQueryTargetConfigs(\n            schema=\"schema\",\n            project=\"project\",\n            credentials=credentials,\n        )\n        ```\n\n        Instantiate BigQueryTargetConfigs with service account info.\n        ```python\n        import json\n        from prefect_dbt.cli.configs import BigQueryTargetConfigs\n        from prefect_gcp.credentials import GcpCredentials\n\n        credentials = GcpCredentials(\n            service_account_info=json.dumps({\n                \"type\": \"service_account\",\n                \"project_id\": \"project_id\",\n                \"private_key_id\": \"private_key_id\",\n                \"private_key\": \"private_key\",\n                \"client_email\": \"client_email\",\n                \"client_id\": \"client_id\",\n                \"auth_uri\": \"auth_uri\",\n                \"token_uri\": \"token_uri\",\n                \"auth_provider_x509_cert_url\": \"auth_provider_x509_cert_url\",\n                \"client_x509_cert_url\": \"client_x509_cert_url\"\n            })\n        )\n        target_configs = BigQueryTargetConfigs(\n            schema=\"schema\",\n            project=\"project\",\n            credentials=credentials,\n            extras={\"execution_project\": \"my_exe_project\"},\n        )\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt CLI BigQuery Target Configs\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _description = \"dbt CLI target configs containing credentials and settings, specific to BigQuery.\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs\"  # noqa\n\n    type: Literal[\"bigquery\"] = Field(\n        default=\"bigquery\", description=\"The type of target.\"\n    )\n    project: Optional[str] = Field(default=None, description=\"The project to use.\")\n    credentials: GcpCredentials = Field(\n        default_factory=GcpCredentials,\n        description=\"The credentials to use to authenticate.\",\n    )\n\n    @sync_compatible\n    async def get_configs(self) -&gt; Dict[str, Any]:\n\"\"\"\n        Returns the dbt configs specific to BigQuery profile.\n\n        Returns:\n            A configs JSON.\n        \"\"\"\n        # since GcpCredentials will always define a project\n        self_copy = self.copy()\n        if self_copy.project is not None:\n            self_copy.credentials.project = None\n        all_configs_json = self._populate_configs_json(\n            {}, self_copy.__fields__, model=self_copy\n        )\n\n        # decouple prefect-gcp from prefect-dbt\n        # by mapping all the keys dbt gcp accepts\n        # https://docs.getdbt.com/reference/warehouse-setups/bigquery-setup\n        rename_keys = {\n            # dbt\n            \"type\": \"type\",\n            \"schema\": \"schema\",\n            \"threads\": \"threads\",\n            # general\n            \"dataset\": \"schema\",\n            \"method\": \"method\",\n            \"project\": \"project\",\n            # service-account\n            \"service_account_file\": \"keyfile\",\n            # service-account json\n            \"service_account_info\": \"keyfile_json\",\n            # oauth secrets\n            \"refresh_token\": \"refresh_token\",\n            \"client_id\": \"client_id\",\n            \"client_secret\": \"client_secret\",\n            \"token_uri\": \"token_uri\",\n            # optional\n            \"priority\": \"priority\",\n            \"timeout_seconds\": \"timeout_seconds\",\n            \"location\": \"location\",\n            \"maximum_bytes_billed\": \"maximum_bytes_billed\",\n            \"scopes\": \"scopes\",\n            \"impersonate_service_account\": \"impersonate_service_account\",\n            \"execution_project\": \"execution_project\",\n        }\n        configs_json = {}\n        extras = self.extras or {}\n        for key in all_configs_json.keys():\n            if key not in rename_keys and key not in extras:\n                # skip invalid keys\n                continue\n            # rename key to something dbt profile expects\n            dbt_key = rename_keys.get(key) or key\n            configs_json[dbt_key] = all_configs_json[key]\n\n        if \"keyfile_json\" in configs_json:\n            configs_json[\"method\"] = \"service-account-json\"\n        elif \"keyfile\" in configs_json:\n            configs_json[\"method\"] = \"service-account\"\n            configs_json[\"keyfile\"] = str(configs_json[\"keyfile\"])\n        else:\n            configs_json[\"method\"] = \"oauth-secrets\"\n            # through gcloud application-default login\n            google_credentials = (\n                self_copy.credentials.get_credentials_from_service_account()\n            )\n            if hasattr(google_credentials, \"token\"):\n                request = Request()\n                google_credentials.refresh(request)\n                configs_json[\"token\"] = google_credentials.token\n            else:\n                for key in (\"refresh_token\", \"client_id\", \"client_secret\", \"token_uri\"):\n                    configs_json[key] = getattr(google_credentials, key)\n\n        if \"project\" not in configs_json:\n            raise ValueError(\n                \"The keyword, project, must be provided in either \"\n                \"GcpCredentials or BigQueryTargetConfigs\"\n            )\n        return configs_json\n</code></pre>"},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs-functions","title":"Functions","text":""},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs.get_configs","title":"<code>get_configs</code>  <code>async</code>","text":"<p>Returns the dbt configs specific to BigQuery profile.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A configs JSON.</p> Source code in <code>prefect_dbt/cli/configs/bigquery.py</code> <pre><code>@sync_compatible\nasync def get_configs(self) -&gt; Dict[str, Any]:\n\"\"\"\n    Returns the dbt configs specific to BigQuery profile.\n\n    Returns:\n        A configs JSON.\n    \"\"\"\n    # since GcpCredentials will always define a project\n    self_copy = self.copy()\n    if self_copy.project is not None:\n        self_copy.credentials.project = None\n    all_configs_json = self._populate_configs_json(\n        {}, self_copy.__fields__, model=self_copy\n    )\n\n    # decouple prefect-gcp from prefect-dbt\n    # by mapping all the keys dbt gcp accepts\n    # https://docs.getdbt.com/reference/warehouse-setups/bigquery-setup\n    rename_keys = {\n        # dbt\n        \"type\": \"type\",\n        \"schema\": \"schema\",\n        \"threads\": \"threads\",\n        # general\n        \"dataset\": \"schema\",\n        \"method\": \"method\",\n        \"project\": \"project\",\n        # service-account\n        \"service_account_file\": \"keyfile\",\n        # service-account json\n        \"service_account_info\": \"keyfile_json\",\n        # oauth secrets\n        \"refresh_token\": \"refresh_token\",\n        \"client_id\": \"client_id\",\n        \"client_secret\": \"client_secret\",\n        \"token_uri\": \"token_uri\",\n        # optional\n        \"priority\": \"priority\",\n        \"timeout_seconds\": \"timeout_seconds\",\n        \"location\": \"location\",\n        \"maximum_bytes_billed\": \"maximum_bytes_billed\",\n        \"scopes\": \"scopes\",\n        \"impersonate_service_account\": \"impersonate_service_account\",\n        \"execution_project\": \"execution_project\",\n    }\n    configs_json = {}\n    extras = self.extras or {}\n    for key in all_configs_json.keys():\n        if key not in rename_keys and key not in extras:\n            # skip invalid keys\n            continue\n        # rename key to something dbt profile expects\n        dbt_key = rename_keys.get(key) or key\n        configs_json[dbt_key] = all_configs_json[key]\n\n    if \"keyfile_json\" in configs_json:\n        configs_json[\"method\"] = \"service-account-json\"\n    elif \"keyfile\" in configs_json:\n        configs_json[\"method\"] = \"service-account\"\n        configs_json[\"keyfile\"] = str(configs_json[\"keyfile\"])\n    else:\n        configs_json[\"method\"] = \"oauth-secrets\"\n        # through gcloud application-default login\n        google_credentials = (\n            self_copy.credentials.get_credentials_from_service_account()\n        )\n        if hasattr(google_credentials, \"token\"):\n            request = Request()\n            google_credentials.refresh(request)\n            configs_json[\"token\"] = google_credentials.token\n        else:\n            for key in (\"refresh_token\", \"client_id\", \"client_secret\", \"token_uri\"):\n                configs_json[key] = getattr(google_credentials, key)\n\n    if \"project\" not in configs_json:\n        raise ValueError(\n            \"The keyword, project, must be provided in either \"\n            \"GcpCredentials or BigQueryTargetConfigs\"\n        )\n    return configs_json\n</code></pre>"},{"location":"cli/configs/postgres/","title":"Postgres","text":""},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres","title":"<code>prefect_dbt.cli.configs.postgres</code>","text":"<p>Module containing models for Postgres configs</p>"},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres-classes","title":"Classes","text":""},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs","title":"<code>PostgresTargetConfigs</code>","text":"<p>         Bases: <code>BaseTargetConfigs</code></p> <p>Target configs contain credentials and settings, specific to Postgres. To find valid keys, head to the Postgres Profile page.</p> <p>Attributes:</p> Name Type Description <code>credentials</code> <code>DatabaseCredentials</code> <p>The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised.</p> <p>Examples:</p> <p>Load stored PostgresTargetConfigs: <pre><code>from prefect_dbt.cli.configs import PostgresTargetConfigs\n\npostgres_target_configs = PostgresTargetConfigs.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Instantiate PostgresTargetConfigs with DatabaseCredentials. <pre><code>from prefect_dbt.cli.configs import PostgresTargetConfigs\nfrom prefect_sqlalchemy import DatabaseCredentials, SyncDriver\n\ncredentials = DatabaseCredentials(\n    driver=SyncDriver.POSTGRESQL_PSYCOPG2,\n    username=\"prefect\",\n    password=\"prefect_password\",\n    database=\"postgres\",\n    host=\"host\",\n    port=8080\n)\ntarget_configs = PostgresTargetConfigs(credentials=credentials, schema=\"schema\")\n</code></pre></p> Source code in <code>prefect_dbt/cli/configs/postgres.py</code> <pre><code>class PostgresTargetConfigs(BaseTargetConfigs):\n\"\"\"\n    Target configs contain credentials and\n    settings, specific to Postgres.\n    To find valid keys, head to the [Postgres Profile](\n    https://docs.getdbt.com/reference/warehouse-profiles/postgres-profile)\n    page.\n\n    Attributes:\n        credentials: The credentials to use to authenticate; if there are\n            duplicate keys between credentials and TargetConfigs,\n            e.g. schema, an error will be raised.\n\n    Examples:\n        Load stored PostgresTargetConfigs:\n        ```python\n        from prefect_dbt.cli.configs import PostgresTargetConfigs\n\n        postgres_target_configs = PostgresTargetConfigs.load(\"BLOCK_NAME\")\n        ```\n\n        Instantiate PostgresTargetConfigs with DatabaseCredentials.\n        ```python\n        from prefect_dbt.cli.configs import PostgresTargetConfigs\n        from prefect_sqlalchemy import DatabaseCredentials, SyncDriver\n\n        credentials = DatabaseCredentials(\n            driver=SyncDriver.POSTGRESQL_PSYCOPG2,\n            username=\"prefect\",\n            password=\"prefect_password\",\n            database=\"postgres\",\n            host=\"host\",\n            port=8080\n        )\n        target_configs = PostgresTargetConfigs(credentials=credentials, schema=\"schema\")\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt CLI Postgres Target Configs\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _description = \"dbt CLI target configs containing credentials and settings specific to Postgres.\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs\"  # noqa\n\n    type: Literal[\"postgres\"] = Field(\n        default=\"postgres\", description=\"The type of the target.\"\n    )\n    credentials: DatabaseCredentials = Field(\n        default=...,\n        description=(\n            \"The credentials to use to authenticate; if there are duplicate keys \"\n            \"between credentials and TargetConfigs, e.g. schema, \"\n            \"an error will be raised.\"\n        ),\n    )  # noqa\n\n    def get_configs(self) -&gt; Dict[str, Any]:\n\"\"\"\n        Returns the dbt configs specific to Postgres profile.\n\n        Returns:\n            A configs JSON.\n        \"\"\"\n        configs_json = super().get_configs()\n        invalid_keys = [\"driver\", \"query\", \"url\", \"connect_args\", \"_async_supported\"]\n        rename_keys = {\n            \"database\": \"dbname\",\n            \"username\": \"user\",\n            \"password\": \"password\",\n            \"host\": \"host\",\n            \"port\": \"port\",\n        }\n        # get the keys from rendered url\n        for invalid_key in invalid_keys + list(rename_keys):\n            configs_json.pop(invalid_key, None)\n\n        rendered_url = self.credentials.rendered_url\n        for key in rename_keys:\n            renamed_key = rename_keys[key]\n            configs_json[renamed_key] = getattr(rendered_url, key)\n        return configs_json\n</code></pre>"},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs-functions","title":"Functions","text":""},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs.get_configs","title":"<code>get_configs</code>","text":"<p>Returns the dbt configs specific to Postgres profile.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A configs JSON.</p> Source code in <code>prefect_dbt/cli/configs/postgres.py</code> <pre><code>def get_configs(self) -&gt; Dict[str, Any]:\n\"\"\"\n    Returns the dbt configs specific to Postgres profile.\n\n    Returns:\n        A configs JSON.\n    \"\"\"\n    configs_json = super().get_configs()\n    invalid_keys = [\"driver\", \"query\", \"url\", \"connect_args\", \"_async_supported\"]\n    rename_keys = {\n        \"database\": \"dbname\",\n        \"username\": \"user\",\n        \"password\": \"password\",\n        \"host\": \"host\",\n        \"port\": \"port\",\n    }\n    # get the keys from rendered url\n    for invalid_key in invalid_keys + list(rename_keys):\n        configs_json.pop(invalid_key, None)\n\n    rendered_url = self.credentials.rendered_url\n    for key in rename_keys:\n        renamed_key = rename_keys[key]\n        configs_json[renamed_key] = getattr(rendered_url, key)\n    return configs_json\n</code></pre>"},{"location":"cli/configs/snowflake/","title":"Snowflake","text":""},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake","title":"<code>prefect_dbt.cli.configs.snowflake</code>","text":"<p>Module containing models for Snowflake configs</p>"},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake-classes","title":"Classes","text":""},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs","title":"<code>SnowflakeTargetConfigs</code>","text":"<p>         Bases: <code>BaseTargetConfigs</code></p> <p>Target configs contain credentials and settings, specific to Snowflake. To find valid keys, head to the Snowflake Profile page.</p> <p>Attributes:</p> Name Type Description <code>connector</code> <code>SnowflakeConnector</code> <p>The connector to use.</p> <p>Examples:</p> <p>Load stored SnowflakeTargetConfigs: <pre><code>from prefect_dbt.cli.configs import SnowflakeTargetConfigs\n\nsnowflake_target_configs = SnowflakeTargetConfigs.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Instantiate SnowflakeTargetConfigs. <pre><code>from prefect_dbt.cli.configs import SnowflakeTargetConfigs\nfrom prefect_snowflake.credentials import SnowflakeCredentials\nfrom prefect_snowflake.database import SnowflakeConnector\n\ncredentials = SnowflakeCredentials(\n    user=\"user\",\n    password=\"password\",\n    account=\"account.region.aws\",\n    role=\"role\",\n)\nconnector = SnowflakeConnector(\n    schema=\"public\",\n    database=\"database\",\n    warehouse=\"warehouse\",\n    credentials=credentials,\n)\ntarget_configs = SnowflakeTargetConfigs(\n    connector=connector,\n    extras={\"retry_on_database_errors\": True},\n)\n</code></pre></p> Source code in <code>prefect_dbt/cli/configs/snowflake.py</code> <pre><code>class SnowflakeTargetConfigs(BaseTargetConfigs):\n\"\"\"\n    Target configs contain credentials and\n    settings, specific to Snowflake.\n    To find valid keys, head to the [Snowflake Profile](\n    https://docs.getdbt.com/reference/warehouse-profiles/snowflake-profile)\n    page.\n\n    Attributes:\n        connector: The connector to use.\n\n    Examples:\n        Load stored SnowflakeTargetConfigs:\n        ```python\n        from prefect_dbt.cli.configs import SnowflakeTargetConfigs\n\n        snowflake_target_configs = SnowflakeTargetConfigs.load(\"BLOCK_NAME\")\n        ```\n\n        Instantiate SnowflakeTargetConfigs.\n        ```python\n        from prefect_dbt.cli.configs import SnowflakeTargetConfigs\n        from prefect_snowflake.credentials import SnowflakeCredentials\n        from prefect_snowflake.database import SnowflakeConnector\n\n        credentials = SnowflakeCredentials(\n            user=\"user\",\n            password=\"password\",\n            account=\"account.region.aws\",\n            role=\"role\",\n        )\n        connector = SnowflakeConnector(\n            schema=\"public\",\n            database=\"database\",\n            warehouse=\"warehouse\",\n            credentials=credentials,\n        )\n        target_configs = SnowflakeTargetConfigs(\n            connector=connector,\n            extras={\"retry_on_database_errors\": True},\n        )\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt CLI Snowflake Target Configs\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs\"  # noqa\n\n    type: Literal[\"snowflake\"] = Field(\n        default=\"snowflake\", description=\"The type of the target configs.\"\n    )\n    schema_: Optional[str] = Field(\n        default=None,\n        alias=\"schema\",\n        description=\"The schema to use for the target configs.\",\n    )\n    connector: SnowflakeConnector = Field(\n        default=..., description=\"The connector to use.\"\n    )\n\n    def get_configs(self) -&gt; Dict[str, Any]:\n\"\"\"\n        Returns the dbt configs specific to Snowflake profile.\n\n        Returns:\n            A configs JSON.\n        \"\"\"\n        all_configs_json = super().get_configs()\n\n        # decouple prefect-snowflake from prefect-dbt\n        # by mapping all the keys dbt snowflake accepts\n        # https://docs.getdbt.com/reference/warehouse-setups/snowflake-setup\n        rename_keys = {\n            # dbt\n            \"type\": \"type\",\n            \"schema\": \"schema\",\n            \"threads\": \"threads\",\n            # general\n            \"account\": \"account\",\n            \"user\": \"user\",\n            \"role\": \"role\",\n            \"database\": \"database\",\n            \"warehouse\": \"warehouse\",\n            # user and password\n            \"password\": \"password\",\n            # duo mfa / sso\n            \"authenticator\": \"authenticator\",\n            # key pair\n            \"private_key_path\": \"private_key_path\",\n            \"private_key_passphrase\": \"private_key_passphrase\",\n            # optional\n            \"client_session_keep_alive\": \"client_session_keep_alive\",\n            \"query_tag\": \"query_tag\",\n            \"connect_retries\": \"connect_retries\",\n            \"connect_timeout\": \"connect_timeout\",\n            \"retry_on_database_errors\": \"retry_on_database_errors\",\n            \"retry_all\": \"retry_all\",\n        }\n        configs_json = {}\n        extras = self.extras or {}\n        for key in all_configs_json.keys():\n            if key not in rename_keys and key not in extras:\n                # skip invalid keys, like fetch_size + poll_frequency_s\n                continue\n            # rename key to something dbt profile expects\n            dbt_key = rename_keys.get(key) or key\n            configs_json[dbt_key] = all_configs_json[key]\n        return configs_json\n</code></pre>"},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs-functions","title":"Functions","text":""},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs.get_configs","title":"<code>get_configs</code>","text":"<p>Returns the dbt configs specific to Snowflake profile.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A configs JSON.</p> Source code in <code>prefect_dbt/cli/configs/snowflake.py</code> <pre><code>def get_configs(self) -&gt; Dict[str, Any]:\n\"\"\"\n    Returns the dbt configs specific to Snowflake profile.\n\n    Returns:\n        A configs JSON.\n    \"\"\"\n    all_configs_json = super().get_configs()\n\n    # decouple prefect-snowflake from prefect-dbt\n    # by mapping all the keys dbt snowflake accepts\n    # https://docs.getdbt.com/reference/warehouse-setups/snowflake-setup\n    rename_keys = {\n        # dbt\n        \"type\": \"type\",\n        \"schema\": \"schema\",\n        \"threads\": \"threads\",\n        # general\n        \"account\": \"account\",\n        \"user\": \"user\",\n        \"role\": \"role\",\n        \"database\": \"database\",\n        \"warehouse\": \"warehouse\",\n        # user and password\n        \"password\": \"password\",\n        # duo mfa / sso\n        \"authenticator\": \"authenticator\",\n        # key pair\n        \"private_key_path\": \"private_key_path\",\n        \"private_key_passphrase\": \"private_key_passphrase\",\n        # optional\n        \"client_session_keep_alive\": \"client_session_keep_alive\",\n        \"query_tag\": \"query_tag\",\n        \"connect_retries\": \"connect_retries\",\n        \"connect_timeout\": \"connect_timeout\",\n        \"retry_on_database_errors\": \"retry_on_database_errors\",\n        \"retry_all\": \"retry_all\",\n    }\n    configs_json = {}\n    extras = self.extras or {}\n    for key in all_configs_json.keys():\n        if key not in rename_keys and key not in extras:\n            # skip invalid keys, like fetch_size + poll_frequency_s\n            continue\n        # rename key to something dbt profile expects\n        dbt_key = rename_keys.get(key) or key\n        configs_json[dbt_key] = all_configs_json[key]\n    return configs_json\n</code></pre>"},{"location":"cloud/clients/","title":"Clients","text":""},{"location":"cloud/clients/#prefect_dbt.cloud.clients","title":"<code>prefect_dbt.cloud.clients</code>","text":"<p>Module containing clients for interacting with the dbt Cloud API</p>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients-classes","title":"Classes","text":""},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient","title":"<code>DbtCloudAdministrativeClient</code>","text":"<p>Client for interacting with the dbt cloud Administrative API.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>API key to authenticate with the dbt Cloud administrative API.</p> required <code>account_id</code> <code>int</code> <p>ID of dbt Cloud account with which to interact.</p> required <code>domain</code> <code>str</code> <p>Domain at which the dbt Cloud API is hosted.</p> <code>'cloud.getdbt.com'</code> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>class DbtCloudAdministrativeClient:\n\"\"\"\n    Client for interacting with the dbt cloud Administrative API.\n\n    Args:\n        api_key: API key to authenticate with the dbt Cloud administrative API.\n        account_id: ID of dbt Cloud account with which to interact.\n        domain: Domain at which the dbt Cloud API is hosted.\n    \"\"\"\n\n    def __init__(self, api_key: str, account_id: int, domain: str = \"cloud.getdbt.com\"):\n        self._closed = False\n        self._started = False\n\n        self._admin_client = AsyncClient(\n            headers={\n                \"Authorization\": f\"Bearer {api_key}\",\n                \"user-agent\": f\"prefect-{prefect.__version__}\",\n            },\n            base_url=f\"https://{domain}/api/v2/accounts/{account_id}\",\n        )\n\n    async def call_endpoint(\n        self,\n        http_method: str,\n        path: str,\n        params: Optional[Dict[str, Any]] = None,\n        json: Optional[Dict[str, Any]] = None,\n    ) -&gt; Response:\n\"\"\"\n        Call an endpoint in the dbt Cloud API.\n\n        Args:\n            path: The partial path for the request (e.g. /projects/). Will be appended\n                onto the base URL as determined by the client configuration.\n            http_method: HTTP method to call on the endpoint.\n            params: Query parameters to include in the request.\n            json: JSON serializable body to send in the request.\n\n        Returns:\n            The response from the dbt Cloud administrative API.\n        \"\"\"\n        response = await self._admin_client.request(\n            method=http_method, url=path, params=params, json=json\n        )\n\n        response.raise_for_status()\n\n        return response\n\n    async def get_job(\n        self,\n        job_id: int,\n        order_by: Optional[str] = None,\n    ) -&gt; Response:\n\"\"\"\n        Return job details for a job on an account.\n\n        Args:\n            job_id: Numeric ID of the job.\n            order_by: Field to order the result by. Use - to indicate reverse order.\n\n        Returns:\n            The response from the dbt Cloud administrative API.\n        \"\"\"  # noqa\n        params = {\"order_by\": order_by} if order_by else None\n        return await self.call_endpoint(\n            path=f\"/jobs/{job_id}/\", http_method=\"GET\", params=params\n        )\n\n    async def trigger_job_run(\n        self, job_id: int, options: Optional[TriggerJobRunOptions] = None\n    ) -&gt; Response:\n\"\"\"\n        Sends a request to the [trigger job run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Jobs/operation/triggerRun)\n        to initiate a job run.\n\n        Args:\n            job_id: The ID of the job to trigger.\n            options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run.\n\n        Returns:\n            The response from the dbt Cloud administrative API.\n        \"\"\"  # noqa\n        if options is None:\n            options = TriggerJobRunOptions()\n\n        return await self.call_endpoint(\n            path=f\"/jobs/{job_id}/run/\",\n            http_method=\"POST\",\n            json=options.dict(exclude_none=True),\n        )\n\n    async def get_run(\n        self,\n        run_id: int,\n        include_related: Optional[\n            List[Literal[\"trigger\", \"job\", \"debug_logs\", \"run_steps\"]]\n        ] = None,\n    ) -&gt; Response:\n\"\"\"\n        Sends a request to the [get run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getRunById)\n        to get details about a job run.\n\n        Args:\n            run_id: The ID of the run to get details for.\n            include_related: List of related fields to pull with the run.\n                Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\".\n                If \"debug_logs\" is not provided in a request, then the included debug\n                logs will be truncated to the last 1,000 lines of the debug log output file.\n\n        Returns:\n            The response from the dbt Cloud administrative API.\n        \"\"\"  # noqa\n        params = {\"include_related\": include_related} if include_related else None\n        return await self.call_endpoint(\n            path=f\"/runs/{run_id}/\", http_method=\"GET\", params=params\n        )\n\n    async def list_run_artifacts(\n        self, run_id: int, step: Optional[int] = None\n    ) -&gt; Response:\n\"\"\"\n        Sends a request to the [list run artifacts endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/listArtifactsByRunId)\n        to fetch a list of paths of artifacts generated for a completed run.\n\n        Args:\n            run_id: The ID of the run to list run artifacts for.\n            step: The index of the step in the run to query for artifacts. The\n                first step in the run has the index 1. If the step parameter is\n                omitted, then this method will return the artifacts compiled\n                for the last step in the run.\n\n        Returns:\n            The response from the dbt Cloud administrative API.\n        \"\"\"  # noqa\n        params = {\"step\": step} if step else None\n        return await self.call_endpoint(\n            path=f\"/runs/{run_id}/artifacts/\", http_method=\"GET\", params=params\n        )\n\n    async def get_run_artifact(\n        self, run_id: int, path: str, step: Optional[int] = None\n    ) -&gt; Response:\n\"\"\"\n        Sends a request to the [get run artifact endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getArtifactsByRunId)\n        to fetch an artifact generated for a completed run.\n\n        Args:\n            run_id: The ID of the run to list run artifacts for.\n            path: The relative path to the run artifact (e.g. manifest.json, catalog.json,\n                run_results.json)\n            step: The index of the step in the run to query for artifacts. The\n                first step in the run has the index 1. If the step parameter is\n                omitted, then this method will return the artifacts compiled\n                for the last step in the run.\n\n        Returns:\n            The response from the dbt Cloud administrative API.\n        \"\"\"  # noqa\n        params = {\"step\": step} if step else None\n        return await self.call_endpoint(\n            path=f\"/runs/{run_id}/artifacts/{path}\", http_method=\"GET\", params=params\n        )\n\n    async def __aenter__(self):\n        if self._closed:\n            raise RuntimeError(\n                \"The client cannot be started again after it has been closed.\"\n            )\n        if self._started:\n            raise RuntimeError(\"The client cannot be started more than once.\")\n\n        self._started = True\n\n        return self\n\n    async def __aexit__(self, *exc):\n        self._closed = True\n        await self._admin_client.__aexit__()\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient-functions","title":"Functions","text":""},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.call_endpoint","title":"<code>call_endpoint</code>  <code>async</code>","text":"<p>Call an endpoint in the dbt Cloud API.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration.</p> required <code>http_method</code> <code>str</code> <p>HTTP method to call on the endpoint.</p> required <code>params</code> <code>Optional[Dict[str, Any]]</code> <p>Query parameters to include in the request.</p> <code>None</code> <code>json</code> <code>Optional[Dict[str, Any]]</code> <p>JSON serializable body to send in the request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>The response from the dbt Cloud administrative API.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>async def call_endpoint(\n    self,\n    http_method: str,\n    path: str,\n    params: Optional[Dict[str, Any]] = None,\n    json: Optional[Dict[str, Any]] = None,\n) -&gt; Response:\n\"\"\"\n    Call an endpoint in the dbt Cloud API.\n\n    Args:\n        path: The partial path for the request (e.g. /projects/). Will be appended\n            onto the base URL as determined by the client configuration.\n        http_method: HTTP method to call on the endpoint.\n        params: Query parameters to include in the request.\n        json: JSON serializable body to send in the request.\n\n    Returns:\n        The response from the dbt Cloud administrative API.\n    \"\"\"\n    response = await self._admin_client.request(\n        method=http_method, url=path, params=params, json=json\n    )\n\n    response.raise_for_status()\n\n    return response\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.get_job","title":"<code>get_job</code>  <code>async</code>","text":"<p>Return job details for a job on an account.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>int</code> <p>Numeric ID of the job.</p> required <code>order_by</code> <code>Optional[str]</code> <p>Field to order the result by. Use - to indicate reverse order.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>The response from the dbt Cloud administrative API.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>async def get_job(\n    self,\n    job_id: int,\n    order_by: Optional[str] = None,\n) -&gt; Response:\n\"\"\"\n    Return job details for a job on an account.\n\n    Args:\n        job_id: Numeric ID of the job.\n        order_by: Field to order the result by. Use - to indicate reverse order.\n\n    Returns:\n        The response from the dbt Cloud administrative API.\n    \"\"\"  # noqa\n    params = {\"order_by\": order_by} if order_by else None\n    return await self.call_endpoint(\n        path=f\"/jobs/{job_id}/\", http_method=\"GET\", params=params\n    )\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.get_run","title":"<code>get_run</code>  <code>async</code>","text":"<p>Sends a request to the get run endpoint to get details about a job run.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>int</code> <p>The ID of the run to get details for.</p> required <code>include_related</code> <code>Optional[List[Literal[trigger, job, debug_logs, run_steps]]]</code> <p>List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>The response from the dbt Cloud administrative API.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>async def get_run(\n    self,\n    run_id: int,\n    include_related: Optional[\n        List[Literal[\"trigger\", \"job\", \"debug_logs\", \"run_steps\"]]\n    ] = None,\n) -&gt; Response:\n\"\"\"\n    Sends a request to the [get run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getRunById)\n    to get details about a job run.\n\n    Args:\n        run_id: The ID of the run to get details for.\n        include_related: List of related fields to pull with the run.\n            Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\".\n            If \"debug_logs\" is not provided in a request, then the included debug\n            logs will be truncated to the last 1,000 lines of the debug log output file.\n\n    Returns:\n        The response from the dbt Cloud administrative API.\n    \"\"\"  # noqa\n    params = {\"include_related\": include_related} if include_related else None\n    return await self.call_endpoint(\n        path=f\"/runs/{run_id}/\", http_method=\"GET\", params=params\n    )\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.get_run_artifact","title":"<code>get_run_artifact</code>  <code>async</code>","text":"<p>Sends a request to the get run artifact endpoint to fetch an artifact generated for a completed run.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>int</code> <p>The ID of the run to list run artifacts for.</p> required <code>path</code> <code>str</code> <p>The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json)</p> required <code>step</code> <code>Optional[int]</code> <p>The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>The response from the dbt Cloud administrative API.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>async def get_run_artifact(\n    self, run_id: int, path: str, step: Optional[int] = None\n) -&gt; Response:\n\"\"\"\n    Sends a request to the [get run artifact endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getArtifactsByRunId)\n    to fetch an artifact generated for a completed run.\n\n    Args:\n        run_id: The ID of the run to list run artifacts for.\n        path: The relative path to the run artifact (e.g. manifest.json, catalog.json,\n            run_results.json)\n        step: The index of the step in the run to query for artifacts. The\n            first step in the run has the index 1. If the step parameter is\n            omitted, then this method will return the artifacts compiled\n            for the last step in the run.\n\n    Returns:\n        The response from the dbt Cloud administrative API.\n    \"\"\"  # noqa\n    params = {\"step\": step} if step else None\n    return await self.call_endpoint(\n        path=f\"/runs/{run_id}/artifacts/{path}\", http_method=\"GET\", params=params\n    )\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.list_run_artifacts","title":"<code>list_run_artifacts</code>  <code>async</code>","text":"<p>Sends a request to the list run artifacts endpoint to fetch a list of paths of artifacts generated for a completed run.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>int</code> <p>The ID of the run to list run artifacts for.</p> required <code>step</code> <code>Optional[int]</code> <p>The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>The response from the dbt Cloud administrative API.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>async def list_run_artifacts(\n    self, run_id: int, step: Optional[int] = None\n) -&gt; Response:\n\"\"\"\n    Sends a request to the [list run artifacts endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/listArtifactsByRunId)\n    to fetch a list of paths of artifacts generated for a completed run.\n\n    Args:\n        run_id: The ID of the run to list run artifacts for.\n        step: The index of the step in the run to query for artifacts. The\n            first step in the run has the index 1. If the step parameter is\n            omitted, then this method will return the artifacts compiled\n            for the last step in the run.\n\n    Returns:\n        The response from the dbt Cloud administrative API.\n    \"\"\"  # noqa\n    params = {\"step\": step} if step else None\n    return await self.call_endpoint(\n        path=f\"/runs/{run_id}/artifacts/\", http_method=\"GET\", params=params\n    )\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.trigger_job_run","title":"<code>trigger_job_run</code>  <code>async</code>","text":"<p>Sends a request to the trigger job run endpoint to initiate a job run.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>int</code> <p>The ID of the job to trigger.</p> required <code>options</code> <code>Optional[TriggerJobRunOptions]</code> <p>An optional TriggerJobRunOptions instance to specify overrides for the triggered job run.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>The response from the dbt Cloud administrative API.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>async def trigger_job_run(\n    self, job_id: int, options: Optional[TriggerJobRunOptions] = None\n) -&gt; Response:\n\"\"\"\n    Sends a request to the [trigger job run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Jobs/operation/triggerRun)\n    to initiate a job run.\n\n    Args:\n        job_id: The ID of the job to trigger.\n        options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run.\n\n    Returns:\n        The response from the dbt Cloud administrative API.\n    \"\"\"  # noqa\n    if options is None:\n        options = TriggerJobRunOptions()\n\n    return await self.call_endpoint(\n        path=f\"/jobs/{job_id}/run/\",\n        http_method=\"POST\",\n        json=options.dict(exclude_none=True),\n    )\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudMetadataClient","title":"<code>DbtCloudMetadataClient</code>","text":"<p>Client for interacting with the dbt cloud Administrative API.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>API key to authenticate with the dbt Cloud administrative API.</p> required <code>domain</code> <code>str</code> <p>Domain at which the dbt Cloud API is hosted.</p> <code>'metadata.cloud.getdbt.com'</code> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>class DbtCloudMetadataClient:\n\"\"\"\n    Client for interacting with the dbt cloud Administrative API.\n\n    Args:\n        api_key: API key to authenticate with the dbt Cloud administrative API.\n        domain: Domain at which the dbt Cloud API is hosted.\n    \"\"\"\n\n    def __init__(self, api_key: str, domain: str = \"metadata.cloud.getdbt.com\"):\n        self._http_endpoint = HTTPEndpoint(\n            base_headers={\n                \"Authorization\": f\"Bearer {api_key}\",\n                \"user-agent\": f\"prefect-{prefect.__version__}\",\n                \"content-type\": \"application/json\",\n            },\n            url=f\"https://{domain}/graphql\",\n        )\n\n    def query(\n        self,\n        query: str,\n        variables: Optional[Dict] = None,\n        operation_name: Optional[str] = None,\n    ) -&gt; Dict[str, Any]:\n\"\"\"\n        Run a GraphQL query against the dbt Cloud metadata API.\n\n        Args:\n            query: The GraphQL query to run.\n            variables: The values of any variables defined in the GraphQL query.\n            operation_name: The name of the operation to run if multiple operations\n                are defined in the provided query.\n\n        Returns:\n            The result of the GraphQL query.\n        \"\"\"\n        return self._http_endpoint(\n            query=query, variables=variables, operation_name=operation_name\n        )\n</code></pre>"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudMetadataClient-functions","title":"Functions","text":""},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudMetadataClient.query","title":"<code>query</code>","text":"<p>Run a GraphQL query against the dbt Cloud metadata API.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The GraphQL query to run.</p> required <code>variables</code> <code>Optional[Dict]</code> <p>The values of any variables defined in the GraphQL query.</p> <code>None</code> <code>operation_name</code> <code>Optional[str]</code> <p>The name of the operation to run if multiple operations are defined in the provided query.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The result of the GraphQL query.</p> Source code in <code>prefect_dbt/cloud/clients.py</code> <pre><code>def query(\n    self,\n    query: str,\n    variables: Optional[Dict] = None,\n    operation_name: Optional[str] = None,\n) -&gt; Dict[str, Any]:\n\"\"\"\n    Run a GraphQL query against the dbt Cloud metadata API.\n\n    Args:\n        query: The GraphQL query to run.\n        variables: The values of any variables defined in the GraphQL query.\n        operation_name: The name of the operation to run if multiple operations\n            are defined in the provided query.\n\n    Returns:\n        The result of the GraphQL query.\n    \"\"\"\n    return self._http_endpoint(\n        query=query, variables=variables, operation_name=operation_name\n    )\n</code></pre>"},{"location":"cloud/credentials/","title":"Credentials","text":""},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials","title":"<code>prefect_dbt.cloud.credentials</code>","text":"<p>Module containing credentials for interacting with dbt Cloud</p>"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials-classes","title":"Classes","text":""},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials","title":"<code>DbtCloudCredentials</code>","text":"<p>         Bases: <code>CredentialsBlock</code></p> <p>Credentials block for credential use across dbt Cloud tasks and flows.</p> <p>Attributes:</p> Name Type Description <code>api_key</code> <code>SecretStr</code> <p>API key to authenticate with the dbt Cloud administrative API. Refer to the Authentication docs for retrieving the API key.</p> <code>account_id</code> <code>int</code> <p>ID of dbt Cloud account with which to interact.</p> <code>domain</code> <code>Optional[str]</code> <p>Domain at which the dbt Cloud API is hosted.</p> <p>Examples:</p> <p>Load stored dbt Cloud credentials: <pre><code>from prefect_dbt.cloud import DbtCloudCredentials\n\ndbt_cloud_credentials = DbtCloudCredentials.load(\"BLOCK_NAME\")\n</code></pre></p> <p>Use DbtCloudCredentials instance to trigger a job run: <pre><code>from prefect_dbt.cloud import DbtCloudCredentials\n\ncredentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\nasync with dbt_cloud_credentials.get_administrative_client() as client:\n    client.trigger_job_run(job_id=1)\n</code></pre></p> <p>Load saved dbt Cloud credentials within a flow: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n\n\n@flow\ndef trigger_dbt_cloud_job_run_flow():\n    credentials = DbtCloudCredentials.load(\"my-dbt-credentials\")\n    trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1)\n\ntrigger_dbt_cloud_job_run_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/credentials.py</code> <pre><code>class DbtCloudCredentials(CredentialsBlock):\n\"\"\"\n    Credentials block for credential use across dbt Cloud tasks and flows.\n\n    Attributes:\n        api_key (SecretStr): API key to authenticate with the dbt Cloud\n            administrative API. Refer to the [Authentication docs](\n            https://docs.getdbt.com/dbt-cloud/api-v2#section/Authentication)\n            for retrieving the API key.\n        account_id (int): ID of dbt Cloud account with which to interact.\n        domain (Optional[str]): Domain at which the dbt Cloud API is hosted.\n\n    Examples:\n        Load stored dbt Cloud credentials:\n        ```python\n        from prefect_dbt.cloud import DbtCloudCredentials\n\n        dbt_cloud_credentials = DbtCloudCredentials.load(\"BLOCK_NAME\")\n        ```\n\n        Use DbtCloudCredentials instance to trigger a job run:\n        ```python\n        from prefect_dbt.cloud import DbtCloudCredentials\n\n        credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            client.trigger_job_run(job_id=1)\n        ```\n\n        Load saved dbt Cloud credentials within a flow:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n\n\n        @flow\n        def trigger_dbt_cloud_job_run_flow():\n            credentials = DbtCloudCredentials.load(\"my-dbt-credentials\")\n            trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1)\n\n        trigger_dbt_cloud_job_run_flow()\n        ```\n    \"\"\"\n\n    _block_type_name = \"dbt Cloud Credentials\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-dbt/cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials\"  # noqa\n\n    api_key: SecretStr = Field(\n        default=...,\n        title=\"API Key\",\n        description=\"A dbt Cloud API key to use for authentication.\",\n    )\n    account_id: int = Field(\n        default=..., title=\"Account ID\", description=\"The ID of your dbt Cloud account.\"\n    )\n    domain: str = Field(\n        default=\"cloud.getdbt.com\",\n        description=\"The base domain of your dbt Cloud instance.\",\n    )\n\n    def get_administrative_client(self) -&gt; DbtCloudAdministrativeClient:\n\"\"\"\n        Returns a newly instantiated client for working with the dbt Cloud\n        administrative API.\n\n        Returns:\n            An authenticated dbt Cloud administrative API client.\n        \"\"\"\n        return DbtCloudAdministrativeClient(\n            api_key=self.api_key.get_secret_value(),\n            account_id=self.account_id,\n            domain=self.domain,\n        )\n\n    def get_metadata_client(self) -&gt; DbtCloudMetadataClient:\n\"\"\"\n        Returns a newly instantiated client for working with the dbt Cloud\n        metadata API.\n\n        Example:\n            Sending queries via the returned metadata client:\n            ```python\n            from prefect_dbt import DbtCloudCredentials\n\n            credentials_block = DbtCloudCredentials.load(\"test-account\")\n            metadata_client = credentials_block.get_metadata_client()\n            query = \\\"\\\"\\\"\n            {\n                metrics(jobId: 123) {\n                    uniqueId\n                    name\n                    packageName\n                    tags\n                    label\n                    runId\n                    description\n                    type\n                    sql\n                    timestamp\n                    timeGrains\n                    dimensions\n                    meta\n                    resourceType\n                    filters {\n                        field\n                        operator\n                        value\n                    }\n                    model {\n                        name\n                    }\n                }\n            }\n            \\\"\\\"\\\"\n            metadata_client.query(query)\n            # Result:\n            # {\n            #   \"data\": {\n            #     \"metrics\": [\n            #       {\n            #         \"uniqueId\": \"metric.tpch.total_revenue\",\n            #         \"name\": \"total_revenue\",\n            #         \"packageName\": \"tpch\",\n            #         \"tags\": [],\n            #         \"label\": \"Total Revenue ($)\",\n            #         \"runId\": 108952046,\n            #         \"description\": \"\",\n            #         \"type\": \"sum\",\n            #         \"sql\": \"net_item_sales_amount\",\n            #         \"timestamp\": \"order_date\",\n            #         \"timeGrains\": [\"day\", \"week\", \"month\"],\n            #         \"dimensions\": [\"status_code\", \"priority_code\"],\n            #         \"meta\": {},\n            #         \"resourceType\": \"metric\",\n            #         \"filters\": [],\n            #         \"model\": { \"name\": \"fct_orders\" }\n            #       }\n            #     ]\n            #   }\n            # }\n            ```\n\n        Returns:\n            An authenticated dbt Cloud metadata API client.\n        \"\"\"\n        return DbtCloudMetadataClient(\n            api_key=self.api_key.get_secret_value(),\n            domain=f\"metadata.{self.domain}\",\n        )\n\n    def get_client(\n        self, client_type: Literal[\"administrative\", \"metadata\"]\n    ) -&gt; Union[DbtCloudAdministrativeClient, DbtCloudMetadataClient]:\n\"\"\"\n        Returns a newly instantiated client for working with the dbt Cloud API.\n\n        Args:\n            client_type: Type of client to return. Accepts either 'administrative'\n                or 'metadata'.\n\n        Returns:\n            The authenticated client of the requested type.\n        \"\"\"\n        get_client_method = getattr(self, f\"get_{client_type}_client\", None)\n        if get_client_method is None:\n            raise ValueError(f\"'{client_type}' is not a supported client type.\")\n        return get_client_method()\n</code></pre>"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials-functions","title":"Functions","text":""},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials.get_administrative_client","title":"<code>get_administrative_client</code>","text":"<p>Returns a newly instantiated client for working with the dbt Cloud administrative API.</p> <p>Returns:</p> Type Description <code>DbtCloudAdministrativeClient</code> <p>An authenticated dbt Cloud administrative API client.</p> Source code in <code>prefect_dbt/cloud/credentials.py</code> <pre><code>def get_administrative_client(self) -&gt; DbtCloudAdministrativeClient:\n\"\"\"\n    Returns a newly instantiated client for working with the dbt Cloud\n    administrative API.\n\n    Returns:\n        An authenticated dbt Cloud administrative API client.\n    \"\"\"\n    return DbtCloudAdministrativeClient(\n        api_key=self.api_key.get_secret_value(),\n        account_id=self.account_id,\n        domain=self.domain,\n    )\n</code></pre>"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials.get_client","title":"<code>get_client</code>","text":"<p>Returns a newly instantiated client for working with the dbt Cloud API.</p> <p>Parameters:</p> Name Type Description Default <code>client_type</code> <code>Literal[administrative, metadata]</code> <p>Type of client to return. Accepts either 'administrative' or 'metadata'.</p> required <p>Returns:</p> Type Description <code>Union[DbtCloudAdministrativeClient, DbtCloudMetadataClient]</code> <p>The authenticated client of the requested type.</p> Source code in <code>prefect_dbt/cloud/credentials.py</code> <pre><code>def get_client(\n    self, client_type: Literal[\"administrative\", \"metadata\"]\n) -&gt; Union[DbtCloudAdministrativeClient, DbtCloudMetadataClient]:\n\"\"\"\n    Returns a newly instantiated client for working with the dbt Cloud API.\n\n    Args:\n        client_type: Type of client to return. Accepts either 'administrative'\n            or 'metadata'.\n\n    Returns:\n        The authenticated client of the requested type.\n    \"\"\"\n    get_client_method = getattr(self, f\"get_{client_type}_client\", None)\n    if get_client_method is None:\n        raise ValueError(f\"'{client_type}' is not a supported client type.\")\n    return get_client_method()\n</code></pre>"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials.get_metadata_client","title":"<code>get_metadata_client</code>","text":"<p>Returns a newly instantiated client for working with the dbt Cloud metadata API.</p> Example <p>Sending queries via the returned metadata client: <pre><code>from prefect_dbt import DbtCloudCredentials\n\ncredentials_block = DbtCloudCredentials.load(\"test-account\")\nmetadata_client = credentials_block.get_metadata_client()\nquery = \"\"\"\n{\n    metrics(jobId: 123) {\n        uniqueId\n        name\n        packageName\n        tags\n        label\n        runId\n        description\n        type\n        sql\n        timestamp\n        timeGrains\n        dimensions\n        meta\n        resourceType\n        filters {\n            field\n            operator\n            value\n        }\n        model {\n            name\n        }\n    }\n}\n\"\"\"\nmetadata_client.query(query)\n# Result:\n# {\n#   \"data\": {\n#     \"metrics\": [\n#       {\n#         \"uniqueId\": \"metric.tpch.total_revenue\",\n#         \"name\": \"total_revenue\",\n#         \"packageName\": \"tpch\",\n#         \"tags\": [],\n#         \"label\": \"Total Revenue ($)\",\n#         \"runId\": 108952046,\n#         \"description\": \"\",\n#         \"type\": \"sum\",\n#         \"sql\": \"net_item_sales_amount\",\n#         \"timestamp\": \"order_date\",\n#         \"timeGrains\": [\"day\", \"week\", \"month\"],\n#         \"dimensions\": [\"status_code\", \"priority_code\"],\n#         \"meta\": {},\n#         \"resourceType\": \"metric\",\n#         \"filters\": [],\n#         \"model\": { \"name\": \"fct_orders\" }\n#       }\n#     ]\n#   }\n# }\n</code></pre></p> <p>Returns:</p> Type Description <code>DbtCloudMetadataClient</code> <p>An authenticated dbt Cloud metadata API client.</p> Source code in <code>prefect_dbt/cloud/credentials.py</code> <pre><code>def get_metadata_client(self) -&gt; DbtCloudMetadataClient:\n\"\"\"\n    Returns a newly instantiated client for working with the dbt Cloud\n    metadata API.\n\n    Example:\n        Sending queries via the returned metadata client:\n        ```python\n        from prefect_dbt import DbtCloudCredentials\n\n        credentials_block = DbtCloudCredentials.load(\"test-account\")\n        metadata_client = credentials_block.get_metadata_client()\n        query = \\\"\\\"\\\"\n        {\n            metrics(jobId: 123) {\n                uniqueId\n                name\n                packageName\n                tags\n                label\n                runId\n                description\n                type\n                sql\n                timestamp\n                timeGrains\n                dimensions\n                meta\n                resourceType\n                filters {\n                    field\n                    operator\n                    value\n                }\n                model {\n                    name\n                }\n            }\n        }\n        \\\"\\\"\\\"\n        metadata_client.query(query)\n        # Result:\n        # {\n        #   \"data\": {\n        #     \"metrics\": [\n        #       {\n        #         \"uniqueId\": \"metric.tpch.total_revenue\",\n        #         \"name\": \"total_revenue\",\n        #         \"packageName\": \"tpch\",\n        #         \"tags\": [],\n        #         \"label\": \"Total Revenue ($)\",\n        #         \"runId\": 108952046,\n        #         \"description\": \"\",\n        #         \"type\": \"sum\",\n        #         \"sql\": \"net_item_sales_amount\",\n        #         \"timestamp\": \"order_date\",\n        #         \"timeGrains\": [\"day\", \"week\", \"month\"],\n        #         \"dimensions\": [\"status_code\", \"priority_code\"],\n        #         \"meta\": {},\n        #         \"resourceType\": \"metric\",\n        #         \"filters\": [],\n        #         \"model\": { \"name\": \"fct_orders\" }\n        #       }\n        #     ]\n        #   }\n        # }\n        ```\n\n    Returns:\n        An authenticated dbt Cloud metadata API client.\n    \"\"\"\n    return DbtCloudMetadataClient(\n        api_key=self.api_key.get_secret_value(),\n        domain=f\"metadata.{self.domain}\",\n    )\n</code></pre>"},{"location":"cloud/jobs/","title":"Jobs","text":""},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs","title":"<code>prefect_dbt.cloud.jobs</code>","text":"<p>Module containing tasks and flows for interacting with dbt Cloud jobs</p>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs-classes","title":"Classes","text":""},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudGetJobFailed","title":"<code>DbtCloudGetJobFailed</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raised when unable to retrieve dbt Cloud job.</p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>class DbtCloudGetJobFailed(Exception):\n\"\"\"Raised when unable to retrieve dbt Cloud job.\"\"\"\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJobRunTriggerFailed","title":"<code>DbtCloudJobRunTriggerFailed</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raised when a dbt Cloud job trigger fails.</p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>class DbtCloudJobRunTriggerFailed(Exception):\n\"\"\"Raised when a dbt Cloud job trigger fails.\"\"\"\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs-functions","title":"Functions","text":""},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.get_dbt_cloud_job_info","title":"<code>get_dbt_cloud_job_info</code>  <code>async</code>","text":"<p>A task to retrieve information about a dbt Cloud job.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>job_id</code> <code>int</code> <p>The ID of the job to get.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>The job data returned by the dbt Cloud administrative API.</p> Example <p>Get status of a dbt Cloud job: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import get_job\n\n@flow\ndef get_job_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    return get_job(\n        dbt_cloud_credentials=credentials,\n        job_id=42\n    )\n\nget_job_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@task(\n    name=\"Get dbt Cloud job details\",\n    description=\"Retrieves details of a dbt Cloud job \"\n    \"for the job with the given job_id.\",\n    retries=3,\n    retry_delay_seconds=10,\n)\nasync def get_dbt_cloud_job_info(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    job_id: int,\n    order_by: Optional[str] = None,\n) -&gt; Dict:\n\"\"\"\n    A task to retrieve information about a dbt Cloud job.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        job_id: The ID of the job to get.\n\n    Returns:\n        The job data returned by the dbt Cloud administrative API.\n\n    Example:\n        Get status of a dbt Cloud job:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import get_job\n\n        @flow\n        def get_job_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            return get_job(\n                dbt_cloud_credentials=credentials,\n                job_id=42\n            )\n\n        get_job_flow()\n        ```\n    \"\"\"  # noqa\n    try:\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.get_job(\n                job_id=job_id,\n                order_by=order_by,\n            )\n    except HTTPStatusError as ex:\n        raise DbtCloudGetJobFailed(extract_user_message(ex)) from ex\n    return response.json()[\"data\"]\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.get_run_id","title":"<code>get_run_id</code>","text":"<p>Task that extracts the run ID from a trigger job run API response,</p> <p>This task is mainly used to maintain dependency tracking between the <code>trigger_dbt_cloud_job_run</code> task and downstream tasks/flows that use the run ID.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Dict</code> <p>The JSON body from the trigger job run response.</p> required Example <pre><code>from prefect import flow\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run, get_run_id\n\n\n@flow\ndef trigger_run_and_get_id():\n    dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        )\n\n    triggered_run_data = trigger_dbt_cloud_job_run(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        job_id=job_id,\n        options=trigger_job_run_options,\n    )\n    run_id = get_run_id.submit(triggered_run_data)\n    return run_id\n\ntrigger_run_and_get_id()\n</code></pre> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@task(\n    name=\"Get dbt Cloud job run ID\",\n    description=\"Extracts the run ID from a trigger job run API response\",\n)\ndef get_run_id(obj: Dict):\n\"\"\"\n    Task that extracts the run ID from a trigger job run API response,\n\n    This task is mainly used to maintain dependency tracking between the\n    `trigger_dbt_cloud_job_run` task and downstream tasks/flows that use the run ID.\n\n    Args:\n        obj: The JSON body from the trigger job run response.\n\n    Example:\n        ```python\n        from prefect import flow\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run, get_run_id\n\n\n        @flow\n        def trigger_run_and_get_id():\n            dbt_cloud_credentials=DbtCloudCredentials(\n                    api_key=\"my_api_key\",\n                    account_id=123456789\n                )\n\n            triggered_run_data = trigger_dbt_cloud_job_run(\n                dbt_cloud_credentials=dbt_cloud_credentials,\n                job_id=job_id,\n                options=trigger_job_run_options,\n            )\n            run_id = get_run_id.submit(triggered_run_data)\n            return run_id\n\n        trigger_run_and_get_id()\n        ```\n    \"\"\"\n    id = obj.get(\"id\")\n    if id is None:\n        raise RuntimeError(\"Unable to determine run ID for triggered job.\")\n    return id\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.retry_dbt_cloud_job_run_subset_and_wait_for_completion","title":"<code>retry_dbt_cloud_job_run_subset_and_wait_for_completion</code>  <code>async</code>","text":"<p>Flow that retrys a subset of dbt Cloud job run, filtered by select statuses, and waits for the triggered retry to complete.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>trigger_job_run_options</code> <code>Optional[TriggerJobRunOptions]</code> <p>An optional TriggerJobRunOptions instance to specify overrides for the triggered job run.</p> <code>None</code> <code>max_wait_seconds</code> <code>int</code> <p>Maximum number of seconds to wait for job to complete</p> <code>900</code> <code>poll_frequency_seconds</code> <code>int</code> <p>Number of seconds to wait in between checks for run completion.</p> <code>10</code> <code>run_id</code> <code>int</code> <p>The ID of the job run to retry.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>trigger_job_run_options.steps_override</code> is set by the user.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>The run data returned by the dbt Cloud administrative API.</p> <p>Examples:</p> <p>Retry a subset of models in a dbt Cloud job run and wait for completion: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import retry_dbt_cloud_job_run_subset_and_wait_for_completion\n\n@flow\ndef retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow():\n    credentials = DbtCloudCredentials.load(\"MY_BLOCK_NAME\")\n    retry_dbt_cloud_job_run_subset_and_wait_for_completion(\n        dbt_cloud_credentials=credentials,\n        run_id=88640123,\n    )\n\nretry_dbt_cloud_job_run_subset_and_wait_for_completion_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@flow(\n    name=\"Retry subset of dbt Cloud job run and wait for completion\",\n    description=(\n        \"Retries a subset of dbt Cloud job run, filtered by select statuses, \"\n        \"and waits for the triggered retry to complete.\"\n    ),\n)\nasync def retry_dbt_cloud_job_run_subset_and_wait_for_completion(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    run_id: int,\n    trigger_job_run_options: Optional[TriggerJobRunOptions] = None,\n    max_wait_seconds: int = 900,\n    poll_frequency_seconds: int = 10,\n) -&gt; Dict:\n\"\"\"\n    Flow that retrys a subset of dbt Cloud job run, filtered by select statuses,\n    and waits for the triggered retry to complete.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        trigger_job_run_options: An optional TriggerJobRunOptions instance to\n            specify overrides for the triggered job run.\n        max_wait_seconds: Maximum number of seconds to wait for job to complete\n        poll_frequency_seconds: Number of seconds to wait in between checks for\n            run completion.\n        run_id: The ID of the job run to retry.\n\n    Raises:\n        ValueError: If `trigger_job_run_options.steps_override` is set by the user.\n\n    Returns:\n        The run data returned by the dbt Cloud administrative API.\n\n    Examples:\n        Retry a subset of models in a dbt Cloud job run and wait for completion:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import retry_dbt_cloud_job_run_subset_and_wait_for_completion\n\n        @flow\n        def retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow():\n            credentials = DbtCloudCredentials.load(\"MY_BLOCK_NAME\")\n            retry_dbt_cloud_job_run_subset_and_wait_for_completion(\n                dbt_cloud_credentials=credentials,\n                run_id=88640123,\n            )\n\n        retry_dbt_cloud_job_run_subset_and_wait_for_completion_flow()\n        ```\n    \"\"\"  # noqa\n    if trigger_job_run_options and trigger_job_run_options.steps_override is not None:\n        raise ValueError(\n            \"Do not set `steps_override` in `trigger_job_run_options` \"\n            \"because this flow will automatically set it\"\n        )\n\n    run_info_future = await get_dbt_cloud_run_info.submit(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        run_id=run_id,\n        include_related=[\"run_steps\"],\n    )\n    run_info = await run_info_future.result()\n\n    job_id = run_info[\"job_id\"]\n    job_info_future = await get_dbt_cloud_job_info.submit(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        job_id=job_id,\n    )\n    job_info = await job_info_future.result()\n\n    trigger_job_run_options_override = await _build_trigger_job_run_options(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        trigger_job_run_options=trigger_job_run_options,\n        run_id=run_id,\n        run_info=run_info,\n        job_info=job_info,\n    )\n\n    # to circumvent `RuntimeError: The task runner is already started!`\n    flow_run_context = FlowRunContext.get()\n    task_runner_type = type(flow_run_context.task_runner)\n\n    run_data = await trigger_dbt_cloud_job_run_and_wait_for_completion.with_options(\n        task_runner=task_runner_type()\n    )(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        job_id=job_id,\n        retry_filtered_models_attempts=0,\n        trigger_job_run_options=trigger_job_run_options_override,\n        max_wait_seconds=max_wait_seconds,\n        poll_frequency_seconds=poll_frequency_seconds,\n    )\n    return run_data\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.trigger_dbt_cloud_job_run","title":"<code>trigger_dbt_cloud_job_run</code>  <code>async</code>","text":"<p>A task to trigger a dbt Cloud job run.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>job_id</code> <code>int</code> <p>The ID of the job to trigger.</p> required <code>options</code> <code>Optional[TriggerJobRunOptions]</code> <p>An optional TriggerJobRunOptions instance to specify overrides for the triggered job run.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict</code> <p>The run data returned from the dbt Cloud administrative API.</p> <p>Examples:</p> <p>Trigger a dbt Cloud job run: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n\n\n@flow\ndef trigger_dbt_cloud_job_run_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1)\n\n\ntrigger_dbt_cloud_job_run_flow()\n</code></pre></p> <p>Trigger a dbt Cloud job run with overrides: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\nfrom prefect_dbt.cloud.models import TriggerJobRunOptions\n\n\n@flow\ndef trigger_dbt_cloud_job_run_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    trigger_dbt_cloud_job_run(\n        dbt_cloud_credentials=credentials,\n        job_id=1,\n        options=TriggerJobRunOptions(\n            git_branch=\"staging\",\n            schema_override=\"dbt_cloud_pr_123\",\n            dbt_version_override=\"0.18.0\",\n            target_name_override=\"staging\",\n            timeout_seconds_override=3000,\n            generate_docs_override=True,\n            threads_override=8,\n            steps_override=[\n                \"dbt seed\",\n                \"dbt run --fail-fast\",\n                \"dbt test --fail fast\",\n            ],\n        ),\n    )\n\n\ntrigger_dbt_cloud_job_run()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@task(\n    name=\"Trigger dbt Cloud job run\",\n    description=\"Triggers a dbt Cloud job run for the job \"\n    \"with the given job_id and optional overrides.\",\n    retries=3,\n    retry_delay_seconds=10,\n)\nasync def trigger_dbt_cloud_job_run(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    job_id: int,\n    options: Optional[TriggerJobRunOptions] = None,\n) -&gt; Dict:\n\"\"\"\n    A task to trigger a dbt Cloud job run.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        job_id: The ID of the job to trigger.\n        options: An optional TriggerJobRunOptions instance to specify overrides\n            for the triggered job run.\n\n    Returns:\n        The run data returned from the dbt Cloud administrative API.\n\n    Examples:\n        Trigger a dbt Cloud job run:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n\n\n        @flow\n        def trigger_dbt_cloud_job_run_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1)\n\n\n        trigger_dbt_cloud_job_run_flow()\n        ```\n\n        Trigger a dbt Cloud job run with overrides:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run\n        from prefect_dbt.cloud.models import TriggerJobRunOptions\n\n\n        @flow\n        def trigger_dbt_cloud_job_run_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            trigger_dbt_cloud_job_run(\n                dbt_cloud_credentials=credentials,\n                job_id=1,\n                options=TriggerJobRunOptions(\n                    git_branch=\"staging\",\n                    schema_override=\"dbt_cloud_pr_123\",\n                    dbt_version_override=\"0.18.0\",\n                    target_name_override=\"staging\",\n                    timeout_seconds_override=3000,\n                    generate_docs_override=True,\n                    threads_override=8,\n                    steps_override=[\n                        \"dbt seed\",\n                        \"dbt run --fail-fast\",\n                        \"dbt test --fail fast\",\n                    ],\n                ),\n            )\n\n\n        trigger_dbt_cloud_job_run()\n        ```\n    \"\"\"  # noqa\n    logger = get_run_logger()\n\n    logger.info(f\"Triggering run for job with ID {job_id}\")\n\n    try:\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.trigger_job_run(job_id=job_id, options=options)\n    except HTTPStatusError as ex:\n        raise DbtCloudJobRunTriggerFailed(extract_user_message(ex)) from ex\n\n    run_data = response.json()[\"data\"]\n\n    if \"project_id\" in run_data and \"id\" in run_data:\n        logger.info(\n            f\"Run successfully triggered for job with ID {job_id}. \"\n            \"You can view the status of this run at \"\n            f\"https://{dbt_cloud_credentials.domain}/#/accounts/\"\n            f\"{dbt_cloud_credentials.account_id}/projects/{run_data['project_id']}/\"\n            f\"runs/{run_data['id']}/\"\n        )\n\n    return run_data\n</code></pre>"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.trigger_dbt_cloud_job_run_and_wait_for_completion","title":"<code>trigger_dbt_cloud_job_run_and_wait_for_completion</code>  <code>async</code>","text":"<p>Flow that triggers a job run and waits for the triggered run to complete.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>job_id</code> <code>int</code> <p>The ID of the job to trigger.</p> required <code>trigger_job_run_options</code> <code>Optional[TriggerJobRunOptions]</code> <p>An optional TriggerJobRunOptions instance to specify overrides for the triggered job run.</p> <code>None</code> <code>max_wait_seconds</code> <code>int</code> <p>Maximum number of seconds to wait for job to complete</p> <code>900</code> <code>poll_frequency_seconds</code> <code>int</code> <p>Number of seconds to wait in between checks for run completion.</p> <code>10</code> <code>retry_filtered_models_attempts</code> <code>int</code> <p>Number of times to retry models selected by <code>retry_status_filters</code>.</p> <code>3</code> <p>Raises:</p> Type Description <code>DbtCloudJobRunCancelled</code> <p>The triggered dbt Cloud job run was cancelled.</p> <code>DbtCloudJobRunFailed</code> <p>The triggered dbt Cloud job run failed.</p> <code>RuntimeError</code> <p>The triggered dbt Cloud job run ended in an unexpected state.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>The run data returned by the dbt Cloud administrative API.</p> <p>Examples:</p> <p>Trigger a dbt Cloud job and wait for completion as a stand alone flow: <pre><code>import asyncio\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n\nasyncio.run(\n    trigger_dbt_cloud_job_run_and_wait_for_completion(\n        dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        ),\n        job_id=1\n    )\n)\n</code></pre></p> <p>Trigger a dbt Cloud job and wait for completion as a sub-flow: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n\n@flow\ndef my_flow():\n    ...\n    run_result = trigger_dbt_cloud_job_run_and_wait_for_completion(\n        dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        ),\n        job_id=1\n    )\n    ...\n\nmy_flow()\n</code></pre></p> <p>Trigger a dbt Cloud job with overrides: <pre><code>import asyncio\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\nfrom prefect_dbt.cloud.models import TriggerJobRunOptions\n\nasyncio.run(\n    trigger_dbt_cloud_job_run_and_wait_for_completion(\n        dbt_cloud_credentials=DbtCloudCredentials(\n            api_key=\"my_api_key\",\n            account_id=123456789\n        ),\n        job_id=1,\n        trigger_job_run_options=TriggerJobRunOptions(\n            git_branch=\"staging\",\n            schema_override=\"dbt_cloud_pr_123\",\n            dbt_version_override=\"0.18.0\",\n            target_name_override=\"staging\",\n            timeout_seconds_override=3000,\n            generate_docs_override=True,\n            threads_override=8,\n            steps_override=[\n                \"dbt seed\",\n                \"dbt run --fail-fast\",\n                \"dbt test --fail fast\",\n            ],\n        ),\n    )\n)\n</code></pre></p> Source code in <code>prefect_dbt/cloud/jobs.py</code> <pre><code>@flow(\n    name=\"Trigger dbt Cloud job run and wait for completion\",\n    description=\"Triggers a dbt Cloud job run and waits for the\"\n    \"triggered run to complete.\",\n)\nasync def trigger_dbt_cloud_job_run_and_wait_for_completion(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    job_id: int,\n    trigger_job_run_options: Optional[TriggerJobRunOptions] = None,\n    max_wait_seconds: int = 900,\n    poll_frequency_seconds: int = 10,\n    retry_filtered_models_attempts: int = 3,\n) -&gt; Dict:\n\"\"\"\n    Flow that triggers a job run and waits for the triggered run to complete.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        job_id: The ID of the job to trigger.\n        trigger_job_run_options: An optional TriggerJobRunOptions instance to\n            specify overrides for the triggered job run.\n        max_wait_seconds: Maximum number of seconds to wait for job to complete\n        poll_frequency_seconds: Number of seconds to wait in between checks for\n            run completion.\n        retry_filtered_models_attempts: Number of times to retry models selected by `retry_status_filters`.\n\n    Raises:\n        DbtCloudJobRunCancelled: The triggered dbt Cloud job run was cancelled.\n        DbtCloudJobRunFailed: The triggered dbt Cloud job run failed.\n        RuntimeError: The triggered dbt Cloud job run ended in an unexpected state.\n\n    Returns:\n        The run data returned by the dbt Cloud administrative API.\n\n    Examples:\n        Trigger a dbt Cloud job and wait for completion as a stand alone flow:\n        ```python\n        import asyncio\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n\n        asyncio.run(\n            trigger_dbt_cloud_job_run_and_wait_for_completion(\n                dbt_cloud_credentials=DbtCloudCredentials(\n                    api_key=\"my_api_key\",\n                    account_id=123456789\n                ),\n                job_id=1\n            )\n        )\n        ```\n\n        Trigger a dbt Cloud job and wait for completion as a sub-flow:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n\n        @flow\n        def my_flow():\n            ...\n            run_result = trigger_dbt_cloud_job_run_and_wait_for_completion(\n                dbt_cloud_credentials=DbtCloudCredentials(\n                    api_key=\"my_api_key\",\n                    account_id=123456789\n                ),\n                job_id=1\n            )\n            ...\n\n        my_flow()\n        ```\n\n        Trigger a dbt Cloud job with overrides:\n        ```python\n        import asyncio\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion\n        from prefect_dbt.cloud.models import TriggerJobRunOptions\n\n        asyncio.run(\n            trigger_dbt_cloud_job_run_and_wait_for_completion(\n                dbt_cloud_credentials=DbtCloudCredentials(\n                    api_key=\"my_api_key\",\n                    account_id=123456789\n                ),\n                job_id=1,\n                trigger_job_run_options=TriggerJobRunOptions(\n                    git_branch=\"staging\",\n                    schema_override=\"dbt_cloud_pr_123\",\n                    dbt_version_override=\"0.18.0\",\n                    target_name_override=\"staging\",\n                    timeout_seconds_override=3000,\n                    generate_docs_override=True,\n                    threads_override=8,\n                    steps_override=[\n                        \"dbt seed\",\n                        \"dbt run --fail-fast\",\n                        \"dbt test --fail fast\",\n                    ],\n                ),\n            )\n        )\n        ```\n\n    \"\"\"  # noqa\n    logger = get_run_logger()\n\n    triggered_run_data_future = await trigger_dbt_cloud_job_run.submit(\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        job_id=job_id,\n        options=trigger_job_run_options,\n    )\n    run_id = (await triggered_run_data_future.result()).get(\"id\")\n    if run_id is None:\n        raise RuntimeError(\"Unable to determine run ID for triggered job.\")\n\n    final_run_status, run_data = await wait_for_dbt_cloud_job_run(\n        run_id=run_id,\n        dbt_cloud_credentials=dbt_cloud_credentials,\n        max_wait_seconds=max_wait_seconds,\n        poll_frequency_seconds=poll_frequency_seconds,\n    )\n\n    if final_run_status == DbtCloudJobRunStatus.SUCCESS:\n        try:\n            list_run_artifacts_future = await list_dbt_cloud_run_artifacts.submit(\n                dbt_cloud_credentials=dbt_cloud_credentials,\n                run_id=run_id,\n            )\n            run_data[\"artifact_paths\"] = await list_run_artifacts_future.result()\n        except DbtCloudListRunArtifactsFailed as ex:\n            logger.warning(\n                \"Unable to retrieve artifacts for job run with ID %s. Reason: %s\",\n                run_id,\n                ex,\n            )\n        logger.info(\n            \"dbt Cloud job run with ID %s completed successfully!\",\n            run_id,\n        )\n        return run_data\n    elif final_run_status == DbtCloudJobRunStatus.CANCELLED:\n        raise DbtCloudJobRunCancelled(\n            f\"Triggered job run with ID {run_id} was cancelled.\"\n        )\n    elif final_run_status == DbtCloudJobRunStatus.FAILED:\n        while retry_filtered_models_attempts &gt; 0:\n            logger.info(\n                f\"Retrying job run with ID: {run_id} \"\n                f\"{retry_filtered_models_attempts} more times\"\n            )\n            try:\n                retry_filtered_models_attempts -= 1\n                run_data = await (\n                    retry_dbt_cloud_job_run_subset_and_wait_for_completion(\n                        dbt_cloud_credentials=dbt_cloud_credentials,\n                        run_id=run_id,\n                        trigger_job_run_options=trigger_job_run_options,\n                        max_wait_seconds=max_wait_seconds,\n                        poll_frequency_seconds=poll_frequency_seconds,\n                    )\n                )\n                return run_data\n            except Exception:\n                pass\n        else:\n            raise DbtCloudJobRunFailed(f\"Triggered job run with ID: {run_id} failed.\")\n    else:\n        raise RuntimeError(\n            f\"Triggered job run with ID: {run_id} ended with unexpected\"\n            f\"status {final_run_status.value}.\"\n        )\n</code></pre>"},{"location":"cloud/models/","title":"Models","text":""},{"location":"cloud/models/#prefect_dbt.cloud.models","title":"<code>prefect_dbt.cloud.models</code>","text":"<p>Module containing models used for passing data to dbt Cloud</p>"},{"location":"cloud/models/#prefect_dbt.cloud.models-classes","title":"Classes","text":""},{"location":"cloud/models/#prefect_dbt.cloud.models.TriggerJobRunOptions","title":"<code>TriggerJobRunOptions</code>","text":"<p>         Bases: <code>BaseModel</code></p> <p>Defines options that can be defined when triggering a dbt Cloud job run.</p> Source code in <code>prefect_dbt/cloud/models.py</code> <pre><code>class TriggerJobRunOptions(BaseModel):\n\"\"\"\n    Defines options that can be defined when triggering a dbt Cloud job run.\n    \"\"\"\n\n    cause: str = Field(\n        default_factory=default_cause_factory,\n        description=\"A text description of the reason for running this job.\",\n    )\n    git_sha: Optional[str] = Field(\n        default=None, description=\"The git sha to check out before running this job.\"\n    )\n    git_branch: Optional[str] = Field(\n        default=None, description=\"The git branch to check out before running this job.\"\n    )\n    schema_override: Optional[str] = Field(\n        default=None,\n        description=\"Override the destination schema in the configured \"\n        \"target for this job.\",\n    )\n    dbt_version_override: Optional[str] = Field(\n        default=None, description=\"Override the version of dbt used to run this job.\"\n    )\n    threads_override: Optional[int] = Field(\n        default=None, description=\"Override the number of threads used to run this job.\"\n    )\n    target_name_override: Optional[str] = Field(\n        default=None,\n        description=\"Override the target.name context variable used when \"\n        \"running this job\",\n    )\n    generate_docs_override: Optional[bool] = Field(\n        default=None,\n        description=\"Override whether or not this job generates docs \"\n        \"(true=yes, false=no).\",\n    )\n    timeout_seconds_override: Optional[int] = Field(\n        default=None, description=\"Override the timeout in seconds for this job.\"\n    )\n    steps_override: Optional[List[str]] = Field(\n        default=None, description=\"Override the list of steps for this job.\"\n    )\n</code></pre>"},{"location":"cloud/models/#prefect_dbt.cloud.models-functions","title":"Functions","text":""},{"location":"cloud/models/#prefect_dbt.cloud.models.default_cause_factory","title":"<code>default_cause_factory</code>","text":"<p>Factory function to populate the default cause for a job run to include information from the Prefect run context.</p> Source code in <code>prefect_dbt/cloud/models.py</code> <pre><code>def default_cause_factory():\n\"\"\"\n    Factory function to populate the default cause for a job run to include information\n    from the Prefect run context.\n    \"\"\"\n    cause = \"Triggered via Prefect\"\n\n    try:\n        context = get_run_context()\n        if isinstance(context, FlowRunContext):\n            cause = f\"{cause} in flow run {context.flow_run.name}\"\n        elif isinstance(context, TaskRunContext):\n            cause = f\"{cause} in task run {context.task_run.name}\"\n    except RuntimeError:\n        pass\n\n    return cause\n</code></pre>"},{"location":"cloud/runs/","title":"Runs","text":""},{"location":"cloud/runs/#prefect_dbt.cloud.runs","title":"<code>prefect_dbt.cloud.runs</code>","text":"<p>Module containing tasks and flows for interacting with dbt Cloud job runs</p>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs-classes","title":"Classes","text":""},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudGetRunArtifactFailed","title":"<code>DbtCloudGetRunArtifactFailed</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raised when unable to get a dbt Cloud run artifact</p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>class DbtCloudGetRunArtifactFailed(Exception):\n\"\"\"Raised when unable to get a dbt Cloud run artifact\"\"\"\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudGetRunFailed","title":"<code>DbtCloudGetRunFailed</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raised when unable to retrieve dbt Cloud run</p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>class DbtCloudGetRunFailed(Exception):\n\"\"\"Raised when unable to retrieve dbt Cloud run\"\"\"\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunCancelled","title":"<code>DbtCloudJobRunCancelled</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raised when a triggered job run is cancelled</p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>class DbtCloudJobRunCancelled(Exception):\n\"\"\"Raised when a triggered job run is cancelled\"\"\"\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunFailed","title":"<code>DbtCloudJobRunFailed</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raised when a triggered job run fails</p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>class DbtCloudJobRunFailed(Exception):\n\"\"\"Raised when a triggered job run fails\"\"\"\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunStatus","title":"<code>DbtCloudJobRunStatus</code>","text":"<p>         Bases: <code>Enum</code></p> <p>dbt Cloud Job statuses.</p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>class DbtCloudJobRunStatus(Enum):\n\"\"\"dbt Cloud Job statuses.\"\"\"\n\n    QUEUED = 1\n    STARTING = 2\n    RUNNING = 3\n    SUCCESS = 10\n    FAILED = 20\n    CANCELLED = 30\n\n    @classmethod\n    def is_terminal_status_code(cls, status_code: Any) -&gt; bool:\n\"\"\"\n        Returns True if a status code is terminal for a job run.\n        Returns False otherwise.\n        \"\"\"\n        return status_code in [cls.SUCCESS.value, cls.FAILED.value, cls.CANCELLED.value]\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunStatus-functions","title":"Functions","text":""},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunStatus.is_terminal_status_code","title":"<code>is_terminal_status_code</code>  <code>classmethod</code>","text":"<p>Returns True if a status code is terminal for a job run. Returns False otherwise.</p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>@classmethod\ndef is_terminal_status_code(cls, status_code: Any) -&gt; bool:\n\"\"\"\n    Returns True if a status code is terminal for a job run.\n    Returns False otherwise.\n    \"\"\"\n    return status_code in [cls.SUCCESS.value, cls.FAILED.value, cls.CANCELLED.value]\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunTimedOut","title":"<code>DbtCloudJobRunTimedOut</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raised when a triggered job run does not complete in the configured max wait seconds</p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>class DbtCloudJobRunTimedOut(Exception):\n\"\"\"\n    Raised when a triggered job run does not complete in the configured max\n    wait seconds\n    \"\"\"\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudListRunArtifactsFailed","title":"<code>DbtCloudListRunArtifactsFailed</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raised when unable to list dbt Cloud run artifacts</p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>class DbtCloudListRunArtifactsFailed(Exception):\n\"\"\"Raised when unable to list dbt Cloud run artifacts\"\"\"\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs-functions","title":"Functions","text":""},{"location":"cloud/runs/#prefect_dbt.cloud.runs.get_dbt_cloud_run_artifact","title":"<code>get_dbt_cloud_run_artifact</code>  <code>async</code>","text":"<p>A task to get an artifact generated for a completed run. The requested artifact is saved to a file in the current working directory.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>run_id</code> <code>int</code> <p>The ID of the run to list run artifacts for.</p> required <code>path</code> <code>str</code> <p>The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json)</p> required <code>step</code> <code>Optional[int]</code> <p>The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Dict, str]</code> <p>The contents of the requested manifest. Returns a <code>Dict</code> if the requested artifact is a JSON file and a <code>str</code> otherwise.</p> <p>Examples:</p> <p>Get an artifact of a dbt Cloud job run: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact\n\n@flow\ndef get_artifact_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    return get_dbt_cloud_run_artifact(\n        dbt_cloud_credentials=credentials,\n        run_id=42,\n        path=\"manifest.json\"\n    )\n\nget_artifact_flow()\n</code></pre></p> <p>Get an artifact of a dbt Cloud job run and write it to a file: <pre><code>import json\n\nfrom prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact\n\n@flow\ndef get_artifact_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    get_run_artifact_result = get_dbt_cloud_run_artifact(\n        dbt_cloud_credentials=credentials,\n        run_id=42,\n        path=\"manifest.json\"\n    )\n\n    with open(\"manifest.json\", \"w\") as file:\n        json.dump(get_run_artifact_result, file)\n\nget_artifact_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>@task(\n    name=\"Get dbt Cloud job artifact\",\n    description=\"Fetches an artifact from a completed run.\",\n    retries=3,\n    retry_delay_seconds=10,\n)\nasync def get_dbt_cloud_run_artifact(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    run_id: int,\n    path: str,\n    step: Optional[int] = None,\n) -&gt; Union[Dict, str]:\n\"\"\"\n    A task to get an artifact generated for a completed run. The requested artifact\n    is saved to a file in the current working directory.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        run_id: The ID of the run to list run artifacts for.\n        path: The relative path to the run artifact (e.g. manifest.json, catalog.json,\n            run_results.json)\n        step: The index of the step in the run to query for artifacts. The\n            first step in the run has the index 1. If the step parameter is\n            omitted, then this method will return the artifacts compiled\n            for the last step in the run.\n\n    Returns:\n        The contents of the requested manifest. Returns a `Dict` if the\n            requested artifact is a JSON file and a `str` otherwise.\n\n    Examples:\n        Get an artifact of a dbt Cloud job run:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact\n\n        @flow\n        def get_artifact_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            return get_dbt_cloud_run_artifact(\n                dbt_cloud_credentials=credentials,\n                run_id=42,\n                path=\"manifest.json\"\n            )\n\n        get_artifact_flow()\n        ```\n\n        Get an artifact of a dbt Cloud job run and write it to a file:\n        ```python\n        import json\n\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact\n\n        @flow\n        def get_artifact_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            get_run_artifact_result = get_dbt_cloud_run_artifact(\n                dbt_cloud_credentials=credentials,\n                run_id=42,\n                path=\"manifest.json\"\n            )\n\n            with open(\"manifest.json\", \"w\") as file:\n                json.dump(get_run_artifact_result, file)\n\n        get_artifact_flow()\n        ```\n    \"\"\"  # noqa\n\n    try:\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.get_run_artifact(\n                run_id=run_id, path=path, step=step\n            )\n    except HTTPStatusError as ex:\n        raise DbtCloudGetRunArtifactFailed(extract_user_message(ex)) from ex\n\n    if path.endswith(\".json\"):\n        artifact_contents = response.json()\n    else:\n        artifact_contents = response.text\n\n    return artifact_contents\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.get_dbt_cloud_run_info","title":"<code>get_dbt_cloud_run_info</code>  <code>async</code>","text":"<p>A task to retrieve information about a dbt Cloud job run.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>run_id</code> <code>int</code> <p>The ID of the job to trigger.</p> required <code>include_related</code> <code>Optional[List[Literal[trigger, job, debug_logs, run_steps]]]</code> <p>List of related fields to pull with the run. Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\". If \"debug_logs\" is not provided in a request, then the included debug logs will be truncated to the last 1,000 lines of the debug log output file.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict</code> <p>The run data returned by the dbt Cloud administrative API.</p> Example <p>Get status of a dbt Cloud job run: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import get_run\n\n@flow\ndef get_run_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    return get_run(\n        dbt_cloud_credentials=credentials,\n        run_id=42\n    )\n\nget_run_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>@task(\n    name=\"Get dbt Cloud job run details\",\n    description=\"Retrieves details of a dbt Cloud job run \"\n    \"for the run with the given run_id.\",\n    retries=3,\n    retry_delay_seconds=10,\n)\nasync def get_dbt_cloud_run_info(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    run_id: int,\n    include_related: Optional[\n        List[Literal[\"trigger\", \"job\", \"debug_logs\", \"run_steps\"]]\n    ] = None,\n) -&gt; Dict:\n\"\"\"\n    A task to retrieve information about a dbt Cloud job run.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        run_id: The ID of the job to trigger.\n        include_related: List of related fields to pull with the run.\n            Valid values are \"trigger\", \"job\", \"debug_logs\", and \"run_steps\".\n            If \"debug_logs\" is not provided in a request, then the included debug\n            logs will be truncated to the last 1,000 lines of the debug log output file.\n\n    Returns:\n        The run data returned by the dbt Cloud administrative API.\n\n    Example:\n        Get status of a dbt Cloud job run:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import get_run\n\n        @flow\n        def get_run_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            return get_run(\n                dbt_cloud_credentials=credentials,\n                run_id=42\n            )\n\n        get_run_flow()\n        ```\n    \"\"\"  # noqa\n    try:\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.get_run(\n                run_id=run_id, include_related=include_related\n            )\n    except HTTPStatusError as ex:\n        raise DbtCloudGetRunFailed(extract_user_message(ex)) from ex\n    return response.json()[\"data\"]\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.list_dbt_cloud_run_artifacts","title":"<code>list_dbt_cloud_run_artifacts</code>  <code>async</code>","text":"<p>A task to list the artifact files generated for a completed run.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>run_id</code> <code>int</code> <p>The ID of the run to list run artifacts for.</p> required <code>step</code> <code>Optional[int]</code> <p>The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of paths to artifact files that can be used to retrieve the generated artifacts.</p> Example <p>List artifacts of a dbt Cloud job run: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts\n\n@flow\ndef list_artifacts_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    return list_dbt_cloud_run_artifacts(\n        dbt_cloud_credentials=credentials,\n        run_id=42\n    )\n\nlist_artifacts_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>@task(\n    name=\"List dbt Cloud job artifacts\",\n    description=\"Fetches a list of artifact files generated for a completed run.\",\n    retries=3,\n    retry_delay_seconds=10,\n)\nasync def list_dbt_cloud_run_artifacts(\n    dbt_cloud_credentials: DbtCloudCredentials, run_id: int, step: Optional[int] = None\n) -&gt; List[str]:\n\"\"\"\n    A task to list the artifact files generated for a completed run.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        run_id: The ID of the run to list run artifacts for.\n        step: The index of the step in the run to query for artifacts. The\n            first step in the run has the index 1. If the step parameter is\n            omitted, then this method will return the artifacts compiled\n            for the last step in the run.\n\n    Returns:\n        A list of paths to artifact files that can be used to retrieve the generated artifacts.\n\n    Example:\n        List artifacts of a dbt Cloud job run:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts\n\n        @flow\n        def list_artifacts_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            return list_dbt_cloud_run_artifacts(\n                dbt_cloud_credentials=credentials,\n                run_id=42\n            )\n\n        list_artifacts_flow()\n        ```\n    \"\"\"  # noqa\n    try:\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.list_run_artifacts(run_id=run_id, step=step)\n    except HTTPStatusError as ex:\n        raise DbtCloudListRunArtifactsFailed(extract_user_message(ex)) from ex\n    return response.json()[\"data\"]\n</code></pre>"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.wait_for_dbt_cloud_job_run","title":"<code>wait_for_dbt_cloud_job_run</code>  <code>async</code>","text":"<p>Waits for the given dbt Cloud job run to finish running.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>int</code> <p>The ID of the run to wait for.</p> required <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>max_wait_seconds</code> <code>int</code> <p>Maximum number of seconds to wait for job to complete</p> <code>900</code> <code>poll_frequency_seconds</code> <code>int</code> <p>Number of seconds to wait in between checks for run completion.</p> <code>10</code> <p>Raises:</p> Type Description <code>DbtCloudJobRunTimedOut</code> <p>When the elapsed wait time exceeds <code>max_wait_seconds</code>.</p> <p>Returns:</p> Name Type Description <code>run_status</code> <code>DbtCloudJobRunStatus</code> <p>An enum representing the final dbt Cloud job run status</p> <code>run_data</code> <code>Dict</code> <p>A dictionary containing information about the run after completion.</p> Source code in <code>prefect_dbt/cloud/runs.py</code> <pre><code>@flow(\n    name=\"Wait for dbt Cloud job run\",\n    description=\"Waits for a dbt Cloud job run to finish running.\",\n)\nasync def wait_for_dbt_cloud_job_run(\n    run_id: int,\n    dbt_cloud_credentials: DbtCloudCredentials,\n    max_wait_seconds: int = 900,\n    poll_frequency_seconds: int = 10,\n) -&gt; Tuple[DbtCloudJobRunStatus, Dict]:\n\"\"\"\n    Waits for the given dbt Cloud job run to finish running.\n\n    Args:\n        run_id: The ID of the run to wait for.\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        max_wait_seconds: Maximum number of seconds to wait for job to complete\n        poll_frequency_seconds: Number of seconds to wait in between checks for\n            run completion.\n\n    Raises:\n        DbtCloudJobRunTimedOut: When the elapsed wait time exceeds `max_wait_seconds`.\n\n    Returns:\n        run_status: An enum representing the final dbt Cloud job run status\n        run_data: A dictionary containing information about the run after completion.\n\n\n    Example:\n\n\n    \"\"\"\n    logger = get_run_logger()\n    seconds_waited_for_run_completion = 0\n    wait_for = []\n    while seconds_waited_for_run_completion &lt;= max_wait_seconds:\n        run_data_future = await get_dbt_cloud_run_info.submit(\n            dbt_cloud_credentials=dbt_cloud_credentials,\n            run_id=run_id,\n            wait_for=wait_for,\n        )\n        run_data = await run_data_future.result()\n        run_status_code = run_data.get(\"status\")\n\n        if DbtCloudJobRunStatus.is_terminal_status_code(run_status_code):\n            return DbtCloudJobRunStatus(run_status_code), run_data\n\n        wait_for = [run_data_future]\n        logger.debug(\n            \"dbt Cloud job run with ID %i has status %s. Waiting for %i seconds.\",\n            run_id,\n            DbtCloudJobRunStatus(run_status_code).name,\n            poll_frequency_seconds,\n        )\n        await asyncio.sleep(poll_frequency_seconds)\n        seconds_waited_for_run_completion += poll_frequency_seconds\n\n    raise DbtCloudJobRunTimedOut(\n        f\"Max wait time of {max_wait_seconds} seconds exceeded while waiting \"\n        \"for job run with ID {run_id}\"\n    )\n</code></pre>"},{"location":"cloud/utils/","title":"Utils","text":""},{"location":"cloud/utils/#prefect_dbt.cloud.utils","title":"<code>prefect_dbt.cloud.utils</code>","text":"<p>Utilities for common interactions with the dbt Cloud API</p>"},{"location":"cloud/utils/#prefect_dbt.cloud.utils-classes","title":"Classes","text":""},{"location":"cloud/utils/#prefect_dbt.cloud.utils.DbtCloudAdministrativeApiCallFailed","title":"<code>DbtCloudAdministrativeApiCallFailed</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raised when a call to dbt Cloud administrative API fails.</p> Source code in <code>prefect_dbt/cloud/utils.py</code> <pre><code>class DbtCloudAdministrativeApiCallFailed(Exception):\n\"\"\"Raised when a call to dbt Cloud administrative API fails.\"\"\"\n</code></pre>"},{"location":"cloud/utils/#prefect_dbt.cloud.utils-functions","title":"Functions","text":""},{"location":"cloud/utils/#prefect_dbt.cloud.utils.call_dbt_cloud_administrative_api_endpoint","title":"<code>call_dbt_cloud_administrative_api_endpoint</code>  <code>async</code>","text":"<p>Task that calls a specified endpoint in the dbt Cloud administrative API. Use this task if a prebuilt one is not yet available.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_cloud_credentials</code> <code>DbtCloudCredentials</code> <p>Credentials for authenticating with dbt Cloud.</p> required <code>path</code> <code>str</code> <p>The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration.</p> required <code>http_method</code> <code>str</code> <p>HTTP method to call on the endpoint.</p> required <code>params</code> <code>Optional[Dict[str, Any]]</code> <p>Query parameters to include in the request.</p> <code>None</code> <code>json</code> <code>Optional[Dict[str, Any]]</code> <p>JSON serializable body to send in the request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The body of the response. If the body is JSON serializable, then the result of <code>json.loads</code> with the body as the input will be returned. Otherwise, the body will be returned directly.</p> <p>Examples:</p> <p>List projects for an account: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint\n\n@flow\ndef get_projects_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    result = call_dbt_cloud_administrative_api_endpoint(\n        dbt_cloud_credentials=credentials,\n        path=\"/projects/\",\n        http_method=\"GET\",\n    )\n    return result[\"data\"]\n\nget_projects_flow()\n</code></pre></p> <p>Create a new job: <pre><code>from prefect import flow\n\nfrom prefect_dbt.cloud import DbtCloudCredentials\nfrom prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint\n\n\n@flow\ndef create_job_flow():\n    credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n    result = call_dbt_cloud_administrative_api_endpoint(\n        dbt_cloud_credentials=credentials,\n        path=\"/jobs/\",\n        http_method=\"POST\",\n        json={\n            \"id\": None,\n            \"account_id\": 123456789,\n            \"project_id\": 100,\n            \"environment_id\": 10,\n            \"name\": \"Nightly run\",\n            \"dbt_version\": None,\n            \"triggers\": {\"github_webhook\": True, \"schedule\": True},\n            \"execute_steps\": [\"dbt run\", \"dbt test\", \"dbt source snapshot-freshness\"],\n            \"settings\": {\"threads\": 4, \"target_name\": \"prod\"},\n            \"state\": 1,\n            \"schedule\": {\n                \"date\": {\"type\": \"every_day\"},\n                \"time\": {\"type\": \"every_hour\", \"interval\": 1},\n            },\n        },\n    )\n    return result[\"data\"]\n\ncreate_job_flow()\n</code></pre></p> Source code in <code>prefect_dbt/cloud/utils.py</code> <pre><code>@task(\n    name=\"Call dbt Cloud administrative API endpoint\",\n    description=\"Calls a dbt Cloud administrative API endpoint\",\n    retries=3,\n    retry_delay_seconds=10,\n)\nasync def call_dbt_cloud_administrative_api_endpoint(\n    dbt_cloud_credentials: DbtCloudCredentials,\n    path: str,\n    http_method: str,\n    params: Optional[Dict[str, Any]] = None,\n    json: Optional[Dict[str, Any]] = None,\n) -&gt; Any:\n\"\"\"\n    Task that calls a specified endpoint in the dbt Cloud administrative API. Use this\n    task if a prebuilt one is not yet available.\n\n    Args:\n        dbt_cloud_credentials: Credentials for authenticating with dbt Cloud.\n        path: The partial path for the request (e.g. /projects/). Will be appended\n            onto the base URL as determined by the client configuration.\n        http_method: HTTP method to call on the endpoint.\n        params: Query parameters to include in the request.\n        json: JSON serializable body to send in the request.\n\n    Returns:\n        The body of the response. If the body is JSON serializable, then the result of\n            `json.loads` with the body as the input will be returned. Otherwise, the\n            body will be returned directly.\n\n    Examples:\n        List projects for an account:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint\n\n        @flow\n        def get_projects_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            result = call_dbt_cloud_administrative_api_endpoint(\n                dbt_cloud_credentials=credentials,\n                path=\"/projects/\",\n                http_method=\"GET\",\n            )\n            return result[\"data\"]\n\n        get_projects_flow()\n        ```\n\n        Create a new job:\n        ```python\n        from prefect import flow\n\n        from prefect_dbt.cloud import DbtCloudCredentials\n        from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint\n\n\n        @flow\n        def create_job_flow():\n            credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789)\n\n            result = call_dbt_cloud_administrative_api_endpoint(\n                dbt_cloud_credentials=credentials,\n                path=\"/jobs/\",\n                http_method=\"POST\",\n                json={\n                    \"id\": None,\n                    \"account_id\": 123456789,\n                    \"project_id\": 100,\n                    \"environment_id\": 10,\n                    \"name\": \"Nightly run\",\n                    \"dbt_version\": None,\n                    \"triggers\": {\"github_webhook\": True, \"schedule\": True},\n                    \"execute_steps\": [\"dbt run\", \"dbt test\", \"dbt source snapshot-freshness\"],\n                    \"settings\": {\"threads\": 4, \"target_name\": \"prod\"},\n                    \"state\": 1,\n                    \"schedule\": {\n                        \"date\": {\"type\": \"every_day\"},\n                        \"time\": {\"type\": \"every_hour\", \"interval\": 1},\n                    },\n                },\n            )\n            return result[\"data\"]\n\n        create_job_flow()\n        ```\n    \"\"\"  # noqa\n    try:\n\n        async with dbt_cloud_credentials.get_administrative_client() as client:\n            response = await client.call_endpoint(\n                http_method=http_method, path=path, params=params, json=json\n            )\n    except HTTPStatusError as ex:\n        raise DbtCloudAdministrativeApiCallFailed(extract_developer_message(ex)) from ex\n    try:\n        return response.json()\n    except JSONDecodeError:\n        return response.text\n</code></pre>"},{"location":"cloud/utils/#prefect_dbt.cloud.utils.extract_developer_message","title":"<code>extract_developer_message</code>","text":"<p>Extracts developer message from a error response from the dbt Cloud administrative API.</p> <p>Parameters:</p> Name Type Description Default <code>ex</code> <code>HTTPStatusError</code> <p>An HTTPStatusError raised by httpx</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>developer_message from dbt Cloud administrative API response or None if a</p> <code>Optional[str]</code> <p>developer_message cannot be extracted</p> Source code in <code>prefect_dbt/cloud/utils.py</code> <pre><code>def extract_developer_message(ex: HTTPStatusError) -&gt; Optional[str]:\n\"\"\"\n    Extracts developer message from a error response from the dbt Cloud\n    administrative API.\n\n    Args:\n        ex: An HTTPStatusError raised by httpx\n\n    Returns:\n        developer_message from dbt Cloud administrative API response or None if a\n        developer_message cannot be extracted\n    \"\"\"\n    response_payload = ex.response.json()\n    status = response_payload.get(\"status\", {})\n    return status.get(\"developer_message\")\n</code></pre>"},{"location":"cloud/utils/#prefect_dbt.cloud.utils.extract_user_message","title":"<code>extract_user_message</code>","text":"<p>Extracts user message from a error response from the dbt Cloud administrative API.</p> <p>Parameters:</p> Name Type Description Default <code>ex</code> <code>HTTPStatusError</code> <p>An HTTPStatusError raised by httpx</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>user_message from dbt Cloud administrative API response or None if a</p> <code>Optional[str]</code> <p>user_message cannot be extracted</p> Source code in <code>prefect_dbt/cloud/utils.py</code> <pre><code>def extract_user_message(ex: HTTPStatusError) -&gt; Optional[str]:\n\"\"\"\n    Extracts user message from a error response from the dbt Cloud administrative API.\n\n    Args:\n        ex: An HTTPStatusError raised by httpx\n\n    Returns:\n        user_message from dbt Cloud administrative API response or None if a\n        user_message cannot be extracted\n    \"\"\"\n    response_payload = ex.response.json()\n    status = response_payload.get(\"status\", {})\n    return status.get(\"user_message\")\n</code></pre>"}]}