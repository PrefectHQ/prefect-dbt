{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"prefect-dbt Welcome! prefect-dbt is a collection of Prefect integrations for working with dbt with your Prefect flows. Getting Started Python setup Requires an installation of Python 3.7+. We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv. These tasks are designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the Prefect documentation . Installation Install prefect-dbt with pip : pip install prefect-dbt Trigger a dbt Cloud job and wait for completion from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion @flow def run_dbt_job_flow (): run_result = trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 ) run_dbt_job_flow () Execute a dbt CLI command from prefect import flow from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_command_flow () -> str : result = trigger_dbt_cli_command ( \"dbt debug\" ) return result # Returns the last line the in CLI output trigger_dbt_cli_command_flow () Execute a dbt CLI command without a pre-populated profiles.yml from prefect import flow from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command from prefect_dbt.cli.configs import SnowflakeTargetConfigs @flow def trigger_dbt_cli_command_flow (): connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ), ) target_configs = SnowflakeTargetConfigs ( connector = connector ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) result = trigger_dbt_cli_command ( \"dbt debug\" , overwrite_profiles = True , dbt_cli_profile = dbt_cli_profile ) return result trigger_dbt_cli_command_flow () Resources If you encounter any bugs while using prefect-dbt , feel free to open an issue in the prefect-dbt repository. If you have any questions or issues while using prefect-dbt , you can find help in either the Prefect Discourse forum or the Prefect Slack community . If you need help getting started with or using dbt, please consult the dbt documentation . Development If you'd like to install a version of prefect-dbt for development, clone the repository and perform an editable install with pip : git clone https://github.com/PrefectHQ/prefect-dbt.git cd prefect-dbt/ pip install -e \".[dev]\" # Install linting pre-commit hooks pre-commit install","title":"Home"},{"location":"#prefect-dbt","text":"","title":"prefect-dbt"},{"location":"#welcome","text":"prefect-dbt is a collection of Prefect integrations for working with dbt with your Prefect flows.","title":"Welcome!"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#python-setup","text":"Requires an installation of Python 3.7+. We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv. These tasks are designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the Prefect documentation .","title":"Python setup"},{"location":"#installation","text":"Install prefect-dbt with pip : pip install prefect-dbt","title":"Installation"},{"location":"#trigger-a-dbt-cloud-job-and-wait-for-completion","text":"from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion @flow def run_dbt_job_flow (): run_result = trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 ) run_dbt_job_flow ()","title":"Trigger a dbt Cloud job and wait for completion"},{"location":"#execute-a-dbt-cli-command","text":"from prefect import flow from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_command_flow () -> str : result = trigger_dbt_cli_command ( \"dbt debug\" ) return result # Returns the last line the in CLI output trigger_dbt_cli_command_flow ()","title":"Execute a dbt CLI command"},{"location":"#execute-a-dbt-cli-command-without-a-pre-populated-profilesyml","text":"from prefect import flow from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command from prefect_dbt.cli.configs import SnowflakeTargetConfigs @flow def trigger_dbt_cli_command_flow (): connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ), ) target_configs = SnowflakeTargetConfigs ( connector = connector ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) result = trigger_dbt_cli_command ( \"dbt debug\" , overwrite_profiles = True , dbt_cli_profile = dbt_cli_profile ) return result trigger_dbt_cli_command_flow ()","title":"Execute a dbt CLI command without a pre-populated profiles.yml"},{"location":"#resources","text":"If you encounter any bugs while using prefect-dbt , feel free to open an issue in the prefect-dbt repository. If you have any questions or issues while using prefect-dbt , you can find help in either the Prefect Discourse forum or the Prefect Slack community . If you need help getting started with or using dbt, please consult the dbt documentation .","title":"Resources"},{"location":"#development","text":"If you'd like to install a version of prefect-dbt for development, clone the repository and perform an editable install with pip : git clone https://github.com/PrefectHQ/prefect-dbt.git cd prefect-dbt/ pip install -e \".[dev]\" # Install linting pre-commit hooks pre-commit install","title":"Development"},{"location":"cli/commands/","text":"prefect_dbt.cli.commands Module containing tasks and flows for interacting with dbt CLI trigger_dbt_cli_command async Task for running dbt commands. If no profiles.yml file is found or if overwrite_profiles flag is set to True, this will first generate a profiles.yml file in the profiles_dir directory. Then run the dbt CLI shell command. Parameters: Name Type Description Default command str The dbt command to be executed. required profiles_dir Optional [ Union [ Path , str ]] The directory to search for the profiles.yml file. Setting this appends the --profiles-dir option to the command provided. If this is not set, will try using the DBT_PROFILES_DIR environment variable, but if that's also not set, will use the default directory $HOME/.dbt/ . None project_dir Optional [ Union [ Path , str ]] The directory to search for the dbt_project.yml file. Default is the current working directory and its parents. None overwrite_profiles bool Whether the existing profiles.yml file under profiles_dir should be overwritten with a new profile. False dbt_cli_profile Optional [ DbtCliProfile ] Profiles class containing the profile written to profiles.yml. Note! This is optional and will raise an error if profiles.yml already exists under profile_dir and overwrite_profiles is set to False. None **shell_run_command_kwargs Dict [ str , Any ] Additional keyword arguments to pass to shell_run_command . {} Returns: Name Type Description last_line_cli_output str The last line of the CLI output will be returned if return_all in shell_run_command_kwargs is False. This is the default behavior. full_cli_output List [ str ] Full CLI output will be returned if return_all in shell_run_command_kwargs is True. Examples: Execute dbt debug with a pre-populated profiles.yml. from prefect import flow from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_command_flow (): result = trigger_dbt_cli_command ( \"dbt debug\" ) return result trigger_dbt_cli_command_flow () Execute dbt debug without a pre-populated profiles.yml. from prefect import flow from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials @flow def trigger_dbt_cli_command_flow (): credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ) connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = credentials , ) target_configs = SnowflakeTargetConfigs ( connector = connector ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) result = trigger_dbt_cli_command ( \"dbt debug\" , overwrite_profiles = True , dbt_cli_profile = dbt_cli_profile ) return result trigger_dbt_cli_command_flow () Source code in prefect_dbt/cli/commands.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 @task async def trigger_dbt_cli_command ( command : str , profiles_dir : Optional [ Union [ Path , str ]] = None , project_dir : Optional [ Union [ Path , str ]] = None , overwrite_profiles : bool = False , dbt_cli_profile : Optional [ DbtCliProfile ] = None , ** shell_run_command_kwargs : Dict [ str , Any ], ) -> Union [ List [ str ], str ]: \"\"\" Task for running dbt commands. If no profiles.yml file is found or if overwrite_profiles flag is set to True, this will first generate a profiles.yml file in the profiles_dir directory. Then run the dbt CLI shell command. Args: command: The dbt command to be executed. profiles_dir: The directory to search for the profiles.yml file. Setting this appends the `--profiles-dir` option to the command provided. If this is not set, will try using the DBT_PROFILES_DIR environment variable, but if that's also not set, will use the default directory `$HOME/.dbt/`. project_dir: The directory to search for the dbt_project.yml file. Default is the current working directory and its parents. overwrite_profiles: Whether the existing profiles.yml file under profiles_dir should be overwritten with a new profile. dbt_cli_profile: Profiles class containing the profile written to profiles.yml. Note! This is optional and will raise an error if profiles.yml already exists under profile_dir and overwrite_profiles is set to False. **shell_run_command_kwargs: Additional keyword arguments to pass to [shell_run_command](https://prefecthq.github.io/prefect-shell/commands/#prefect_shell.commands.shell_run_command). Returns: last_line_cli_output (str): The last line of the CLI output will be returned if `return_all` in `shell_run_command_kwargs` is False. This is the default behavior. full_cli_output (List[str]): Full CLI output will be returned if `return_all` in `shell_run_command_kwargs` is True. Examples: Execute `dbt debug` with a pre-populated profiles.yml. ```python from prefect import flow from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_command_flow(): result = trigger_dbt_cli_command(\"dbt debug\") return result trigger_dbt_cli_command_flow() ``` Execute `dbt debug` without a pre-populated profiles.yml. ```python from prefect import flow from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials @flow def trigger_dbt_cli_command_flow(): credentials = SnowflakeCredentials( user=\"user\", password=\"password\", account=\"account.region.aws\", role=\"role\", ) connector = SnowflakeConnector( schema=\"public\", database=\"database\", warehouse=\"warehouse\", credentials=credentials, ) target_configs = SnowflakeTargetConfigs( connector=connector ) dbt_cli_profile = DbtCliProfile( name=\"jaffle_shop\", target=\"dev\", target_configs=target_configs, ) result = trigger_dbt_cli_command( \"dbt debug\", overwrite_profiles=True, dbt_cli_profile=dbt_cli_profile ) return result trigger_dbt_cli_command_flow() ``` \"\"\" # noqa # check if variable is set, if not check env, if not use expected default logger = get_run_logger () if not which ( \"dbt\" ): raise ImportError ( \"dbt-core needs to be installed to use this task; run \" '`pip install \"prefect-dbt[cli]\"' ) elif not command . startswith ( \"dbt\" ): await shell_run_command . fn ( command = \"dbt --help\" ) raise ValueError ( \"Command is not a valid dbt sub-command; see dbt --help above,\" \"or use prefect_shell.commands.shell_run_command for non-dbt related \" \"commands instead\" ) if profiles_dir is None : profiles_dir = os . getenv ( \"DBT_PROFILES_DIR\" , Path . home () / \".dbt\" ) profiles_dir = Path ( profiles_dir ) . expanduser () # https://docs.getdbt.com/dbt-cli/configure-your-profile # Note that the file always needs to be called profiles.yml, # regardless of which directory it is in. profiles_path = profiles_dir / \"profiles.yml\" logger . debug ( f \"Using this profiles path: { profiles_path } \" ) # write the profile if overwrite or no profiles exist if overwrite_profiles or not profiles_path . exists (): if dbt_cli_profile is None : raise ValueError ( \"Provide `dbt_cli_profile` keyword for writing profiles\" ) profile = dbt_cli_profile . get_profile () profiles_dir . mkdir ( exist_ok = True ) with open ( profiles_path , \"w+\" ) as f : yaml . dump ( profile , f , default_flow_style = False ) logger . info ( f \"Wrote profile to { profiles_path } \" ) elif dbt_cli_profile is not None : raise ValueError ( f \"Since overwrite_profiles is False and profiles_path ( { profiles_path } ) \" f \"already exists, the profile within dbt_cli_profile could not be used; \" f \"if the existing profile is satisfactory, do not pass dbt_cli_profile\" ) # append the options command += f \" --profiles-dir { profiles_dir } \" if project_dir is not None : project_dir = Path ( project_dir ) . expanduser () command += f \" --project-dir { project_dir } \" # fix up empty shell_run_command_kwargs shell_run_command_kwargs = shell_run_command_kwargs or {} logger . info ( f \"Running dbt command: { command } \" ) result = await shell_run_command . fn ( command = command , ** shell_run_command_kwargs ) return result","title":"Commands"},{"location":"cli/commands/#prefect_dbt.cli.commands","text":"Module containing tasks and flows for interacting with dbt CLI","title":"commands"},{"location":"cli/commands/#prefect_dbt.cli.commands.trigger_dbt_cli_command","text":"Task for running dbt commands. If no profiles.yml file is found or if overwrite_profiles flag is set to True, this will first generate a profiles.yml file in the profiles_dir directory. Then run the dbt CLI shell command. Parameters: Name Type Description Default command str The dbt command to be executed. required profiles_dir Optional [ Union [ Path , str ]] The directory to search for the profiles.yml file. Setting this appends the --profiles-dir option to the command provided. If this is not set, will try using the DBT_PROFILES_DIR environment variable, but if that's also not set, will use the default directory $HOME/.dbt/ . None project_dir Optional [ Union [ Path , str ]] The directory to search for the dbt_project.yml file. Default is the current working directory and its parents. None overwrite_profiles bool Whether the existing profiles.yml file under profiles_dir should be overwritten with a new profile. False dbt_cli_profile Optional [ DbtCliProfile ] Profiles class containing the profile written to profiles.yml. Note! This is optional and will raise an error if profiles.yml already exists under profile_dir and overwrite_profiles is set to False. None **shell_run_command_kwargs Dict [ str , Any ] Additional keyword arguments to pass to shell_run_command . {} Returns: Name Type Description last_line_cli_output str The last line of the CLI output will be returned if return_all in shell_run_command_kwargs is False. This is the default behavior. full_cli_output List [ str ] Full CLI output will be returned if return_all in shell_run_command_kwargs is True. Examples: Execute dbt debug with a pre-populated profiles.yml. from prefect import flow from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_command_flow (): result = trigger_dbt_cli_command ( \"dbt debug\" ) return result trigger_dbt_cli_command_flow () Execute dbt debug without a pre-populated profiles.yml. from prefect import flow from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials @flow def trigger_dbt_cli_command_flow (): credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ) connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = credentials , ) target_configs = SnowflakeTargetConfigs ( connector = connector ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) result = trigger_dbt_cli_command ( \"dbt debug\" , overwrite_profiles = True , dbt_cli_profile = dbt_cli_profile ) return result trigger_dbt_cli_command_flow () Source code in prefect_dbt/cli/commands.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 @task async def trigger_dbt_cli_command ( command : str , profiles_dir : Optional [ Union [ Path , str ]] = None , project_dir : Optional [ Union [ Path , str ]] = None , overwrite_profiles : bool = False , dbt_cli_profile : Optional [ DbtCliProfile ] = None , ** shell_run_command_kwargs : Dict [ str , Any ], ) -> Union [ List [ str ], str ]: \"\"\" Task for running dbt commands. If no profiles.yml file is found or if overwrite_profiles flag is set to True, this will first generate a profiles.yml file in the profiles_dir directory. Then run the dbt CLI shell command. Args: command: The dbt command to be executed. profiles_dir: The directory to search for the profiles.yml file. Setting this appends the `--profiles-dir` option to the command provided. If this is not set, will try using the DBT_PROFILES_DIR environment variable, but if that's also not set, will use the default directory `$HOME/.dbt/`. project_dir: The directory to search for the dbt_project.yml file. Default is the current working directory and its parents. overwrite_profiles: Whether the existing profiles.yml file under profiles_dir should be overwritten with a new profile. dbt_cli_profile: Profiles class containing the profile written to profiles.yml. Note! This is optional and will raise an error if profiles.yml already exists under profile_dir and overwrite_profiles is set to False. **shell_run_command_kwargs: Additional keyword arguments to pass to [shell_run_command](https://prefecthq.github.io/prefect-shell/commands/#prefect_shell.commands.shell_run_command). Returns: last_line_cli_output (str): The last line of the CLI output will be returned if `return_all` in `shell_run_command_kwargs` is False. This is the default behavior. full_cli_output (List[str]): Full CLI output will be returned if `return_all` in `shell_run_command_kwargs` is True. Examples: Execute `dbt debug` with a pre-populated profiles.yml. ```python from prefect import flow from prefect_dbt.cli.commands import trigger_dbt_cli_command @flow def trigger_dbt_cli_command_flow(): result = trigger_dbt_cli_command(\"dbt debug\") return result trigger_dbt_cli_command_flow() ``` Execute `dbt debug` without a pre-populated profiles.yml. ```python from prefect import flow from prefect_dbt.cli.credentials import DbtCliProfile from prefect_dbt.cli.commands import trigger_dbt_cli_command from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials @flow def trigger_dbt_cli_command_flow(): credentials = SnowflakeCredentials( user=\"user\", password=\"password\", account=\"account.region.aws\", role=\"role\", ) connector = SnowflakeConnector( schema=\"public\", database=\"database\", warehouse=\"warehouse\", credentials=credentials, ) target_configs = SnowflakeTargetConfigs( connector=connector ) dbt_cli_profile = DbtCliProfile( name=\"jaffle_shop\", target=\"dev\", target_configs=target_configs, ) result = trigger_dbt_cli_command( \"dbt debug\", overwrite_profiles=True, dbt_cli_profile=dbt_cli_profile ) return result trigger_dbt_cli_command_flow() ``` \"\"\" # noqa # check if variable is set, if not check env, if not use expected default logger = get_run_logger () if not which ( \"dbt\" ): raise ImportError ( \"dbt-core needs to be installed to use this task; run \" '`pip install \"prefect-dbt[cli]\"' ) elif not command . startswith ( \"dbt\" ): await shell_run_command . fn ( command = \"dbt --help\" ) raise ValueError ( \"Command is not a valid dbt sub-command; see dbt --help above,\" \"or use prefect_shell.commands.shell_run_command for non-dbt related \" \"commands instead\" ) if profiles_dir is None : profiles_dir = os . getenv ( \"DBT_PROFILES_DIR\" , Path . home () / \".dbt\" ) profiles_dir = Path ( profiles_dir ) . expanduser () # https://docs.getdbt.com/dbt-cli/configure-your-profile # Note that the file always needs to be called profiles.yml, # regardless of which directory it is in. profiles_path = profiles_dir / \"profiles.yml\" logger . debug ( f \"Using this profiles path: { profiles_path } \" ) # write the profile if overwrite or no profiles exist if overwrite_profiles or not profiles_path . exists (): if dbt_cli_profile is None : raise ValueError ( \"Provide `dbt_cli_profile` keyword for writing profiles\" ) profile = dbt_cli_profile . get_profile () profiles_dir . mkdir ( exist_ok = True ) with open ( profiles_path , \"w+\" ) as f : yaml . dump ( profile , f , default_flow_style = False ) logger . info ( f \"Wrote profile to { profiles_path } \" ) elif dbt_cli_profile is not None : raise ValueError ( f \"Since overwrite_profiles is False and profiles_path ( { profiles_path } ) \" f \"already exists, the profile within dbt_cli_profile could not be used; \" f \"if the existing profile is satisfactory, do not pass dbt_cli_profile\" ) # append the options command += f \" --profiles-dir { profiles_dir } \" if project_dir is not None : project_dir = Path ( project_dir ) . expanduser () command += f \" --project-dir { project_dir } \" # fix up empty shell_run_command_kwargs shell_run_command_kwargs = shell_run_command_kwargs or {} logger . info ( f \"Running dbt command: { command } \" ) result = await shell_run_command . fn ( command = command , ** shell_run_command_kwargs ) return result","title":"trigger_dbt_cli_command()"},{"location":"cli/credentials/","text":"prefect_dbt.cli.credentials Module containing credentials for interacting with dbt CLI DbtCliProfile Profile for use across dbt CLI tasks and flows. Attributes: Name Type Description name str Profile name used for populating profiles.yml. target str The default target your dbt project will use. target_configs TargetConfigs Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink. global_configs GlobalConfigs Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Valid keys can be found here . Examples: Load stored dbt CLI profile: from prefect_dbt.cli import DbtCliProfile dbt_cli_profile = DbtCliProfile . load ( \"BLOCK_NAME\" ) . get_profile () Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs: from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials snowflake_credentials = SnowflakeCredentials ( schema = \"schema\" , user = \"user\" , password = \"password\" , account = \"account\" , role = \"role\" , database = \"database\" , warehouse = \"warehouse\" , ) target_configs = SnowflakeTargetConfigs ( credentials = snowflake_credentials ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) profile = dbt_cli_profile . get_profile () Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs: from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import GlobalConfigs , TargetConfigs target_configs_extras = dict ( host = \"hostname.region.redshift.amazonaws.com\" , user = \"username\" , password = \"password1\" , port = 5439 , dbname = \"analytics\" , ) target_configs = TargetConfigs ( type = \"redshift\" , schema = \"schema\" , threads = 4 , extras = target_configs_extras ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) profile = dbt_cli_profile . get_profile () Source code in prefect_dbt/cli/credentials.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class DbtCliProfile ( Block ): \"\"\" Profile for use across dbt CLI tasks and flows. Attributes: name (str): Profile name used for populating profiles.yml. target (str): The default target your dbt project will use. target_configs (TargetConfigs): Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the [Available adapters]( https://docs.getdbt.com/docs/available-adapters) page and click the desired adapter's \"Profile Setup\" hyperlink. global_configs (GlobalConfigs): Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Valid keys can be found [here]( https://docs.getdbt.com/reference/global-configs). Examples: Load stored dbt CLI profile: ```python from prefect_dbt.cli import DbtCliProfile dbt_cli_profile = DbtCliProfile.load(\"BLOCK_NAME\").get_profile() ``` Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs: ```python from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials snowflake_credentials = SnowflakeCredentials( schema=\"schema\", user=\"user\", password=\"password\", account=\"account\", role=\"role\", database=\"database\", warehouse=\"warehouse\", ) target_configs = SnowflakeTargetConfigs( credentials=snowflake_credentials ) dbt_cli_profile = DbtCliProfile( name=\"jaffle_shop\", target=\"dev\", target_configs=target_configs, ) profile = dbt_cli_profile.get_profile() ``` Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs: ```python from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import GlobalConfigs, TargetConfigs target_configs_extras = dict( host=\"hostname.region.redshift.amazonaws.com\", user=\"username\", password=\"password1\", port=5439, dbname=\"analytics\", ) target_configs = TargetConfigs( type=\"redshift\", schema=\"schema\", threads=4, extras=target_configs_extras ) dbt_cli_profile = DbtCliProfile( name=\"jaffle_shop\", target=\"dev\", target_configs=target_configs, ) profile = dbt_cli_profile.get_profile() ``` \"\"\" _block_type_name = \"dbt CLI Profile\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa name : str target : str target_configs : TargetConfigs global_configs : Optional [ GlobalConfigs ] = None def get_profile ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt profile, likely used for writing to profiles.yml. Returns: A JSON compatible dictionary with the expected format of profiles.yml. \"\"\" profile = { \"config\" : self . global_configs . get_configs () if self . global_configs else {}, self . name : { \"target\" : self . target , \"outputs\" : { self . target : self . target_configs . get_configs ()}, }, } return profile get_profile Returns the dbt profile, likely used for writing to profiles.yml. Returns: Type Description Dict [ str , Any ] A JSON compatible dictionary with the expected format of profiles.yml. Source code in prefect_dbt/cli/credentials.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def get_profile ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt profile, likely used for writing to profiles.yml. Returns: A JSON compatible dictionary with the expected format of profiles.yml. \"\"\" profile = { \"config\" : self . global_configs . get_configs () if self . global_configs else {}, self . name : { \"target\" : self . target , \"outputs\" : { self . target : self . target_configs . get_configs ()}, }, } return profile","title":"Credentials"},{"location":"cli/credentials/#prefect_dbt.cli.credentials","text":"Module containing credentials for interacting with dbt CLI","title":"credentials"},{"location":"cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile","text":"Profile for use across dbt CLI tasks and flows. Attributes: Name Type Description name str Profile name used for populating profiles.yml. target str The default target your dbt project will use. target_configs TargetConfigs Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink. global_configs GlobalConfigs Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Valid keys can be found here . Examples: Load stored dbt CLI profile: from prefect_dbt.cli import DbtCliProfile dbt_cli_profile = DbtCliProfile . load ( \"BLOCK_NAME\" ) . get_profile () Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs: from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials snowflake_credentials = SnowflakeCredentials ( schema = \"schema\" , user = \"user\" , password = \"password\" , account = \"account\" , role = \"role\" , database = \"database\" , warehouse = \"warehouse\" , ) target_configs = SnowflakeTargetConfigs ( credentials = snowflake_credentials ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) profile = dbt_cli_profile . get_profile () Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs: from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import GlobalConfigs , TargetConfigs target_configs_extras = dict ( host = \"hostname.region.redshift.amazonaws.com\" , user = \"username\" , password = \"password1\" , port = 5439 , dbname = \"analytics\" , ) target_configs = TargetConfigs ( type = \"redshift\" , schema = \"schema\" , threads = 4 , extras = target_configs_extras ) dbt_cli_profile = DbtCliProfile ( name = \"jaffle_shop\" , target = \"dev\" , target_configs = target_configs , ) profile = dbt_cli_profile . get_profile () Source code in prefect_dbt/cli/credentials.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class DbtCliProfile ( Block ): \"\"\" Profile for use across dbt CLI tasks and flows. Attributes: name (str): Profile name used for populating profiles.yml. target (str): The default target your dbt project will use. target_configs (TargetConfigs): Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the [Available adapters]( https://docs.getdbt.com/docs/available-adapters) page and click the desired adapter's \"Profile Setup\" hyperlink. global_configs (GlobalConfigs): Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Valid keys can be found [here]( https://docs.getdbt.com/reference/global-configs). Examples: Load stored dbt CLI profile: ```python from prefect_dbt.cli import DbtCliProfile dbt_cli_profile = DbtCliProfile.load(\"BLOCK_NAME\").get_profile() ``` Get a dbt Snowflake profile from DbtCliProfile by using SnowflakeTargetConfigs: ```python from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials snowflake_credentials = SnowflakeCredentials( schema=\"schema\", user=\"user\", password=\"password\", account=\"account\", role=\"role\", database=\"database\", warehouse=\"warehouse\", ) target_configs = SnowflakeTargetConfigs( credentials=snowflake_credentials ) dbt_cli_profile = DbtCliProfile( name=\"jaffle_shop\", target=\"dev\", target_configs=target_configs, ) profile = dbt_cli_profile.get_profile() ``` Get a dbt Redshift profile from DbtCliProfile by using generic TargetConfigs: ```python from prefect_dbt.cli import DbtCliProfile from prefect_dbt.cli.configs import GlobalConfigs, TargetConfigs target_configs_extras = dict( host=\"hostname.region.redshift.amazonaws.com\", user=\"username\", password=\"password1\", port=5439, dbname=\"analytics\", ) target_configs = TargetConfigs( type=\"redshift\", schema=\"schema\", threads=4, extras=target_configs_extras ) dbt_cli_profile = DbtCliProfile( name=\"jaffle_shop\", target=\"dev\", target_configs=target_configs, ) profile = dbt_cli_profile.get_profile() ``` \"\"\" _block_type_name = \"dbt CLI Profile\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa name : str target : str target_configs : TargetConfigs global_configs : Optional [ GlobalConfigs ] = None def get_profile ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt profile, likely used for writing to profiles.yml. Returns: A JSON compatible dictionary with the expected format of profiles.yml. \"\"\" profile = { \"config\" : self . global_configs . get_configs () if self . global_configs else {}, self . name : { \"target\" : self . target , \"outputs\" : { self . target : self . target_configs . get_configs ()}, }, } return profile","title":"DbtCliProfile"},{"location":"cli/credentials/#prefect_dbt.cli.credentials.DbtCliProfile.get_profile","text":"Returns the dbt profile, likely used for writing to profiles.yml. Returns: Type Description Dict [ str , Any ] A JSON compatible dictionary with the expected format of profiles.yml. Source code in prefect_dbt/cli/credentials.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def get_profile ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt profile, likely used for writing to profiles.yml. Returns: A JSON compatible dictionary with the expected format of profiles.yml. \"\"\" profile = { \"config\" : self . global_configs . get_configs () if self . global_configs else {}, self . name : { \"target\" : self . target , \"outputs\" : { self . target : self . target_configs . get_configs ()}, }, } return profile","title":"get_profile()"},{"location":"cli/configs/base/","text":"prefect_dbt.cli.configs.base Module containing models for base configs DbtConfigs Abstract class for other dbt Configs. Attributes: Name Type Description extras Optional [ Dict [ str , Any ]] Extra target configs' keywords, not yet added to prefect-dbt, but available in dbt; if there are duplicate keys between extras and TargetConfigs, an error will be raised. Source code in prefect_dbt/cli/configs/base.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class DbtConfigs ( Block , abc . ABC ): \"\"\" Abstract class for other dbt Configs. Attributes: extras: Extra target configs' keywords, not yet added to prefect-dbt, but available in dbt; if there are duplicate keys between extras and TargetConfigs, an error will be raised. \"\"\" extras : Optional [ Dict [ str , Any ]] = None def _populate_configs_json ( self , configs_json : Dict [ str , Any ], fields : Dict [ str , Any ], model : BaseModel = None , ) -> Dict [ str , Any ]: \"\"\" Recursively populate configs_json. \"\"\" for field_name , field in fields . items (): if model is not None : # get actual value from model field_value = getattr ( model , field_name ) # override the name with alias so dbt parser can recognize the keyword; # e.g. schema_ -> schema, returns the original name if no alias is set field_name = field . alias else : field_value = field if field_value is None : # do not add to configs json if no value or default is set continue if isinstance ( field_value , BaseModel ): configs_json = self . _populate_configs_json ( configs_json , field_value . __fields__ , model = field_value ) elif field_name == \"extras\" : configs_json = self . _populate_configs_json ( configs_json , field_value ) else : if field_name in configs_json . keys (): raise ValueError ( f \"The keyword, { field_name } , has already been provided in \" f \"TargetConfigs; remove duplicated keywords to continue\" ) if isinstance ( field_value , ( SecretStr , SecretBytes )): field_value = field_value . get_secret_value () configs_json [ field_name ] = field_value return configs_json def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs, likely used eventually for writing to profiles.yml. Returns: A configs JSON. \"\"\" return self . _populate_configs_json ({}, self . __fields__ , model = self ) get_configs Returns the dbt configs, likely used eventually for writing to profiles.yml. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/base.py 64 65 66 67 68 69 70 71 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs, likely used eventually for writing to profiles.yml. Returns: A configs JSON. \"\"\" return self . _populate_configs_json ({}, self . __fields__ , model = self ) GlobalConfigs Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Docs can be found here . Attributes: Name Type Description send_anonymous_usage_stats Optional [ bool ] Whether usage stats are sent to dbt. use_colors Optional [ bool ] Colorize the output it prints in your terminal. partial_parse Optional [ bool ] When partial parsing is enabled, dbt will use an stored internal manifest to determine which files have been changed (if any) since it last parsed the project. printer_width Optional [ int ] Length of characters before starting a new line. write_json Optional [ bool ] Determines whether dbt writes JSON artifacts to the target/ directory. warn_error Optional [ bool ] Whether to convert dbt warnings into errors. log_format Optional [ bool ] The LOG_FORMAT config specifies how dbt's logs should be formatted. If the value of this config is json, dbt will output fully structured logs in JSON format. debug Optional [ bool ] Whether to redirect dbt's debug logs to standard out. version_check Optional [ bool ] Whether to raise an error if a project's version is used with an incompatible dbt version. fail_fast Optional [ bool ] Make dbt exit immediately if a single resource fails to build. use_experimental_parser Optional [ bool ] Opt into the latest experimental version of the static parser. static_parser Optional [ bool ] Whether to use the static parser . Examples: Load stored GlobalConfigs: from prefect_dbt.cli.configs import GlobalConfigs dbt_cli_global_configs = GlobalConfigs . load ( \"BLOCK_NAME\" ) Source code in prefect_dbt/cli/configs/base.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 class GlobalConfigs ( DbtConfigs ): \"\"\" Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Docs can be found [here]( https://docs.getdbt.com/reference/global-configs). Attributes: send_anonymous_usage_stats: Whether usage stats are sent to dbt. use_colors: Colorize the output it prints in your terminal. partial_parse: When partial parsing is enabled, dbt will use an stored internal manifest to determine which files have been changed (if any) since it last parsed the project. printer_width: Length of characters before starting a new line. write_json: Determines whether dbt writes JSON artifacts to the target/ directory. warn_error: Whether to convert dbt warnings into errors. log_format: The LOG_FORMAT config specifies how dbt's logs should be formatted. If the value of this config is json, dbt will output fully structured logs in JSON format. debug: Whether to redirect dbt's debug logs to standard out. version_check: Whether to raise an error if a project's version is used with an incompatible dbt version. fail_fast: Make dbt exit immediately if a single resource fails to build. use_experimental_parser: Opt into the latest experimental version of the static parser. static_parser: Whether to use the [static parser]( https://docs.getdbt.com/reference/parsing#static-parser). Examples: Load stored GlobalConfigs: ```python from prefect_dbt.cli.configs import GlobalConfigs dbt_cli_global_configs = GlobalConfigs.load(\"BLOCK_NAME\") ``` \"\"\" _block_type_name = \"dbt CLI Global Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa send_anonymous_usage_stats : Optional [ bool ] = None use_colors : Optional [ bool ] = None partial_parse : Optional [ bool ] = None printer_width : Optional [ int ] = None write_json : Optional [ bool ] = None warn_error : Optional [ bool ] = None log_format : Optional [ bool ] = None debug : Optional [ bool ] = None version_check : Optional [ bool ] = None fail_fast : Optional [ bool ] = None use_experimental_parser : Optional [ bool ] = None static_parser : Optional [ bool ] = None TargetConfigs Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink. Attributes: Name Type Description type str The name of the database warehouse schema str The schema that dbt will build objects into; in BigQuery, a schema is actually a dataset. threads int The number of threads representing the max number of paths through the graph dbt may work on at once. Examples: Load stored TargetConfigs: from prefect_dbt.cli.configs import TargetConfigs dbt_cli_target_configs = TargetConfigs . load ( \"BLOCK_NAME\" ) Source code in prefect_dbt/cli/configs/base.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 class TargetConfigs ( DbtConfigs ): \"\"\" Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the [Available adapters]( https://docs.getdbt.com/docs/available-adapters) page and click the desired adapter's \"Profile Setup\" hyperlink. Attributes: type: The name of the database warehouse schema: The schema that dbt will build objects into; in BigQuery, a schema is actually a dataset. threads: The number of threads representing the max number of paths through the graph dbt may work on at once. Examples: Load stored TargetConfigs: ```python from prefect_dbt.cli.configs import TargetConfigs dbt_cli_target_configs = TargetConfigs.load(\"BLOCK_NAME\") ``` \"\"\" _block_type_name = \"dbt CLI Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa type : str schema_ : str = Field ( alias = \"schema\" ) threads : int = 4","title":"Base"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base","text":"Module containing models for base configs","title":"base"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs","text":"Abstract class for other dbt Configs. Attributes: Name Type Description extras Optional [ Dict [ str , Any ]] Extra target configs' keywords, not yet added to prefect-dbt, but available in dbt; if there are duplicate keys between extras and TargetConfigs, an error will be raised. Source code in prefect_dbt/cli/configs/base.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class DbtConfigs ( Block , abc . ABC ): \"\"\" Abstract class for other dbt Configs. Attributes: extras: Extra target configs' keywords, not yet added to prefect-dbt, but available in dbt; if there are duplicate keys between extras and TargetConfigs, an error will be raised. \"\"\" extras : Optional [ Dict [ str , Any ]] = None def _populate_configs_json ( self , configs_json : Dict [ str , Any ], fields : Dict [ str , Any ], model : BaseModel = None , ) -> Dict [ str , Any ]: \"\"\" Recursively populate configs_json. \"\"\" for field_name , field in fields . items (): if model is not None : # get actual value from model field_value = getattr ( model , field_name ) # override the name with alias so dbt parser can recognize the keyword; # e.g. schema_ -> schema, returns the original name if no alias is set field_name = field . alias else : field_value = field if field_value is None : # do not add to configs json if no value or default is set continue if isinstance ( field_value , BaseModel ): configs_json = self . _populate_configs_json ( configs_json , field_value . __fields__ , model = field_value ) elif field_name == \"extras\" : configs_json = self . _populate_configs_json ( configs_json , field_value ) else : if field_name in configs_json . keys (): raise ValueError ( f \"The keyword, { field_name } , has already been provided in \" f \"TargetConfigs; remove duplicated keywords to continue\" ) if isinstance ( field_value , ( SecretStr , SecretBytes )): field_value = field_value . get_secret_value () configs_json [ field_name ] = field_value return configs_json def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs, likely used eventually for writing to profiles.yml. Returns: A configs JSON. \"\"\" return self . _populate_configs_json ({}, self . __fields__ , model = self )","title":"DbtConfigs"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.DbtConfigs.get_configs","text":"Returns the dbt configs, likely used eventually for writing to profiles.yml. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/base.py 64 65 66 67 68 69 70 71 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs, likely used eventually for writing to profiles.yml. Returns: A configs JSON. \"\"\" return self . _populate_configs_json ({}, self . __fields__ , model = self )","title":"get_configs()"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.GlobalConfigs","text":"Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Docs can be found here . Attributes: Name Type Description send_anonymous_usage_stats Optional [ bool ] Whether usage stats are sent to dbt. use_colors Optional [ bool ] Colorize the output it prints in your terminal. partial_parse Optional [ bool ] When partial parsing is enabled, dbt will use an stored internal manifest to determine which files have been changed (if any) since it last parsed the project. printer_width Optional [ int ] Length of characters before starting a new line. write_json Optional [ bool ] Determines whether dbt writes JSON artifacts to the target/ directory. warn_error Optional [ bool ] Whether to convert dbt warnings into errors. log_format Optional [ bool ] The LOG_FORMAT config specifies how dbt's logs should be formatted. If the value of this config is json, dbt will output fully structured logs in JSON format. debug Optional [ bool ] Whether to redirect dbt's debug logs to standard out. version_check Optional [ bool ] Whether to raise an error if a project's version is used with an incompatible dbt version. fail_fast Optional [ bool ] Make dbt exit immediately if a single resource fails to build. use_experimental_parser Optional [ bool ] Opt into the latest experimental version of the static parser. static_parser Optional [ bool ] Whether to use the static parser . Examples: Load stored GlobalConfigs: from prefect_dbt.cli.configs import GlobalConfigs dbt_cli_global_configs = GlobalConfigs . load ( \"BLOCK_NAME\" ) Source code in prefect_dbt/cli/configs/base.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 class GlobalConfigs ( DbtConfigs ): \"\"\" Global configs control things like the visual output of logs, the manner in which dbt parses your project, and what to do when dbt finds a version mismatch or a failing model. Docs can be found [here]( https://docs.getdbt.com/reference/global-configs). Attributes: send_anonymous_usage_stats: Whether usage stats are sent to dbt. use_colors: Colorize the output it prints in your terminal. partial_parse: When partial parsing is enabled, dbt will use an stored internal manifest to determine which files have been changed (if any) since it last parsed the project. printer_width: Length of characters before starting a new line. write_json: Determines whether dbt writes JSON artifacts to the target/ directory. warn_error: Whether to convert dbt warnings into errors. log_format: The LOG_FORMAT config specifies how dbt's logs should be formatted. If the value of this config is json, dbt will output fully structured logs in JSON format. debug: Whether to redirect dbt's debug logs to standard out. version_check: Whether to raise an error if a project's version is used with an incompatible dbt version. fail_fast: Make dbt exit immediately if a single resource fails to build. use_experimental_parser: Opt into the latest experimental version of the static parser. static_parser: Whether to use the [static parser]( https://docs.getdbt.com/reference/parsing#static-parser). Examples: Load stored GlobalConfigs: ```python from prefect_dbt.cli.configs import GlobalConfigs dbt_cli_global_configs = GlobalConfigs.load(\"BLOCK_NAME\") ``` \"\"\" _block_type_name = \"dbt CLI Global Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa send_anonymous_usage_stats : Optional [ bool ] = None use_colors : Optional [ bool ] = None partial_parse : Optional [ bool ] = None printer_width : Optional [ int ] = None write_json : Optional [ bool ] = None warn_error : Optional [ bool ] = None log_format : Optional [ bool ] = None debug : Optional [ bool ] = None version_check : Optional [ bool ] = None fail_fast : Optional [ bool ] = None use_experimental_parser : Optional [ bool ] = None static_parser : Optional [ bool ] = None","title":"GlobalConfigs"},{"location":"cli/configs/base/#prefect_dbt.cli.configs.base.TargetConfigs","text":"Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the Available adapters page and click the desired adapter's \"Profile Setup\" hyperlink. Attributes: Name Type Description type str The name of the database warehouse schema str The schema that dbt will build objects into; in BigQuery, a schema is actually a dataset. threads int The number of threads representing the max number of paths through the graph dbt may work on at once. Examples: Load stored TargetConfigs: from prefect_dbt.cli.configs import TargetConfigs dbt_cli_target_configs = TargetConfigs . load ( \"BLOCK_NAME\" ) Source code in prefect_dbt/cli/configs/base.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 class TargetConfigs ( DbtConfigs ): \"\"\" Target configs contain credentials and settings, specific to the warehouse you're connecting to. To find valid keys, head to the [Available adapters]( https://docs.getdbt.com/docs/available-adapters) page and click the desired adapter's \"Profile Setup\" hyperlink. Attributes: type: The name of the database warehouse schema: The schema that dbt will build objects into; in BigQuery, a schema is actually a dataset. threads: The number of threads representing the max number of paths through the graph dbt may work on at once. Examples: Load stored TargetConfigs: ```python from prefect_dbt.cli.configs import TargetConfigs dbt_cli_target_configs = TargetConfigs.load(\"BLOCK_NAME\") ``` \"\"\" _block_type_name = \"dbt CLI Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa type : str schema_ : str = Field ( alias = \"schema\" ) threads : int = 4","title":"TargetConfigs"},{"location":"cli/configs/bigquery/","text":"prefect_dbt.cli.configs.bigquery Module containing models for BigQuery configs BigQueryTargetConfigs Target configs contain credentials and settings, specific to BigQuery. To find valid keys, head to the BigQuery Profile page. Attributes: Name Type Description credentials GcpCredentials The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored BigQueryTargetConfigs: from prefect_dbt.cli.configs import BigQueryTargetConfigs bigquery_target_configs = BigQueryTargetConfigs . load ( \"BLOCK_NAME\" ) Instantiate BigQueryTargetConfigs with service account file. from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials ( service_account_file = \"~/.secrets/gcp\" ) target_configs = BigQueryTargetConfigs ( schema = \"schema\" , project = \"project\" , credentials = credentials , ) Instantiate BigQueryTargetConfigs with service account info. import json from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials ( service_account_info = json . dumps ({ \"type\" : \"service_account\" , \"project_id\" : \"project_id\" , \"private_key_id\" : \"private_key_id\" , \"private_key\" : \"private_key\" , \"client_email\" : \"client_email\" , \"client_id\" : \"client_id\" , \"auth_uri\" : \"auth_uri\" , \"token_uri\" : \"token_uri\" , \"auth_provider_x509_cert_url\" : \"auth_provider_x509_cert_url\" , \"client_x509_cert_url\" : \"client_x509_cert_url\" }) ) target_configs = BigQueryTargetConfigs ( schema = \"schema\" , project = \"project\" , credentials = credentials , ) Source code in prefect_dbt/cli/configs/bigquery.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 class BigQueryTargetConfigs ( TargetConfigs ): \"\"\" Target configs contain credentials and settings, specific to BigQuery. To find valid keys, head to the [BigQuery Profile]( https://docs.getdbt.com/reference/warehouse-profiles/bigquery-profile) page. Attributes: credentials: The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored BigQueryTargetConfigs: ```python from prefect_dbt.cli.configs import BigQueryTargetConfigs bigquery_target_configs = BigQueryTargetConfigs.load(\"BLOCK_NAME\") ``` Instantiate BigQueryTargetConfigs with service account file. ```python from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials(service_account_file=\"~/.secrets/gcp\") target_configs = BigQueryTargetConfigs( schema=\"schema\", project=\"project\", credentials=credentials, ) ``` Instantiate BigQueryTargetConfigs with service account info. ```python import json from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials( service_account_info=json.dumps({ \"type\": \"service_account\", \"project_id\": \"project_id\", \"private_key_id\": \"private_key_id\", \"private_key\": \"private_key\", \"client_email\": \"client_email\", \"client_id\": \"client_id\", \"auth_uri\": \"auth_uri\", \"token_uri\": \"token_uri\", \"auth_provider_x509_cert_url\": \"auth_provider_x509_cert_url\", \"client_x509_cert_url\": \"client_x509_cert_url\" }) ) target_configs = BigQueryTargetConfigs( schema=\"schema\", project=\"project\", credentials=credentials, ) ``` \"\"\" _block_type_name = \"dbt CLI BigQuery Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa _description = \"dbt CLI target configs containing credentials and settings, specific to BigQuery.\" # noqa type : Literal [ \"bigquery\" ] = \"bigquery\" project : Optional [ str ] = None credentials : GcpCredentials def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to BigQuery profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () if \"service_account_info\" in configs_json : configs_json [ \"method\" ] = \"service-account-json\" configs_json [ \"keyfile_json\" ] = configs_json . pop ( \"service_account_info\" ) else : configs_json [ \"method\" ] = \"service-account\" configs_json [ \"keyfile\" ] = str ( configs_json . pop ( \"service_account_file\" )) if \"project\" not in configs_json : raise ValueError ( \"The keyword, project, must be provided in either \" \"GcpCredentials or BigQueryTargetConfigs\" ) return configs_json get_configs Returns the dbt configs specific to BigQuery profile. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/bigquery.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to BigQuery profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () if \"service_account_info\" in configs_json : configs_json [ \"method\" ] = \"service-account-json\" configs_json [ \"keyfile_json\" ] = configs_json . pop ( \"service_account_info\" ) else : configs_json [ \"method\" ] = \"service-account\" configs_json [ \"keyfile\" ] = str ( configs_json . pop ( \"service_account_file\" )) if \"project\" not in configs_json : raise ValueError ( \"The keyword, project, must be provided in either \" \"GcpCredentials or BigQueryTargetConfigs\" ) return configs_json","title":"BigQuery"},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery","text":"Module containing models for BigQuery configs","title":"bigquery"},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs","text":"Target configs contain credentials and settings, specific to BigQuery. To find valid keys, head to the BigQuery Profile page. Attributes: Name Type Description credentials GcpCredentials The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored BigQueryTargetConfigs: from prefect_dbt.cli.configs import BigQueryTargetConfigs bigquery_target_configs = BigQueryTargetConfigs . load ( \"BLOCK_NAME\" ) Instantiate BigQueryTargetConfigs with service account file. from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials ( service_account_file = \"~/.secrets/gcp\" ) target_configs = BigQueryTargetConfigs ( schema = \"schema\" , project = \"project\" , credentials = credentials , ) Instantiate BigQueryTargetConfigs with service account info. import json from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials ( service_account_info = json . dumps ({ \"type\" : \"service_account\" , \"project_id\" : \"project_id\" , \"private_key_id\" : \"private_key_id\" , \"private_key\" : \"private_key\" , \"client_email\" : \"client_email\" , \"client_id\" : \"client_id\" , \"auth_uri\" : \"auth_uri\" , \"token_uri\" : \"token_uri\" , \"auth_provider_x509_cert_url\" : \"auth_provider_x509_cert_url\" , \"client_x509_cert_url\" : \"client_x509_cert_url\" }) ) target_configs = BigQueryTargetConfigs ( schema = \"schema\" , project = \"project\" , credentials = credentials , ) Source code in prefect_dbt/cli/configs/bigquery.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 class BigQueryTargetConfigs ( TargetConfigs ): \"\"\" Target configs contain credentials and settings, specific to BigQuery. To find valid keys, head to the [BigQuery Profile]( https://docs.getdbt.com/reference/warehouse-profiles/bigquery-profile) page. Attributes: credentials: The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored BigQueryTargetConfigs: ```python from prefect_dbt.cli.configs import BigQueryTargetConfigs bigquery_target_configs = BigQueryTargetConfigs.load(\"BLOCK_NAME\") ``` Instantiate BigQueryTargetConfigs with service account file. ```python from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials(service_account_file=\"~/.secrets/gcp\") target_configs = BigQueryTargetConfigs( schema=\"schema\", project=\"project\", credentials=credentials, ) ``` Instantiate BigQueryTargetConfigs with service account info. ```python import json from prefect_dbt.cli.configs import BigQueryTargetConfigs from prefect_gcp.credentials import GcpCredentials credentials = GcpCredentials( service_account_info=json.dumps({ \"type\": \"service_account\", \"project_id\": \"project_id\", \"private_key_id\": \"private_key_id\", \"private_key\": \"private_key\", \"client_email\": \"client_email\", \"client_id\": \"client_id\", \"auth_uri\": \"auth_uri\", \"token_uri\": \"token_uri\", \"auth_provider_x509_cert_url\": \"auth_provider_x509_cert_url\", \"client_x509_cert_url\": \"client_x509_cert_url\" }) ) target_configs = BigQueryTargetConfigs( schema=\"schema\", project=\"project\", credentials=credentials, ) ``` \"\"\" _block_type_name = \"dbt CLI BigQuery Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa _description = \"dbt CLI target configs containing credentials and settings, specific to BigQuery.\" # noqa type : Literal [ \"bigquery\" ] = \"bigquery\" project : Optional [ str ] = None credentials : GcpCredentials def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to BigQuery profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () if \"service_account_info\" in configs_json : configs_json [ \"method\" ] = \"service-account-json\" configs_json [ \"keyfile_json\" ] = configs_json . pop ( \"service_account_info\" ) else : configs_json [ \"method\" ] = \"service-account\" configs_json [ \"keyfile\" ] = str ( configs_json . pop ( \"service_account_file\" )) if \"project\" not in configs_json : raise ValueError ( \"The keyword, project, must be provided in either \" \"GcpCredentials or BigQueryTargetConfigs\" ) return configs_json","title":"BigQueryTargetConfigs"},{"location":"cli/configs/bigquery/#prefect_dbt.cli.configs.bigquery.BigQueryTargetConfigs.get_configs","text":"Returns the dbt configs specific to BigQuery profile. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/bigquery.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to BigQuery profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () if \"service_account_info\" in configs_json : configs_json [ \"method\" ] = \"service-account-json\" configs_json [ \"keyfile_json\" ] = configs_json . pop ( \"service_account_info\" ) else : configs_json [ \"method\" ] = \"service-account\" configs_json [ \"keyfile\" ] = str ( configs_json . pop ( \"service_account_file\" )) if \"project\" not in configs_json : raise ValueError ( \"The keyword, project, must be provided in either \" \"GcpCredentials or BigQueryTargetConfigs\" ) return configs_json","title":"get_configs()"},{"location":"cli/configs/postgres/","text":"prefect_dbt.cli.configs.postgres Module containing models for Postgres configs PostgresTargetConfigs Target configs contain credentials and settings, specific to Postgres. To find valid keys, head to the Postgres Profile page. Attributes: Name Type Description credentials DatabaseCredentials The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored PostgresTargetConfigs: from prefect_dbt.cli.configs import PostgresTargetConfigs postgres_target_configs = PostgresTargetConfigs . load ( \"BLOCK_NAME\" ) Instantiate PostgresTargetConfigs with DatabaseCredentials. from prefect_dbt.cli.configs import PostgresTargetConfigs from prefect_sqlalchemy import DatabaseCredentials , SyncDriver credentials = DatabaseCredentials ( driver = SyncDriver . POSTGRESQL_PSYCOPG2 , username = \"prefect\" , password = \"prefect_password\" , database = \"postgres\" , host = \"host\" , port = 8080 ) target_configs = PostgresTargetConfigs ( credentials = credentials , schema = \"schema\" ) Source code in prefect_dbt/cli/configs/postgres.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class PostgresTargetConfigs ( TargetConfigs ): \"\"\" Target configs contain credentials and settings, specific to Postgres. To find valid keys, head to the [Postgres Profile]( https://docs.getdbt.com/reference/warehouse-profiles/postgres-profile) page. Attributes: credentials: The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored PostgresTargetConfigs: ```python from prefect_dbt.cli.configs import PostgresTargetConfigs postgres_target_configs = PostgresTargetConfigs.load(\"BLOCK_NAME\") ``` Instantiate PostgresTargetConfigs with DatabaseCredentials. ```python from prefect_dbt.cli.configs import PostgresTargetConfigs from prefect_sqlalchemy import DatabaseCredentials, SyncDriver credentials = DatabaseCredentials( driver=SyncDriver.POSTGRESQL_PSYCOPG2, username=\"prefect\", password=\"prefect_password\", database=\"postgres\", host=\"host\", port=8080 ) target_configs = PostgresTargetConfigs(credentials=credentials, schema=\"schema\") ``` \"\"\" _block_type_name = \"dbt CLI Postgres Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa _description = \"dbt CLI target configs containing credentials and settings specific to Postgres.\" # noqa type : Literal [ \"postgres\" ] = \"postgres\" credentials : DatabaseCredentials def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Postgres profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () invalid_keys = [ \"driver\" , \"query\" , \"url\" , \"connect_args\" , \"_async_supported\" ] rename_keys = { \"database\" : \"dbname\" , \"username\" : \"user\" , \"password\" : \"password\" , \"host\" : \"host\" , \"port\" : \"port\" , } # get the keys from rendered url for invalid_key in invalid_keys + list ( rename_keys ): configs_json . pop ( invalid_key , None ) rendered_url = self . credentials . rendered_url for key in rename_keys : renamed_key = rename_keys [ key ] configs_json [ renamed_key ] = getattr ( rendered_url , key ) return configs_json get_configs Returns the dbt configs specific to Postgres profile. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/postgres.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Postgres profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () invalid_keys = [ \"driver\" , \"query\" , \"url\" , \"connect_args\" , \"_async_supported\" ] rename_keys = { \"database\" : \"dbname\" , \"username\" : \"user\" , \"password\" : \"password\" , \"host\" : \"host\" , \"port\" : \"port\" , } # get the keys from rendered url for invalid_key in invalid_keys + list ( rename_keys ): configs_json . pop ( invalid_key , None ) rendered_url = self . credentials . rendered_url for key in rename_keys : renamed_key = rename_keys [ key ] configs_json [ renamed_key ] = getattr ( rendered_url , key ) return configs_json","title":"Postgres"},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres","text":"Module containing models for Postgres configs","title":"postgres"},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs","text":"Target configs contain credentials and settings, specific to Postgres. To find valid keys, head to the Postgres Profile page. Attributes: Name Type Description credentials DatabaseCredentials The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored PostgresTargetConfigs: from prefect_dbt.cli.configs import PostgresTargetConfigs postgres_target_configs = PostgresTargetConfigs . load ( \"BLOCK_NAME\" ) Instantiate PostgresTargetConfigs with DatabaseCredentials. from prefect_dbt.cli.configs import PostgresTargetConfigs from prefect_sqlalchemy import DatabaseCredentials , SyncDriver credentials = DatabaseCredentials ( driver = SyncDriver . POSTGRESQL_PSYCOPG2 , username = \"prefect\" , password = \"prefect_password\" , database = \"postgres\" , host = \"host\" , port = 8080 ) target_configs = PostgresTargetConfigs ( credentials = credentials , schema = \"schema\" ) Source code in prefect_dbt/cli/configs/postgres.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class PostgresTargetConfigs ( TargetConfigs ): \"\"\" Target configs contain credentials and settings, specific to Postgres. To find valid keys, head to the [Postgres Profile]( https://docs.getdbt.com/reference/warehouse-profiles/postgres-profile) page. Attributes: credentials: The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored PostgresTargetConfigs: ```python from prefect_dbt.cli.configs import PostgresTargetConfigs postgres_target_configs = PostgresTargetConfigs.load(\"BLOCK_NAME\") ``` Instantiate PostgresTargetConfigs with DatabaseCredentials. ```python from prefect_dbt.cli.configs import PostgresTargetConfigs from prefect_sqlalchemy import DatabaseCredentials, SyncDriver credentials = DatabaseCredentials( driver=SyncDriver.POSTGRESQL_PSYCOPG2, username=\"prefect\", password=\"prefect_password\", database=\"postgres\", host=\"host\", port=8080 ) target_configs = PostgresTargetConfigs(credentials=credentials, schema=\"schema\") ``` \"\"\" _block_type_name = \"dbt CLI Postgres Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa _description = \"dbt CLI target configs containing credentials and settings specific to Postgres.\" # noqa type : Literal [ \"postgres\" ] = \"postgres\" credentials : DatabaseCredentials def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Postgres profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () invalid_keys = [ \"driver\" , \"query\" , \"url\" , \"connect_args\" , \"_async_supported\" ] rename_keys = { \"database\" : \"dbname\" , \"username\" : \"user\" , \"password\" : \"password\" , \"host\" : \"host\" , \"port\" : \"port\" , } # get the keys from rendered url for invalid_key in invalid_keys + list ( rename_keys ): configs_json . pop ( invalid_key , None ) rendered_url = self . credentials . rendered_url for key in rename_keys : renamed_key = rename_keys [ key ] configs_json [ renamed_key ] = getattr ( rendered_url , key ) return configs_json","title":"PostgresTargetConfigs"},{"location":"cli/configs/postgres/#prefect_dbt.cli.configs.postgres.PostgresTargetConfigs.get_configs","text":"Returns the dbt configs specific to Postgres profile. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/postgres.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Postgres profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () invalid_keys = [ \"driver\" , \"query\" , \"url\" , \"connect_args\" , \"_async_supported\" ] rename_keys = { \"database\" : \"dbname\" , \"username\" : \"user\" , \"password\" : \"password\" , \"host\" : \"host\" , \"port\" : \"port\" , } # get the keys from rendered url for invalid_key in invalid_keys + list ( rename_keys ): configs_json . pop ( invalid_key , None ) rendered_url = self . credentials . rendered_url for key in rename_keys : renamed_key = rename_keys [ key ] configs_json [ renamed_key ] = getattr ( rendered_url , key ) return configs_json","title":"get_configs()"},{"location":"cli/configs/snowflake/","text":"prefect_dbt.cli.configs.snowflake Module containing models for Snowflake configs SnowflakeTargetConfigs Target configs contain credentials and settings, specific to Snowflake. To find valid keys, head to the Snowflake Profile page. Attributes: Name Type Description credentials The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored SnowflakeTargetConfigs: from prefect_dbt.cli.configs import SnowflakeTargetConfigs snowflake_target_configs = SnowflakeTargetConfigs . load ( \"BLOCK_NAME\" ) Instantiate SnowflakeTargetConfigs. from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ) connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = credentials , ) target_configs = SnowflakeTargetConfigs ( connector = connector ) Source code in prefect_dbt/cli/configs/snowflake.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 class SnowflakeTargetConfigs ( TargetConfigs ): \"\"\" Target configs contain credentials and settings, specific to Snowflake. To find valid keys, head to the [Snowflake Profile]( https://docs.getdbt.com/reference/warehouse-profiles/snowflake-profile) page. Attributes: credentials: The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored SnowflakeTargetConfigs: ```python from prefect_dbt.cli.configs import SnowflakeTargetConfigs snowflake_target_configs = SnowflakeTargetConfigs.load(\"BLOCK_NAME\") ``` Instantiate SnowflakeTargetConfigs. ```python from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector credentials = SnowflakeCredentials( user=\"user\", password=\"password\", account=\"account.region.aws\", role=\"role\", ) connector = SnowflakeConnector( schema=\"public\", database=\"database\", warehouse=\"warehouse\", credentials=credentials, ) target_configs = SnowflakeTargetConfigs( connector=connector ) ``` \"\"\" _block_type_name = \"dbt CLI Snowflake Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa type : Literal [ \"snowflake\" ] = \"snowflake\" schema_ : Optional [ str ] = Field ( default = None , alias = \"schema\" ) connector : SnowflakeConnector def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Snowflake profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () return configs_json get_configs Returns the dbt configs specific to Snowflake profile. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/snowflake.py 71 72 73 74 75 76 77 78 79 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Snowflake profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () return configs_json","title":"Snowflake"},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake","text":"Module containing models for Snowflake configs","title":"snowflake"},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs","text":"Target configs contain credentials and settings, specific to Snowflake. To find valid keys, head to the Snowflake Profile page. Attributes: Name Type Description credentials The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored SnowflakeTargetConfigs: from prefect_dbt.cli.configs import SnowflakeTargetConfigs snowflake_target_configs = SnowflakeTargetConfigs . load ( \"BLOCK_NAME\" ) Instantiate SnowflakeTargetConfigs. from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector credentials = SnowflakeCredentials ( user = \"user\" , password = \"password\" , account = \"account.region.aws\" , role = \"role\" , ) connector = SnowflakeConnector ( schema = \"public\" , database = \"database\" , warehouse = \"warehouse\" , credentials = credentials , ) target_configs = SnowflakeTargetConfigs ( connector = connector ) Source code in prefect_dbt/cli/configs/snowflake.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 class SnowflakeTargetConfigs ( TargetConfigs ): \"\"\" Target configs contain credentials and settings, specific to Snowflake. To find valid keys, head to the [Snowflake Profile]( https://docs.getdbt.com/reference/warehouse-profiles/snowflake-profile) page. Attributes: credentials: The credentials to use to authenticate; if there are duplicate keys between credentials and TargetConfigs, e.g. schema, an error will be raised. Examples: Load stored SnowflakeTargetConfigs: ```python from prefect_dbt.cli.configs import SnowflakeTargetConfigs snowflake_target_configs = SnowflakeTargetConfigs.load(\"BLOCK_NAME\") ``` Instantiate SnowflakeTargetConfigs. ```python from prefect_dbt.cli.configs import SnowflakeTargetConfigs from prefect_snowflake.credentials import SnowflakeCredentials from prefect_snowflake.database import SnowflakeConnector credentials = SnowflakeCredentials( user=\"user\", password=\"password\", account=\"account.region.aws\", role=\"role\", ) connector = SnowflakeConnector( schema=\"public\", database=\"database\", warehouse=\"warehouse\", credentials=credentials, ) target_configs = SnowflakeTargetConfigs( connector=connector ) ``` \"\"\" _block_type_name = \"dbt CLI Snowflake Target Configs\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa type : Literal [ \"snowflake\" ] = \"snowflake\" schema_ : Optional [ str ] = Field ( default = None , alias = \"schema\" ) connector : SnowflakeConnector def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Snowflake profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () return configs_json","title":"SnowflakeTargetConfigs"},{"location":"cli/configs/snowflake/#prefect_dbt.cli.configs.snowflake.SnowflakeTargetConfigs.get_configs","text":"Returns the dbt configs specific to Snowflake profile. Returns: Type Description Dict [ str , Any ] A configs JSON. Source code in prefect_dbt/cli/configs/snowflake.py 71 72 73 74 75 76 77 78 79 def get_configs ( self ) -> Dict [ str , Any ]: \"\"\" Returns the dbt configs specific to Snowflake profile. Returns: A configs JSON. \"\"\" configs_json = super () . get_configs () return configs_json","title":"get_configs()"},{"location":"cloud/clients/","text":"prefect_dbt.cloud.clients Module containing clients for interacting with the dbt Cloud API DbtCloudAdministrativeClient Client for interacting with the dbt cloud Administrative API. Parameters: Name Type Description Default api_key str API key to authenticate with the dbt Cloud administrative API. required account_id int ID of dbt Cloud account with which to interact. required domain str Domain at which the dbt Cloud API is hosted. required Source code in prefect_dbt/cloud/clients.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 class DbtCloudAdministrativeClient : \"\"\" Client for interacting with the dbt cloud Administrative API. Args: api_key: API key to authenticate with the dbt Cloud administrative API. account_id: ID of dbt Cloud account with which to interact. domain: Domain at which the dbt Cloud API is hosted. \"\"\" def __init__ ( self , api_key : str , account_id : int , domain : str ): self . _closed = False self . _started = False self . _admin_client = AsyncClient ( headers = { \"Authorization\" : f \"Bearer { api_key } \" , \"user-agent\" : f \"prefect- { prefect . __version__ } \" , }, base_url = f \"https:// { domain } /api/v2/accounts/ { account_id } \" , ) async def call_endpoint ( self , http_method : str , path : str , params : Optional [ Dict [ str , Any ]] = None , json : Optional [ Dict [ str , Any ]] = None , ) -> Response : \"\"\" Call an endpoint in the dbt Cloud API. Args: path: The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. http_method: HTTP method to call on the endpoint. params: Query parameters to include in the request. json: JSON serializable body to send in the request. Returns: The response from the dbt Cloud administrative API. \"\"\" response = await self . _admin_client . request ( method = http_method , url = path , params = params , json = json ) response . raise_for_status () return response async def trigger_job_run ( self , job_id : int , options : Optional [ TriggerJobRunOptions ] = None ) -> Response : \"\"\" Sends a request to the [trigger job run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Jobs/operation/triggerRun) to initiate a job run. Args: job_id: The ID of the job to trigger. options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa if options is None : options = TriggerJobRunOptions () return await self . call_endpoint ( path = f \"/jobs/ { job_id } /run/\" , http_method = \"POST\" , json = options . dict ( exclude_none = True ), ) async def get_run ( self , run_id : int ) -> Response : \"\"\" Sends a request to the [get run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getRunById) to get details about a job run. Args: run_id: The ID of the run to get details for. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa return await self . call_endpoint ( path = f \"/runs/ { run_id } /\" , http_method = \"GET\" ) async def list_run_artifacts ( self , run_id : int , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [list run artifacts endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/listArtifactsByRunId) to fetch a list of paths of artifacts generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/\" , http_method = \"GET\" , params = params ) async def get_run_artifact ( self , run_id : int , path : str , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [get run artifact endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getArtifactsByRunId) to fetch an artifact generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. path: The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/ { path } \" , http_method = \"GET\" , params = params ) async def __aenter__ ( self ): if self . _closed : raise RuntimeError ( \"The client cannot be started again after it has been closed.\" ) if self . _started : raise RuntimeError ( \"The client cannot be started more than once.\" ) self . _started = True return self async def __aexit__ ( self , * exc ): self . _closed = True await self . _admin_client . __aexit__ () call_endpoint async Call an endpoint in the dbt Cloud API. Parameters: Name Type Description Default path str The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. required http_method str HTTP method to call on the endpoint. required params Optional [ Dict [ str , Any ]] Query parameters to include in the request. None json Optional [ Dict [ str , Any ]] JSON serializable body to send in the request. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 async def call_endpoint ( self , http_method : str , path : str , params : Optional [ Dict [ str , Any ]] = None , json : Optional [ Dict [ str , Any ]] = None , ) -> Response : \"\"\" Call an endpoint in the dbt Cloud API. Args: path: The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. http_method: HTTP method to call on the endpoint. params: Query parameters to include in the request. json: JSON serializable body to send in the request. Returns: The response from the dbt Cloud administrative API. \"\"\" response = await self . _admin_client . request ( method = http_method , url = path , params = params , json = json ) response . raise_for_status () return response get_run async Sends a request to the get run endpoint to get details about a job run. Parameters: Name Type Description Default run_id int The ID of the run to get details for. required Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 83 84 85 86 87 88 89 90 91 92 93 94 async def get_run ( self , run_id : int ) -> Response : \"\"\" Sends a request to the [get run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getRunById) to get details about a job run. Args: run_id: The ID of the run to get details for. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa return await self . call_endpoint ( path = f \"/runs/ { run_id } /\" , http_method = \"GET\" ) get_run_artifact async Sends a request to the get run artifact endpoint to fetch an artifact generated for a completed run. Parameters: Name Type Description Default run_id int The ID of the run to list run artifacts for. required path str The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 async def get_run_artifact ( self , run_id : int , path : str , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [get run artifact endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getArtifactsByRunId) to fetch an artifact generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. path: The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/ { path } \" , http_method = \"GET\" , params = params ) list_run_artifacts async Sends a request to the list run artifacts endpoint to fetch a list of paths of artifacts generated for a completed run. Parameters: Name Type Description Default run_id int The ID of the run to list run artifacts for. required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 async def list_run_artifacts ( self , run_id : int , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [list run artifacts endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/listArtifactsByRunId) to fetch a list of paths of artifacts generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/\" , http_method = \"GET\" , params = params ) trigger_job_run async Sends a request to the trigger job run endpoint to initiate a job run. Parameters: Name Type Description Default job_id int The ID of the job to trigger. required options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 async def trigger_job_run ( self , job_id : int , options : Optional [ TriggerJobRunOptions ] = None ) -> Response : \"\"\" Sends a request to the [trigger job run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Jobs/operation/triggerRun) to initiate a job run. Args: job_id: The ID of the job to trigger. options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa if options is None : options = TriggerJobRunOptions () return await self . call_endpoint ( path = f \"/jobs/ { job_id } /run/\" , http_method = \"POST\" , json = options . dict ( exclude_none = True ), )","title":"Clients"},{"location":"cloud/clients/#prefect_dbt.cloud.clients","text":"Module containing clients for interacting with the dbt Cloud API","title":"clients"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient","text":"Client for interacting with the dbt cloud Administrative API. Parameters: Name Type Description Default api_key str API key to authenticate with the dbt Cloud administrative API. required account_id int ID of dbt Cloud account with which to interact. required domain str Domain at which the dbt Cloud API is hosted. required Source code in prefect_dbt/cloud/clients.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 class DbtCloudAdministrativeClient : \"\"\" Client for interacting with the dbt cloud Administrative API. Args: api_key: API key to authenticate with the dbt Cloud administrative API. account_id: ID of dbt Cloud account with which to interact. domain: Domain at which the dbt Cloud API is hosted. \"\"\" def __init__ ( self , api_key : str , account_id : int , domain : str ): self . _closed = False self . _started = False self . _admin_client = AsyncClient ( headers = { \"Authorization\" : f \"Bearer { api_key } \" , \"user-agent\" : f \"prefect- { prefect . __version__ } \" , }, base_url = f \"https:// { domain } /api/v2/accounts/ { account_id } \" , ) async def call_endpoint ( self , http_method : str , path : str , params : Optional [ Dict [ str , Any ]] = None , json : Optional [ Dict [ str , Any ]] = None , ) -> Response : \"\"\" Call an endpoint in the dbt Cloud API. Args: path: The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. http_method: HTTP method to call on the endpoint. params: Query parameters to include in the request. json: JSON serializable body to send in the request. Returns: The response from the dbt Cloud administrative API. \"\"\" response = await self . _admin_client . request ( method = http_method , url = path , params = params , json = json ) response . raise_for_status () return response async def trigger_job_run ( self , job_id : int , options : Optional [ TriggerJobRunOptions ] = None ) -> Response : \"\"\" Sends a request to the [trigger job run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Jobs/operation/triggerRun) to initiate a job run. Args: job_id: The ID of the job to trigger. options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa if options is None : options = TriggerJobRunOptions () return await self . call_endpoint ( path = f \"/jobs/ { job_id } /run/\" , http_method = \"POST\" , json = options . dict ( exclude_none = True ), ) async def get_run ( self , run_id : int ) -> Response : \"\"\" Sends a request to the [get run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getRunById) to get details about a job run. Args: run_id: The ID of the run to get details for. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa return await self . call_endpoint ( path = f \"/runs/ { run_id } /\" , http_method = \"GET\" ) async def list_run_artifacts ( self , run_id : int , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [list run artifacts endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/listArtifactsByRunId) to fetch a list of paths of artifacts generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/\" , http_method = \"GET\" , params = params ) async def get_run_artifact ( self , run_id : int , path : str , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [get run artifact endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getArtifactsByRunId) to fetch an artifact generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. path: The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/ { path } \" , http_method = \"GET\" , params = params ) async def __aenter__ ( self ): if self . _closed : raise RuntimeError ( \"The client cannot be started again after it has been closed.\" ) if self . _started : raise RuntimeError ( \"The client cannot be started more than once.\" ) self . _started = True return self async def __aexit__ ( self , * exc ): self . _closed = True await self . _admin_client . __aexit__ ()","title":"DbtCloudAdministrativeClient"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.call_endpoint","text":"Call an endpoint in the dbt Cloud API. Parameters: Name Type Description Default path str The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. required http_method str HTTP method to call on the endpoint. required params Optional [ Dict [ str , Any ]] Query parameters to include in the request. None json Optional [ Dict [ str , Any ]] JSON serializable body to send in the request. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 async def call_endpoint ( self , http_method : str , path : str , params : Optional [ Dict [ str , Any ]] = None , json : Optional [ Dict [ str , Any ]] = None , ) -> Response : \"\"\" Call an endpoint in the dbt Cloud API. Args: path: The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. http_method: HTTP method to call on the endpoint. params: Query parameters to include in the request. json: JSON serializable body to send in the request. Returns: The response from the dbt Cloud administrative API. \"\"\" response = await self . _admin_client . request ( method = http_method , url = path , params = params , json = json ) response . raise_for_status () return response","title":"call_endpoint()"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.get_run","text":"Sends a request to the get run endpoint to get details about a job run. Parameters: Name Type Description Default run_id int The ID of the run to get details for. required Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 83 84 85 86 87 88 89 90 91 92 93 94 async def get_run ( self , run_id : int ) -> Response : \"\"\" Sends a request to the [get run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getRunById) to get details about a job run. Args: run_id: The ID of the run to get details for. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa return await self . call_endpoint ( path = f \"/runs/ { run_id } /\" , http_method = \"GET\" )","title":"get_run()"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.get_run_artifact","text":"Sends a request to the get run artifact endpoint to fetch an artifact generated for a completed run. Parameters: Name Type Description Default run_id int The ID of the run to list run artifacts for. required path str The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 async def get_run_artifact ( self , run_id : int , path : str , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [get run artifact endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/getArtifactsByRunId) to fetch an artifact generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. path: The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/ { path } \" , http_method = \"GET\" , params = params )","title":"get_run_artifact()"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.list_run_artifacts","text":"Sends a request to the list run artifacts endpoint to fetch a list of paths of artifacts generated for a completed run. Parameters: Name Type Description Default run_id int The ID of the run to list run artifacts for. required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 async def list_run_artifacts ( self , run_id : int , step : Optional [ int ] = None ) -> Response : \"\"\" Sends a request to the [list run artifacts endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Runs/operation/listArtifactsByRunId) to fetch a list of paths of artifacts generated for a completed run. Args: run_id: The ID of the run to list run artifacts for. step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa params = { \"step\" : step } if step else None return await self . call_endpoint ( path = f \"/runs/ { run_id } /artifacts/\" , http_method = \"GET\" , params = params )","title":"list_run_artifacts()"},{"location":"cloud/clients/#prefect_dbt.cloud.clients.DbtCloudAdministrativeClient.trigger_job_run","text":"Sends a request to the trigger job run endpoint to initiate a job run. Parameters: Name Type Description Default job_id int The ID of the job to trigger. required options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None Returns: Type Description Response The response from the dbt Cloud administrative API. Source code in prefect_dbt/cloud/clients.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 async def trigger_job_run ( self , job_id : int , options : Optional [ TriggerJobRunOptions ] = None ) -> Response : \"\"\" Sends a request to the [trigger job run endpoint](https://docs.getdbt.com/dbt-cloud/api-v2#tag/Jobs/operation/triggerRun) to initiate a job run. Args: job_id: The ID of the job to trigger. options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. Returns: The response from the dbt Cloud administrative API. \"\"\" # noqa if options is None : options = TriggerJobRunOptions () return await self . call_endpoint ( path = f \"/jobs/ { job_id } /run/\" , http_method = \"POST\" , json = options . dict ( exclude_none = True ), )","title":"trigger_job_run()"},{"location":"cloud/credentials/","text":"prefect_dbt.cloud.credentials Module containing credentials for interacting with dbt Cloud DbtCloudCredentials Credentials block for credential use across dbt Cloud tasks and flows. Attributes: Name Type Description api_key SecretStr API key to authenticate with the dbt Cloud administrative API. Refer to the Authentication docs for retrieving the API key. account_id int ID of dbt Cloud account with which to interact. domain Optional [ str ] Domain at which the dbt Cloud API is hosted. Examples: Load stored dbt Cloud credentials: from prefect_dbt.cloud import DbtCloudCredentials dbt_cloud_credentials = DbtCloudCredentials . load ( \"BLOCK_NAME\" ) Use DbtCloudCredentials instance to trigger a job run: from prefect_dbt.cloud import DbtCloudCredentials credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) async with dbt_cloud_credentials . get_administrative_client () as client : client . trigger_job_run ( job_id = 1 ) Load saved dbt Cloud credentials within a flow: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow (): credentials = DbtCloudCredentials . load ( \"my-dbt-credentials\" ) trigger_dbt_cloud_job_run ( dbt_cloud_credentials = credentials , job_id = 1 ) trigger_dbt_cloud_job_run_flow () Source code in prefect_dbt/cloud/credentials.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class DbtCloudCredentials ( Block ): \"\"\" Credentials block for credential use across dbt Cloud tasks and flows. Attributes: api_key (SecretStr): API key to authenticate with the dbt Cloud administrative API. Refer to the [Authentication docs]( https://docs.getdbt.com/dbt-cloud/api-v2#section/Authentication) for retrieving the API key. account_id (int): ID of dbt Cloud account with which to interact. domain (Optional[str]): Domain at which the dbt Cloud API is hosted. Examples: Load stored dbt Cloud credentials: ```python from prefect_dbt.cloud import DbtCloudCredentials dbt_cloud_credentials = DbtCloudCredentials.load(\"BLOCK_NAME\") ``` Use DbtCloudCredentials instance to trigger a job run: ```python from prefect_dbt.cloud import DbtCloudCredentials credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) async with dbt_cloud_credentials.get_administrative_client() as client: client.trigger_job_run(job_id=1) ``` Load saved dbt Cloud credentials within a flow: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow(): credentials = DbtCloudCredentials.load(\"my-dbt-credentials\") trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1) trigger_dbt_cloud_job_run_flow() ``` \"\"\" _block_type_name = \"dbt Cloud Credentials\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa api_key : SecretStr account_id : int domain : str = \"cloud.getdbt.com\" def get_administrative_client ( self ): \"\"\" Returns a newly instantiated client for working with the dbt Cloud administrative API. \"\"\" return DbtCloudAdministrativeClient ( api_key = self . api_key . get_secret_value (), account_id = self . account_id , domain = self . domain , ) get_administrative_client Returns a newly instantiated client for working with the dbt Cloud administrative API. Source code in prefect_dbt/cloud/credentials.py 62 63 64 65 66 67 68 69 70 71 def get_administrative_client ( self ): \"\"\" Returns a newly instantiated client for working with the dbt Cloud administrative API. \"\"\" return DbtCloudAdministrativeClient ( api_key = self . api_key . get_secret_value (), account_id = self . account_id , domain = self . domain , )","title":"Credentials"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials","text":"Module containing credentials for interacting with dbt Cloud","title":"credentials"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials","text":"Credentials block for credential use across dbt Cloud tasks and flows. Attributes: Name Type Description api_key SecretStr API key to authenticate with the dbt Cloud administrative API. Refer to the Authentication docs for retrieving the API key. account_id int ID of dbt Cloud account with which to interact. domain Optional [ str ] Domain at which the dbt Cloud API is hosted. Examples: Load stored dbt Cloud credentials: from prefect_dbt.cloud import DbtCloudCredentials dbt_cloud_credentials = DbtCloudCredentials . load ( \"BLOCK_NAME\" ) Use DbtCloudCredentials instance to trigger a job run: from prefect_dbt.cloud import DbtCloudCredentials credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) async with dbt_cloud_credentials . get_administrative_client () as client : client . trigger_job_run ( job_id = 1 ) Load saved dbt Cloud credentials within a flow: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow (): credentials = DbtCloudCredentials . load ( \"my-dbt-credentials\" ) trigger_dbt_cloud_job_run ( dbt_cloud_credentials = credentials , job_id = 1 ) trigger_dbt_cloud_job_run_flow () Source code in prefect_dbt/cloud/credentials.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class DbtCloudCredentials ( Block ): \"\"\" Credentials block for credential use across dbt Cloud tasks and flows. Attributes: api_key (SecretStr): API key to authenticate with the dbt Cloud administrative API. Refer to the [Authentication docs]( https://docs.getdbt.com/dbt-cloud/api-v2#section/Authentication) for retrieving the API key. account_id (int): ID of dbt Cloud account with which to interact. domain (Optional[str]): Domain at which the dbt Cloud API is hosted. Examples: Load stored dbt Cloud credentials: ```python from prefect_dbt.cloud import DbtCloudCredentials dbt_cloud_credentials = DbtCloudCredentials.load(\"BLOCK_NAME\") ``` Use DbtCloudCredentials instance to trigger a job run: ```python from prefect_dbt.cloud import DbtCloudCredentials credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) async with dbt_cloud_credentials.get_administrative_client() as client: client.trigger_job_run(job_id=1) ``` Load saved dbt Cloud credentials within a flow: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow(): credentials = DbtCloudCredentials.load(\"my-dbt-credentials\") trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1) trigger_dbt_cloud_job_run_flow() ``` \"\"\" _block_type_name = \"dbt Cloud Credentials\" _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/5zE9lxfzBHjw3tnEup4wWL/9a001902ed43a84c6c96d23b24622e19/dbt-bit_tm.png?h=250\" # noqa api_key : SecretStr account_id : int domain : str = \"cloud.getdbt.com\" def get_administrative_client ( self ): \"\"\" Returns a newly instantiated client for working with the dbt Cloud administrative API. \"\"\" return DbtCloudAdministrativeClient ( api_key = self . api_key . get_secret_value (), account_id = self . account_id , domain = self . domain , )","title":"DbtCloudCredentials"},{"location":"cloud/credentials/#prefect_dbt.cloud.credentials.DbtCloudCredentials.get_administrative_client","text":"Returns a newly instantiated client for working with the dbt Cloud administrative API. Source code in prefect_dbt/cloud/credentials.py 62 63 64 65 66 67 68 69 70 71 def get_administrative_client ( self ): \"\"\" Returns a newly instantiated client for working with the dbt Cloud administrative API. \"\"\" return DbtCloudAdministrativeClient ( api_key = self . api_key . get_secret_value (), account_id = self . account_id , domain = self . domain , )","title":"get_administrative_client()"},{"location":"cloud/jobs/","text":"prefect_dbt.cloud.jobs Module containing tasks and flows for interacting with dbt Cloud jobs DbtCloudJobRunTriggerFailed Raised when a dbt Cloud job trigger fails Source code in prefect_dbt/cloud/jobs.py 20 21 22 23 class DbtCloudJobRunTriggerFailed ( Exception ): \"\"\"Raised when a dbt Cloud job trigger fails\"\"\" pass get_run_id Task that extracts the run ID from a trigger job run API response, This task is mainly used to maintain dependency tracking between the trigger_dbt_cloud_job_run task and downstream tasks/flows that use the run ID. Parameters: Name Type Description Default obj Dict The JSON body from the trigger job run response. required Example from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run , get_run_id @flow def trigger_run_and_get_id (): dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) triggered_run_data = trigger_dbt_cloud_job_run ( dbt_cloud_credentials = dbt_cloud_credentials , job_id = job_id , options = trigger_job_run_options , ) run_id = get_run_id . submit ( triggered_run_data ) return run_id trigger_run_and_get_id () Source code in prefect_dbt/cloud/jobs.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 @task ( name = \"Get dbt Cloud job run ID\" , description = \"Extracts the run ID from a trigger job run API response\" , ) def get_run_id ( obj : Dict ): \"\"\" Task that extracts the run ID from a trigger job run API response, This task is mainly used to maintain dependency tracking between the `trigger_dbt_cloud_job_run` task and downstream tasks/flows that use the run ID. Args: obj: The JSON body from the trigger job run response. Example: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run, get_run_id @flow def trigger_run_and_get_id(): dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ) triggered_run_data = trigger_dbt_cloud_job_run( dbt_cloud_credentials=dbt_cloud_credentials, job_id=job_id, options=trigger_job_run_options, ) run_id = get_run_id.submit(triggered_run_data) return run_id trigger_run_and_get_id() ``` \"\"\" id = obj . get ( \"id\" ) if id is None : raise RuntimeError ( \"Unable to determine run ID for triggered job.\" ) return id trigger_dbt_cloud_job_run async A task to trigger a dbt Cloud job run. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required job_id int The ID of the job to trigger. required options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None Returns: Type Description Dict The run data returned from the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) trigger_dbt_cloud_job_run ( dbt_cloud_credentials = credentials , job_id = 1 ) trigger_dbt_cloud_job_run_flow () Trigger a dbt Cloud job run with overrides: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run from prefect_dbt.cloud.models import TriggerJobRunOptions @flow def trigger_dbt_cloud_job_run_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) trigger_dbt_cloud_job_run ( dbt_cloud_credentials = credentials , job_id = 1 , options = TriggerJobRunOptions ( git_branch = \"staging\" , schema_override = \"dbt_cloud_pr_123\" , dbt_version_override = \"0.18.0\" , target_name_override = \"staging\" , timeout_seconds_override = 3000 , generate_docs_override = True , threads_override = 8 , steps_override = [ \"dbt seed\" , \"dbt run --fail-fast\" , \"dbt test --fail fast\" , ], ), ) trigger_dbt_cloud_job_run () Source code in prefect_dbt/cloud/jobs.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 @task ( name = \"Trigger dbt Cloud job run\" , description = \"Triggers a dbt Cloud job run for the job \" \"with the given job_id and optional overrides.\" , retries = 3 , retry_delay_seconds = 10 , ) async def trigger_dbt_cloud_job_run ( dbt_cloud_credentials : DbtCloudCredentials , job_id : int , options : Optional [ TriggerJobRunOptions ] = None , ) -> Dict : \"\"\" A task to trigger a dbt Cloud job run. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. job_id: The ID of the job to trigger. options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. Returns: The run data returned from the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1) trigger_dbt_cloud_job_run_flow() ``` Trigger a dbt Cloud job run with overrides: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run from prefect_dbt.cloud.models import TriggerJobRunOptions @flow def trigger_dbt_cloud_job_run_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) trigger_dbt_cloud_job_run( dbt_cloud_credentials=credentials, job_id=1, options=TriggerJobRunOptions( git_branch=\"staging\", schema_override=\"dbt_cloud_pr_123\", dbt_version_override=\"0.18.0\", target_name_override=\"staging\", timeout_seconds_override=3000, generate_docs_override=True, threads_override=8, steps_override=[ \"dbt seed\", \"dbt run --fail-fast\", \"dbt test --fail fast\", ], ), ) trigger_dbt_cloud_job_run() ``` \"\"\" # noqa logger = get_run_logger () logger . info ( f \"Triggering run for job with ID { job_id } \" ) try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . trigger_job_run ( job_id = job_id , options = options ) except HTTPStatusError as ex : raise DbtCloudJobRunTriggerFailed ( extract_user_message ( ex )) from ex run_data = response . json ()[ \"data\" ] logger . info ( f \"Run successfully triggered for job with ID { job_id } . \" \"You can view the status of this run at \" f \"https:// { dbt_cloud_credentials . domain } /#/accounts/\" f \" { dbt_cloud_credentials . account_id } /projects/ { run_data [ 'project_id' ] } /\" f \"runs/ { run_data [ 'id' ] } /\" ) return run_data trigger_dbt_cloud_job_run_and_wait_for_completion async Flow that triggers a job run and waits for the triggered run to complete. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required job_id int The ID of the job to trigger. required trigger_job_run_options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None max_wait_seconds int Maximum number of seconds to wait for job to complete 900 poll_frequency_seconds int Number of seconds to wait in between checks for run completion. 10 Raises: Type Description DbtCloudJobRunCancelled The triggered dbt Cloud job run was cancelled. DbtCloudJobRunFailed The triggered dbt Cloud job run failed. RuntimeError The triggered dbt Cloud job run ended in an unexpected state. Returns: Type Description Dict The run data returned by the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job and wait for completion as a stand alone flow: import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion asyncio . run ( trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 ) ) Trigger a dbt Cloud job and wait for completion as a sub-flow: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion @flow def my_flow (): ... run_result = trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 ) ... my_flow () Trigger a dbt Cloud job with overrides: import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion from prefect_dbt.cloud.models import TriggerJobRunOptions asyncio . run ( trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 , trigger_job_run_options = TriggerJobRunOptions ( git_branch = \"staging\" , schema_override = \"dbt_cloud_pr_123\" , dbt_version_override = \"0.18.0\" , target_name_override = \"staging\" , timeout_seconds_override = 3000 , generate_docs_override = True , threads_override = 8 , steps_override = [ \"dbt seed\" , \"dbt run --fail-fast\" , \"dbt test --fail fast\" , ], ), ) ) Source code in prefect_dbt/cloud/jobs.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 @flow ( name = \"Trigger dbt Cloud job run and wait for completion\" , description = \"Triggers a dbt Cloud job run and waits for the\" \"triggered run to complete.\" , ) async def trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials : DbtCloudCredentials , job_id : int , trigger_job_run_options : Optional [ TriggerJobRunOptions ] = None , max_wait_seconds : int = 900 , poll_frequency_seconds : int = 10 , ) -> Dict : \"\"\" Flow that triggers a job run and waits for the triggered run to complete. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. job_id: The ID of the job to trigger. trigger_job_run_options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. max_wait_seconds: Maximum number of seconds to wait for job to complete poll_frequency_seconds: Number of seconds to wait in between checks for run completion. Raises: DbtCloudJobRunCancelled: The triggered dbt Cloud job run was cancelled. DbtCloudJobRunFailed: The triggered dbt Cloud job run failed. RuntimeError: The triggered dbt Cloud job run ended in an unexpected state. Returns: The run data returned by the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job and wait for completion as a stand alone flow: ```python import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion asyncio.run( trigger_dbt_cloud_job_run_and_wait_for_completion( dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ), job_id=1 ) ) ``` Trigger a dbt Cloud job and wait for completion as a sub-flow: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion @flow def my_flow(): ... run_result = trigger_dbt_cloud_job_run_and_wait_for_completion( dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ), job_id=1 ) ... my_flow() ``` Trigger a dbt Cloud job with overrides: ```python import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion from prefect_dbt.cloud.models import TriggerJobRunOptions asyncio.run( trigger_dbt_cloud_job_run_and_wait_for_completion( dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ), job_id=1, trigger_job_run_options=TriggerJobRunOptions( git_branch=\"staging\", schema_override=\"dbt_cloud_pr_123\", dbt_version_override=\"0.18.0\", target_name_override=\"staging\", timeout_seconds_override=3000, generate_docs_override=True, threads_override=8, steps_override=[ \"dbt seed\", \"dbt run --fail-fast\", \"dbt test --fail fast\", ], ), ) ) ``` \"\"\" # noqa logger = get_run_logger () triggered_run_data_future = await trigger_dbt_cloud_job_run . submit ( dbt_cloud_credentials = dbt_cloud_credentials , job_id = job_id , options = trigger_job_run_options , ) run_id_future = get_run_id . submit ( triggered_run_data_future ) final_run_status , run_data = await wait_for_dbt_cloud_job_run ( run_id = run_id_future , dbt_cloud_credentials = dbt_cloud_credentials , max_wait_seconds = max_wait_seconds , poll_frequency_seconds = poll_frequency_seconds , ) if final_run_status == DbtCloudJobRunStatus . SUCCESS : try : list_run_artifacts_future = await list_dbt_cloud_run_artifacts . submit ( dbt_cloud_credentials = dbt_cloud_credentials , run_id = run_id_future , ) run_data [ \"artifact_paths\" ] = await list_run_artifacts_future . result () except DbtCloudListRunArtifactsFailed as ex : logger . warning ( \"Unable to retrieve artifacts for job run with ID %s . Reason: %s \" , run_id_future . result (), ex , ) logger . info ( \"dbt Cloud job run with ID %s completed successfully!\" , run_id_future . result (), ) return run_data elif final_run_status == DbtCloudJobRunStatus . CANCELLED : raise DbtCloudJobRunCancelled ( f \"Triggered job run with ID { run_id_future . result () } was cancelled.\" ) elif final_run_status == DbtCloudJobRunStatus . FAILED : raise DbtCloudJobRunFailed ( f \"Triggered job run with ID: { run_id_future . result () } failed.\" ) else : raise RuntimeError ( f \"Triggered job run with ID: { run_id_future . result () } ended with unexpected\" \"status {final_run_status.value} .\" )","title":"Jobs"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs","text":"Module containing tasks and flows for interacting with dbt Cloud jobs","title":"jobs"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.DbtCloudJobRunTriggerFailed","text":"Raised when a dbt Cloud job trigger fails Source code in prefect_dbt/cloud/jobs.py 20 21 22 23 class DbtCloudJobRunTriggerFailed ( Exception ): \"\"\"Raised when a dbt Cloud job trigger fails\"\"\" pass","title":"DbtCloudJobRunTriggerFailed"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.get_run_id","text":"Task that extracts the run ID from a trigger job run API response, This task is mainly used to maintain dependency tracking between the trigger_dbt_cloud_job_run task and downstream tasks/flows that use the run ID. Parameters: Name Type Description Default obj Dict The JSON body from the trigger job run response. required Example from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run , get_run_id @flow def trigger_run_and_get_id (): dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) triggered_run_data = trigger_dbt_cloud_job_run ( dbt_cloud_credentials = dbt_cloud_credentials , job_id = job_id , options = trigger_job_run_options , ) run_id = get_run_id . submit ( triggered_run_data ) return run_id trigger_run_and_get_id () Source code in prefect_dbt/cloud/jobs.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 @task ( name = \"Get dbt Cloud job run ID\" , description = \"Extracts the run ID from a trigger job run API response\" , ) def get_run_id ( obj : Dict ): \"\"\" Task that extracts the run ID from a trigger job run API response, This task is mainly used to maintain dependency tracking between the `trigger_dbt_cloud_job_run` task and downstream tasks/flows that use the run ID. Args: obj: The JSON body from the trigger job run response. Example: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run, get_run_id @flow def trigger_run_and_get_id(): dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ) triggered_run_data = trigger_dbt_cloud_job_run( dbt_cloud_credentials=dbt_cloud_credentials, job_id=job_id, options=trigger_job_run_options, ) run_id = get_run_id.submit(triggered_run_data) return run_id trigger_run_and_get_id() ``` \"\"\" id = obj . get ( \"id\" ) if id is None : raise RuntimeError ( \"Unable to determine run ID for triggered job.\" ) return id","title":"get_run_id()"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.trigger_dbt_cloud_job_run","text":"A task to trigger a dbt Cloud job run. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required job_id int The ID of the job to trigger. required options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None Returns: Type Description Dict The run data returned from the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) trigger_dbt_cloud_job_run ( dbt_cloud_credentials = credentials , job_id = 1 ) trigger_dbt_cloud_job_run_flow () Trigger a dbt Cloud job run with overrides: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run from prefect_dbt.cloud.models import TriggerJobRunOptions @flow def trigger_dbt_cloud_job_run_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) trigger_dbt_cloud_job_run ( dbt_cloud_credentials = credentials , job_id = 1 , options = TriggerJobRunOptions ( git_branch = \"staging\" , schema_override = \"dbt_cloud_pr_123\" , dbt_version_override = \"0.18.0\" , target_name_override = \"staging\" , timeout_seconds_override = 3000 , generate_docs_override = True , threads_override = 8 , steps_override = [ \"dbt seed\" , \"dbt run --fail-fast\" , \"dbt test --fail fast\" , ], ), ) trigger_dbt_cloud_job_run () Source code in prefect_dbt/cloud/jobs.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 @task ( name = \"Trigger dbt Cloud job run\" , description = \"Triggers a dbt Cloud job run for the job \" \"with the given job_id and optional overrides.\" , retries = 3 , retry_delay_seconds = 10 , ) async def trigger_dbt_cloud_job_run ( dbt_cloud_credentials : DbtCloudCredentials , job_id : int , options : Optional [ TriggerJobRunOptions ] = None , ) -> Dict : \"\"\" A task to trigger a dbt Cloud job run. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. job_id: The ID of the job to trigger. options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. Returns: The run data returned from the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run @flow def trigger_dbt_cloud_job_run_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) trigger_dbt_cloud_job_run(dbt_cloud_credentials=credentials, job_id=1) trigger_dbt_cloud_job_run_flow() ``` Trigger a dbt Cloud job run with overrides: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run from prefect_dbt.cloud.models import TriggerJobRunOptions @flow def trigger_dbt_cloud_job_run_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) trigger_dbt_cloud_job_run( dbt_cloud_credentials=credentials, job_id=1, options=TriggerJobRunOptions( git_branch=\"staging\", schema_override=\"dbt_cloud_pr_123\", dbt_version_override=\"0.18.0\", target_name_override=\"staging\", timeout_seconds_override=3000, generate_docs_override=True, threads_override=8, steps_override=[ \"dbt seed\", \"dbt run --fail-fast\", \"dbt test --fail fast\", ], ), ) trigger_dbt_cloud_job_run() ``` \"\"\" # noqa logger = get_run_logger () logger . info ( f \"Triggering run for job with ID { job_id } \" ) try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . trigger_job_run ( job_id = job_id , options = options ) except HTTPStatusError as ex : raise DbtCloudJobRunTriggerFailed ( extract_user_message ( ex )) from ex run_data = response . json ()[ \"data\" ] logger . info ( f \"Run successfully triggered for job with ID { job_id } . \" \"You can view the status of this run at \" f \"https:// { dbt_cloud_credentials . domain } /#/accounts/\" f \" { dbt_cloud_credentials . account_id } /projects/ { run_data [ 'project_id' ] } /\" f \"runs/ { run_data [ 'id' ] } /\" ) return run_data","title":"trigger_dbt_cloud_job_run()"},{"location":"cloud/jobs/#prefect_dbt.cloud.jobs.trigger_dbt_cloud_job_run_and_wait_for_completion","text":"Flow that triggers a job run and waits for the triggered run to complete. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required job_id int The ID of the job to trigger. required trigger_job_run_options Optional [ TriggerJobRunOptions ] An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. None max_wait_seconds int Maximum number of seconds to wait for job to complete 900 poll_frequency_seconds int Number of seconds to wait in between checks for run completion. 10 Raises: Type Description DbtCloudJobRunCancelled The triggered dbt Cloud job run was cancelled. DbtCloudJobRunFailed The triggered dbt Cloud job run failed. RuntimeError The triggered dbt Cloud job run ended in an unexpected state. Returns: Type Description Dict The run data returned by the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job and wait for completion as a stand alone flow: import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion asyncio . run ( trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 ) ) Trigger a dbt Cloud job and wait for completion as a sub-flow: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion @flow def my_flow (): ... run_result = trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 ) ... my_flow () Trigger a dbt Cloud job with overrides: import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion from prefect_dbt.cloud.models import TriggerJobRunOptions asyncio . run ( trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ), job_id = 1 , trigger_job_run_options = TriggerJobRunOptions ( git_branch = \"staging\" , schema_override = \"dbt_cloud_pr_123\" , dbt_version_override = \"0.18.0\" , target_name_override = \"staging\" , timeout_seconds_override = 3000 , generate_docs_override = True , threads_override = 8 , steps_override = [ \"dbt seed\" , \"dbt run --fail-fast\" , \"dbt test --fail fast\" , ], ), ) ) Source code in prefect_dbt/cloud/jobs.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 @flow ( name = \"Trigger dbt Cloud job run and wait for completion\" , description = \"Triggers a dbt Cloud job run and waits for the\" \"triggered run to complete.\" , ) async def trigger_dbt_cloud_job_run_and_wait_for_completion ( dbt_cloud_credentials : DbtCloudCredentials , job_id : int , trigger_job_run_options : Optional [ TriggerJobRunOptions ] = None , max_wait_seconds : int = 900 , poll_frequency_seconds : int = 10 , ) -> Dict : \"\"\" Flow that triggers a job run and waits for the triggered run to complete. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. job_id: The ID of the job to trigger. trigger_job_run_options: An optional TriggerJobRunOptions instance to specify overrides for the triggered job run. max_wait_seconds: Maximum number of seconds to wait for job to complete poll_frequency_seconds: Number of seconds to wait in between checks for run completion. Raises: DbtCloudJobRunCancelled: The triggered dbt Cloud job run was cancelled. DbtCloudJobRunFailed: The triggered dbt Cloud job run failed. RuntimeError: The triggered dbt Cloud job run ended in an unexpected state. Returns: The run data returned by the dbt Cloud administrative API. Examples: Trigger a dbt Cloud job and wait for completion as a stand alone flow: ```python import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion asyncio.run( trigger_dbt_cloud_job_run_and_wait_for_completion( dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ), job_id=1 ) ) ``` Trigger a dbt Cloud job and wait for completion as a sub-flow: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion @flow def my_flow(): ... run_result = trigger_dbt_cloud_job_run_and_wait_for_completion( dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ), job_id=1 ) ... my_flow() ``` Trigger a dbt Cloud job with overrides: ```python import asyncio from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import trigger_dbt_cloud_job_run_and_wait_for_completion from prefect_dbt.cloud.models import TriggerJobRunOptions asyncio.run( trigger_dbt_cloud_job_run_and_wait_for_completion( dbt_cloud_credentials=DbtCloudCredentials( api_key=\"my_api_key\", account_id=123456789 ), job_id=1, trigger_job_run_options=TriggerJobRunOptions( git_branch=\"staging\", schema_override=\"dbt_cloud_pr_123\", dbt_version_override=\"0.18.0\", target_name_override=\"staging\", timeout_seconds_override=3000, generate_docs_override=True, threads_override=8, steps_override=[ \"dbt seed\", \"dbt run --fail-fast\", \"dbt test --fail fast\", ], ), ) ) ``` \"\"\" # noqa logger = get_run_logger () triggered_run_data_future = await trigger_dbt_cloud_job_run . submit ( dbt_cloud_credentials = dbt_cloud_credentials , job_id = job_id , options = trigger_job_run_options , ) run_id_future = get_run_id . submit ( triggered_run_data_future ) final_run_status , run_data = await wait_for_dbt_cloud_job_run ( run_id = run_id_future , dbt_cloud_credentials = dbt_cloud_credentials , max_wait_seconds = max_wait_seconds , poll_frequency_seconds = poll_frequency_seconds , ) if final_run_status == DbtCloudJobRunStatus . SUCCESS : try : list_run_artifacts_future = await list_dbt_cloud_run_artifacts . submit ( dbt_cloud_credentials = dbt_cloud_credentials , run_id = run_id_future , ) run_data [ \"artifact_paths\" ] = await list_run_artifacts_future . result () except DbtCloudListRunArtifactsFailed as ex : logger . warning ( \"Unable to retrieve artifacts for job run with ID %s . Reason: %s \" , run_id_future . result (), ex , ) logger . info ( \"dbt Cloud job run with ID %s completed successfully!\" , run_id_future . result (), ) return run_data elif final_run_status == DbtCloudJobRunStatus . CANCELLED : raise DbtCloudJobRunCancelled ( f \"Triggered job run with ID { run_id_future . result () } was cancelled.\" ) elif final_run_status == DbtCloudJobRunStatus . FAILED : raise DbtCloudJobRunFailed ( f \"Triggered job run with ID: { run_id_future . result () } failed.\" ) else : raise RuntimeError ( f \"Triggered job run with ID: { run_id_future . result () } ended with unexpected\" \"status {final_run_status.value} .\" )","title":"trigger_dbt_cloud_job_run_and_wait_for_completion()"},{"location":"cloud/models/","text":"prefect_dbt.cloud.models Module containing models used for passing data to dbt Cloud TriggerJobRunOptions Defines options that can be defined when triggering a dbt Cloud job run. Source code in prefect_dbt/cloud/models.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 class TriggerJobRunOptions ( BaseModel ): \"\"\" Defines options that can be defined when triggering a dbt Cloud job run. \"\"\" cause : str = Field ( default_factory = default_cause_factory , description = \"A text description of the reason for running this job.\" , ) git_sha : Optional [ str ] = Field ( default = None , description = \"The git sha to check out before running this job.\" ) git_branch : Optional [ str ] = Field ( default = None , description = \"The git branch to check out before running this job.\" ) schema_override : Optional [ str ] = Field ( default = None , description = \"Override the destination schema in the configured \" \"target for this job.\" , ) dbt_version_override : Optional [ str ] = Field ( default = None , description = \"Override the version of dbt used to run this job.\" ) threads_override : Optional [ int ] = Field ( default = None , description = \"Override the number of threads used to run this job.\" ) target_name_override : Optional [ str ] = Field ( default = None , description = \"Override the target.name context variable used when \" \"running this job\" , ) generate_docs_override : Optional [ bool ] = Field ( default = None , description = \"Override whether or not this job generates docs \" \"(true=yes, false=no).\" , ) timeout_seconds_override : Optional [ int ] = Field ( default = None , description = \"Override the timeout in seconds for this job.\" ) steps_override : Optional [ List [ str ]] = Field ( default = None , description = \"Override the list of steps for this job.\" ) default_cause_factory Factory function to populate the default cause for a job run to include information from the Prefect run context. Source code in prefect_dbt/cloud/models.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def default_cause_factory (): \"\"\" Factory function to populate the default cause for a job run to include information from the Prefect run context. \"\"\" cause = \"Triggered via Prefect\" try : context = get_run_context () if isinstance ( context , FlowRunContext ): cause = f \" { cause } in flow run { context . flow_run . name } \" elif isinstance ( context , TaskRunContext ): cause = f \" { cause } in task run { context . task_run . name } \" except RuntimeError : pass return cause","title":"Models"},{"location":"cloud/models/#prefect_dbt.cloud.models","text":"Module containing models used for passing data to dbt Cloud","title":"models"},{"location":"cloud/models/#prefect_dbt.cloud.models.TriggerJobRunOptions","text":"Defines options that can be defined when triggering a dbt Cloud job run. Source code in prefect_dbt/cloud/models.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 class TriggerJobRunOptions ( BaseModel ): \"\"\" Defines options that can be defined when triggering a dbt Cloud job run. \"\"\" cause : str = Field ( default_factory = default_cause_factory , description = \"A text description of the reason for running this job.\" , ) git_sha : Optional [ str ] = Field ( default = None , description = \"The git sha to check out before running this job.\" ) git_branch : Optional [ str ] = Field ( default = None , description = \"The git branch to check out before running this job.\" ) schema_override : Optional [ str ] = Field ( default = None , description = \"Override the destination schema in the configured \" \"target for this job.\" , ) dbt_version_override : Optional [ str ] = Field ( default = None , description = \"Override the version of dbt used to run this job.\" ) threads_override : Optional [ int ] = Field ( default = None , description = \"Override the number of threads used to run this job.\" ) target_name_override : Optional [ str ] = Field ( default = None , description = \"Override the target.name context variable used when \" \"running this job\" , ) generate_docs_override : Optional [ bool ] = Field ( default = None , description = \"Override whether or not this job generates docs \" \"(true=yes, false=no).\" , ) timeout_seconds_override : Optional [ int ] = Field ( default = None , description = \"Override the timeout in seconds for this job.\" ) steps_override : Optional [ List [ str ]] = Field ( default = None , description = \"Override the list of steps for this job.\" )","title":"TriggerJobRunOptions"},{"location":"cloud/models/#prefect_dbt.cloud.models.default_cause_factory","text":"Factory function to populate the default cause for a job run to include information from the Prefect run context. Source code in prefect_dbt/cloud/models.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def default_cause_factory (): \"\"\" Factory function to populate the default cause for a job run to include information from the Prefect run context. \"\"\" cause = \"Triggered via Prefect\" try : context = get_run_context () if isinstance ( context , FlowRunContext ): cause = f \" { cause } in flow run { context . flow_run . name } \" elif isinstance ( context , TaskRunContext ): cause = f \" { cause } in task run { context . task_run . name } \" except RuntimeError : pass return cause","title":"default_cause_factory()"},{"location":"cloud/runs/","text":"prefect_dbt.cloud.runs Module containing tasks and flows for interacting with dbt Cloud job runs DbtCloudGetRunArtifactFailed Raised when unable to get a dbt Cloud run artifact Source code in prefect_dbt/cloud/runs.py 25 26 27 28 class DbtCloudGetRunArtifactFailed ( Exception ): \"\"\"Raised when unable to get a dbt Cloud run artifact\"\"\" pass DbtCloudGetRunFailed Raised when unable to retrieve dbt Cloud run Source code in prefect_dbt/cloud/runs.py 13 14 15 16 class DbtCloudGetRunFailed ( Exception ): \"\"\"Raised when unable to retrieve dbt Cloud run\"\"\" pass DbtCloudJobRunCancelled Raised when a triggered job run is cancelled Source code in prefect_dbt/cloud/runs.py 37 38 39 40 class DbtCloudJobRunCancelled ( Exception ): \"\"\"Raised when a triggered job run is cancelled\"\"\" pass DbtCloudJobRunFailed Raised when a triggered job run fails Source code in prefect_dbt/cloud/runs.py 31 32 33 34 class DbtCloudJobRunFailed ( Exception ): \"\"\"Raised when a triggered job run fails\"\"\" pass DbtCloudJobRunStatus dbt Cloud Job statuses. Source code in prefect_dbt/cloud/runs.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 class DbtCloudJobRunStatus ( Enum ): \"\"\"dbt Cloud Job statuses.\"\"\" QUEUED = 1 STARTING = 2 RUNNING = 3 SUCCESS = 10 FAILED = 20 CANCELLED = 30 @classmethod def is_terminal_status_code ( cls , status_code : Any ) -> bool : \"\"\" Returns True if a status code is terminal for a job run. Returns False otherwise. \"\"\" return status_code in [ cls . SUCCESS . value , cls . FAILED . value , cls . CANCELLED . value ] is_terminal_status_code classmethod Returns True if a status code is terminal for a job run. Returns False otherwise. Source code in prefect_dbt/cloud/runs.py 62 63 64 65 66 67 68 @classmethod def is_terminal_status_code ( cls , status_code : Any ) -> bool : \"\"\" Returns True if a status code is terminal for a job run. Returns False otherwise. \"\"\" return status_code in [ cls . SUCCESS . value , cls . FAILED . value , cls . CANCELLED . value ] DbtCloudJobRunTimedOut Raised when a triggered job run does not complete in the configured max wait seconds Source code in prefect_dbt/cloud/runs.py 43 44 45 46 47 48 49 class DbtCloudJobRunTimedOut ( Exception ): \"\"\" Raised when a triggered job run does not complete in the configured max wait seconds \"\"\" pass DbtCloudListRunArtifactsFailed Raised when unable to list dbt Cloud run artifacts Source code in prefect_dbt/cloud/runs.py 19 20 21 22 class DbtCloudListRunArtifactsFailed ( Exception ): \"\"\"Raised when unable to list dbt Cloud run artifacts\"\"\" pass get_dbt_cloud_run_artifact async A task to get an artifact generated for a completed run. The requested artifact is saved to a file in the current working directory. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required run_id int The ID of the run to list run artifacts for. required path str The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description Union [ Dict , str ] The contents of the requested manifest. Returns a Dict if the requested artifact is a JSON file and a str otherwise. Examples: Get an artifact of a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact @flow def get_artifact_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return get_dbt_cloud_run_artifact ( dbt_cloud_credentials = credentials , run_id = 42 , path = \"manifest.json\" ) get_artifact_flow () Get an artifact of a dbt Cloud job run and write it to a file: import json from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact @flow def get_artifact_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) get_run_artifact_result = get_dbt_cloud_run_artifact ( dbt_cloud_credentials = credentials , run_id = 42 , path = \"manifest.json\" ) with open ( \"manifest.json\" , \"w\" ) as file : json . dump ( get_run_artifact_result , file ) get_artifact_flow () Source code in prefect_dbt/cloud/runs.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 @task ( name = \"Get dbt Cloud job artifact\" , description = \"Fetches an artifact from a completed run.\" , retries = 3 , retry_delay_seconds = 10 , ) async def get_dbt_cloud_run_artifact ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int , path : str , step : Optional [ int ] = None , ) -> Union [ Dict , str ]: \"\"\" A task to get an artifact generated for a completed run. The requested artifact is saved to a file in the current working directory. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. run_id: The ID of the run to list run artifacts for. path: The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The contents of the requested manifest. Returns a `Dict` if the requested artifact is a JSON file and a `str` otherwise. Examples: Get an artifact of a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact @flow def get_artifact_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return get_dbt_cloud_run_artifact( dbt_cloud_credentials=credentials, run_id=42, path=\"manifest.json\" ) get_artifact_flow() ``` Get an artifact of a dbt Cloud job run and write it to a file: ```python import json from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact @flow def get_artifact_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) get_run_artifact_result = get_dbt_cloud_run_artifact( dbt_cloud_credentials=credentials, run_id=42, path=\"manifest.json\" ) with open(\"manifest.json\", \"w\") as file: json.dump(get_run_artifact_result, file) get_artifact_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . get_run_artifact ( run_id = run_id , path = path , step = step ) except HTTPStatusError as ex : raise DbtCloudGetRunArtifactFailed ( extract_user_message ( ex )) from ex if path . endswith ( \".json\" ): artifact_contents = response . json () else : artifact_contents = response . text return artifact_contents get_dbt_cloud_run_info async A task to retrieve information about a dbt Cloud job run. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required run_id int The ID of the job to trigger. required Returns: Type Description Dict The run data returned by the dbt Cloud administrative API. Example Get status of a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_run @flow def get_run_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return get_run ( dbt_cloud_credentials = credentials , run_id = 42 ) get_run_flow () Source code in prefect_dbt/cloud/runs.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 @task ( name = \"Get dbt Cloud job run details\" , description = \"Retrieves details of a dbt Cloud job run \" \"for the run with the given run_id.\" , retries = 3 , retry_delay_seconds = 10 , ) async def get_dbt_cloud_run_info ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int ) -> Dict : \"\"\" A task to retrieve information about a dbt Cloud job run. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. run_id: The ID of the job to trigger. Returns: The run data returned by the dbt Cloud administrative API. Example: Get status of a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_run @flow def get_run_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return get_run( dbt_cloud_credentials=credentials, run_id=42 ) get_run_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . get_run ( run_id = run_id ) except HTTPStatusError as ex : raise DbtCloudGetRunFailed ( extract_user_message ( ex )) from ex return response . json ()[ \"data\" ] list_dbt_cloud_run_artifacts async A task to list the artifact files generated for a completed run. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required run_id int The ID of the run to list run artifacts for. required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description List [ str ] A list of paths to artifact files that can be used to retrieve the generated artifacts. Example List artifacts of a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts @flow def list_artifacts_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return list_dbt_cloud_run_artifacts ( dbt_cloud_credentials = credentials , run_id = 42 ) list_artifacts_flow () Source code in prefect_dbt/cloud/runs.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 @task ( name = \"List dbt Cloud job artifacts\" , description = \"Fetches a list of artifact files generated for a completed run.\" , retries = 3 , retry_delay_seconds = 10 , ) async def list_dbt_cloud_run_artifacts ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int , step : Optional [ int ] = None ) -> List [ str ]: \"\"\" A task to list the artifact files generated for a completed run. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. run_id: The ID of the run to list run artifacts for. step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: A list of paths to artifact files that can be used to retrieve the generated artifacts. Example: List artifacts of a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts @flow def list_artifacts_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return list_dbt_cloud_run_artifacts( dbt_cloud_credentials=credentials, run_id=42 ) list_artifacts_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . list_run_artifacts ( run_id = run_id , step = step ) except HTTPStatusError as ex : raise DbtCloudListRunArtifactsFailed ( extract_user_message ( ex )) from ex return response . json ()[ \"data\" ] wait_for_dbt_cloud_job_run async Waits for the given dbt Cloud job run to finish running. Parameters: Name Type Description Default run_id int The ID of the run to wait for. required dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required max_wait_seconds int Maximum number of seconds to wait for job to complete 900 poll_frequency_seconds int Number of seconds to wait in between checks for run completion. 10 Raises: Type Description DbtCloudJobRunTimedOut When the elapsed wait time exceeds max_wait_seconds . Returns: Name Type Description run_status DbtCloudJobRunStatus An enum representing the final dbt Cloud job run status run_data Dict A dictionary containing information about the run after completion. Source code in prefect_dbt/cloud/runs.py 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 @flow ( name = \"Wait for dbt Cloud job run\" , description = \"Waits for a dbt Cloud job run to finish running.\" , ) async def wait_for_dbt_cloud_job_run ( run_id : int , dbt_cloud_credentials : DbtCloudCredentials , max_wait_seconds : int = 900 , poll_frequency_seconds : int = 10 , ) -> Tuple [ DbtCloudJobRunStatus , Dict ]: \"\"\" Waits for the given dbt Cloud job run to finish running. Args: run_id: The ID of the run to wait for. dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. max_wait_seconds: Maximum number of seconds to wait for job to complete poll_frequency_seconds: Number of seconds to wait in between checks for run completion. Raises: DbtCloudJobRunTimedOut: When the elapsed wait time exceeds `max_wait_seconds`. Returns: run_status: An enum representing the final dbt Cloud job run status run_data: A dictionary containing information about the run after completion. Example: \"\"\" logger = get_run_logger () seconds_waited_for_run_completion = 0 wait_for = [] while seconds_waited_for_run_completion <= max_wait_seconds : run_data_future = await get_dbt_cloud_run_info . submit ( dbt_cloud_credentials = dbt_cloud_credentials , run_id = run_id , wait_for = wait_for , ) run_data = await run_data_future . result () run_status_code = run_data . get ( \"status\" ) if DbtCloudJobRunStatus . is_terminal_status_code ( run_status_code ): return DbtCloudJobRunStatus ( run_status_code ), run_data wait_for = [ run_data_future ] logger . info ( \"dbt Cloud job run with ID %i has status %s . Waiting for %i seconds.\" , run_id , DbtCloudJobRunStatus ( run_status_code ) . name , poll_frequency_seconds , ) await asyncio . sleep ( poll_frequency_seconds ) seconds_waited_for_run_completion += poll_frequency_seconds raise DbtCloudJobRunTimedOut ( f \"Max wait time of { max_wait_seconds } seconds exceeded while waiting \" \"for job run with ID {run_id} \" )","title":"Runs"},{"location":"cloud/runs/#prefect_dbt.cloud.runs","text":"Module containing tasks and flows for interacting with dbt Cloud job runs","title":"runs"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudGetRunArtifactFailed","text":"Raised when unable to get a dbt Cloud run artifact Source code in prefect_dbt/cloud/runs.py 25 26 27 28 class DbtCloudGetRunArtifactFailed ( Exception ): \"\"\"Raised when unable to get a dbt Cloud run artifact\"\"\" pass","title":"DbtCloudGetRunArtifactFailed"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudGetRunFailed","text":"Raised when unable to retrieve dbt Cloud run Source code in prefect_dbt/cloud/runs.py 13 14 15 16 class DbtCloudGetRunFailed ( Exception ): \"\"\"Raised when unable to retrieve dbt Cloud run\"\"\" pass","title":"DbtCloudGetRunFailed"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunCancelled","text":"Raised when a triggered job run is cancelled Source code in prefect_dbt/cloud/runs.py 37 38 39 40 class DbtCloudJobRunCancelled ( Exception ): \"\"\"Raised when a triggered job run is cancelled\"\"\" pass","title":"DbtCloudJobRunCancelled"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunFailed","text":"Raised when a triggered job run fails Source code in prefect_dbt/cloud/runs.py 31 32 33 34 class DbtCloudJobRunFailed ( Exception ): \"\"\"Raised when a triggered job run fails\"\"\" pass","title":"DbtCloudJobRunFailed"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunStatus","text":"dbt Cloud Job statuses. Source code in prefect_dbt/cloud/runs.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 class DbtCloudJobRunStatus ( Enum ): \"\"\"dbt Cloud Job statuses.\"\"\" QUEUED = 1 STARTING = 2 RUNNING = 3 SUCCESS = 10 FAILED = 20 CANCELLED = 30 @classmethod def is_terminal_status_code ( cls , status_code : Any ) -> bool : \"\"\" Returns True if a status code is terminal for a job run. Returns False otherwise. \"\"\" return status_code in [ cls . SUCCESS . value , cls . FAILED . value , cls . CANCELLED . value ]","title":"DbtCloudJobRunStatus"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunStatus.is_terminal_status_code","text":"Returns True if a status code is terminal for a job run. Returns False otherwise. Source code in prefect_dbt/cloud/runs.py 62 63 64 65 66 67 68 @classmethod def is_terminal_status_code ( cls , status_code : Any ) -> bool : \"\"\" Returns True if a status code is terminal for a job run. Returns False otherwise. \"\"\" return status_code in [ cls . SUCCESS . value , cls . FAILED . value , cls . CANCELLED . value ]","title":"is_terminal_status_code()"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudJobRunTimedOut","text":"Raised when a triggered job run does not complete in the configured max wait seconds Source code in prefect_dbt/cloud/runs.py 43 44 45 46 47 48 49 class DbtCloudJobRunTimedOut ( Exception ): \"\"\" Raised when a triggered job run does not complete in the configured max wait seconds \"\"\" pass","title":"DbtCloudJobRunTimedOut"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.DbtCloudListRunArtifactsFailed","text":"Raised when unable to list dbt Cloud run artifacts Source code in prefect_dbt/cloud/runs.py 19 20 21 22 class DbtCloudListRunArtifactsFailed ( Exception ): \"\"\"Raised when unable to list dbt Cloud run artifacts\"\"\" pass","title":"DbtCloudListRunArtifactsFailed"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.get_dbt_cloud_run_artifact","text":"A task to get an artifact generated for a completed run. The requested artifact is saved to a file in the current working directory. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required run_id int The ID of the run to list run artifacts for. required path str The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description Union [ Dict , str ] The contents of the requested manifest. Returns a Dict if the requested artifact is a JSON file and a str otherwise. Examples: Get an artifact of a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact @flow def get_artifact_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return get_dbt_cloud_run_artifact ( dbt_cloud_credentials = credentials , run_id = 42 , path = \"manifest.json\" ) get_artifact_flow () Get an artifact of a dbt Cloud job run and write it to a file: import json from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact @flow def get_artifact_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) get_run_artifact_result = get_dbt_cloud_run_artifact ( dbt_cloud_credentials = credentials , run_id = 42 , path = \"manifest.json\" ) with open ( \"manifest.json\" , \"w\" ) as file : json . dump ( get_run_artifact_result , file ) get_artifact_flow () Source code in prefect_dbt/cloud/runs.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 @task ( name = \"Get dbt Cloud job artifact\" , description = \"Fetches an artifact from a completed run.\" , retries = 3 , retry_delay_seconds = 10 , ) async def get_dbt_cloud_run_artifact ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int , path : str , step : Optional [ int ] = None , ) -> Union [ Dict , str ]: \"\"\" A task to get an artifact generated for a completed run. The requested artifact is saved to a file in the current working directory. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. run_id: The ID of the run to list run artifacts for. path: The relative path to the run artifact (e.g. manifest.json, catalog.json, run_results.json) step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: The contents of the requested manifest. Returns a `Dict` if the requested artifact is a JSON file and a `str` otherwise. Examples: Get an artifact of a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.runs import get_dbt_cloud_run_artifact @flow def get_artifact_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return get_dbt_cloud_run_artifact( dbt_cloud_credentials=credentials, run_id=42, path=\"manifest.json\" ) get_artifact_flow() ``` Get an artifact of a dbt Cloud job run and write it to a file: ```python import json from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_dbt_cloud_run_artifact @flow def get_artifact_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) get_run_artifact_result = get_dbt_cloud_run_artifact( dbt_cloud_credentials=credentials, run_id=42, path=\"manifest.json\" ) with open(\"manifest.json\", \"w\") as file: json.dump(get_run_artifact_result, file) get_artifact_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . get_run_artifact ( run_id = run_id , path = path , step = step ) except HTTPStatusError as ex : raise DbtCloudGetRunArtifactFailed ( extract_user_message ( ex )) from ex if path . endswith ( \".json\" ): artifact_contents = response . json () else : artifact_contents = response . text return artifact_contents","title":"get_dbt_cloud_run_artifact()"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.get_dbt_cloud_run_info","text":"A task to retrieve information about a dbt Cloud job run. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required run_id int The ID of the job to trigger. required Returns: Type Description Dict The run data returned by the dbt Cloud administrative API. Example Get status of a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_run @flow def get_run_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return get_run ( dbt_cloud_credentials = credentials , run_id = 42 ) get_run_flow () Source code in prefect_dbt/cloud/runs.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 @task ( name = \"Get dbt Cloud job run details\" , description = \"Retrieves details of a dbt Cloud job run \" \"for the run with the given run_id.\" , retries = 3 , retry_delay_seconds = 10 , ) async def get_dbt_cloud_run_info ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int ) -> Dict : \"\"\" A task to retrieve information about a dbt Cloud job run. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. run_id: The ID of the job to trigger. Returns: The run data returned by the dbt Cloud administrative API. Example: Get status of a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import get_run @flow def get_run_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return get_run( dbt_cloud_credentials=credentials, run_id=42 ) get_run_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . get_run ( run_id = run_id ) except HTTPStatusError as ex : raise DbtCloudGetRunFailed ( extract_user_message ( ex )) from ex return response . json ()[ \"data\" ]","title":"get_dbt_cloud_run_info()"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.list_dbt_cloud_run_artifacts","text":"A task to list the artifact files generated for a completed run. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required run_id int The ID of the run to list run artifacts for. required step Optional [ int ] The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. None Returns: Type Description List [ str ] A list of paths to artifact files that can be used to retrieve the generated artifacts. Example List artifacts of a dbt Cloud job run: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts @flow def list_artifacts_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) return list_dbt_cloud_run_artifacts ( dbt_cloud_credentials = credentials , run_id = 42 ) list_artifacts_flow () Source code in prefect_dbt/cloud/runs.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 @task ( name = \"List dbt Cloud job artifacts\" , description = \"Fetches a list of artifact files generated for a completed run.\" , retries = 3 , retry_delay_seconds = 10 , ) async def list_dbt_cloud_run_artifacts ( dbt_cloud_credentials : DbtCloudCredentials , run_id : int , step : Optional [ int ] = None ) -> List [ str ]: \"\"\" A task to list the artifact files generated for a completed run. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. run_id: The ID of the run to list run artifacts for. step: The index of the step in the run to query for artifacts. The first step in the run has the index 1. If the step parameter is omitted, then this method will return the artifacts compiled for the last step in the run. Returns: A list of paths to artifact files that can be used to retrieve the generated artifacts. Example: List artifacts of a dbt Cloud job run: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.jobs import list_dbt_cloud_run_artifacts @flow def list_artifacts_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) return list_dbt_cloud_run_artifacts( dbt_cloud_credentials=credentials, run_id=42 ) list_artifacts_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . list_run_artifacts ( run_id = run_id , step = step ) except HTTPStatusError as ex : raise DbtCloudListRunArtifactsFailed ( extract_user_message ( ex )) from ex return response . json ()[ \"data\" ]","title":"list_dbt_cloud_run_artifacts()"},{"location":"cloud/runs/#prefect_dbt.cloud.runs.wait_for_dbt_cloud_job_run","text":"Waits for the given dbt Cloud job run to finish running. Parameters: Name Type Description Default run_id int The ID of the run to wait for. required dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required max_wait_seconds int Maximum number of seconds to wait for job to complete 900 poll_frequency_seconds int Number of seconds to wait in between checks for run completion. 10 Raises: Type Description DbtCloudJobRunTimedOut When the elapsed wait time exceeds max_wait_seconds . Returns: Name Type Description run_status DbtCloudJobRunStatus An enum representing the final dbt Cloud job run status run_data Dict A dictionary containing information about the run after completion. Source code in prefect_dbt/cloud/runs.py 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 @flow ( name = \"Wait for dbt Cloud job run\" , description = \"Waits for a dbt Cloud job run to finish running.\" , ) async def wait_for_dbt_cloud_job_run ( run_id : int , dbt_cloud_credentials : DbtCloudCredentials , max_wait_seconds : int = 900 , poll_frequency_seconds : int = 10 , ) -> Tuple [ DbtCloudJobRunStatus , Dict ]: \"\"\" Waits for the given dbt Cloud job run to finish running. Args: run_id: The ID of the run to wait for. dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. max_wait_seconds: Maximum number of seconds to wait for job to complete poll_frequency_seconds: Number of seconds to wait in between checks for run completion. Raises: DbtCloudJobRunTimedOut: When the elapsed wait time exceeds `max_wait_seconds`. Returns: run_status: An enum representing the final dbt Cloud job run status run_data: A dictionary containing information about the run after completion. Example: \"\"\" logger = get_run_logger () seconds_waited_for_run_completion = 0 wait_for = [] while seconds_waited_for_run_completion <= max_wait_seconds : run_data_future = await get_dbt_cloud_run_info . submit ( dbt_cloud_credentials = dbt_cloud_credentials , run_id = run_id , wait_for = wait_for , ) run_data = await run_data_future . result () run_status_code = run_data . get ( \"status\" ) if DbtCloudJobRunStatus . is_terminal_status_code ( run_status_code ): return DbtCloudJobRunStatus ( run_status_code ), run_data wait_for = [ run_data_future ] logger . info ( \"dbt Cloud job run with ID %i has status %s . Waiting for %i seconds.\" , run_id , DbtCloudJobRunStatus ( run_status_code ) . name , poll_frequency_seconds , ) await asyncio . sleep ( poll_frequency_seconds ) seconds_waited_for_run_completion += poll_frequency_seconds raise DbtCloudJobRunTimedOut ( f \"Max wait time of { max_wait_seconds } seconds exceeded while waiting \" \"for job run with ID {run_id} \" )","title":"wait_for_dbt_cloud_job_run()"},{"location":"cloud/utils/","text":"prefect_dbt.cloud.utils Utilities for common interactions with the dbt Cloud API DbtCloudAdministrativeApiCallFailed Raised when a call to dbt Cloud administrative API fails. Source code in prefect_dbt/cloud/utils.py 44 45 46 47 class DbtCloudAdministrativeApiCallFailed ( Exception ): \"\"\"Raised when a call to dbt Cloud administrative API fails.\"\"\" pass call_dbt_cloud_administrative_api_endpoint async Task that calls a specified endpoint in the dbt Cloud administrative API. Use this task if a prebuilt one is not yet available. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required path str The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. required http_method str HTTP method to call on the endpoint. required params Optional [ Dict [ str , Any ]] Query parameters to include in the request. None json Optional [ Dict [ str , Any ]] JSON serializable body to send in the request. None Returns: Type Description Any The body of the response. If the body is JSON serializable, then the result of json.loads with the body as the input will be returned. Otherwise, the body will be returned directly. Examples: List projects for an account: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def get_projects_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) result = call_dbt_cloud_administrative_api_endpoint ( dbt_cloud_credentials = credentials , path = \"/projects/\" , http_method = \"GET\" , ) return result [ \"data\" ] get_projects_flow () Create a new job: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def create_job_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) result = call_dbt_cloud_administrative_api_endpoint ( dbt_cloud_credentials = credentials , path = \"/jobs/\" , http_method = \"POST\" , json = { \"id\" : None , \"account_id\" : 123456789 , \"project_id\" : 100 , \"environment_id\" : 10 , \"name\" : \"Nightly run\" , \"dbt_version\" : None , \"triggers\" : { \"github_webhook\" : True , \"schedule\" : True }, \"execute_steps\" : [ \"dbt run\" , \"dbt test\" , \"dbt source snapshot-freshness\" ], \"settings\" : { \"threads\" : 4 , \"target_name\" : \"prod\" }, \"state\" : 1 , \"schedule\" : { \"date\" : { \"type\" : \"every_day\" }, \"time\" : { \"type\" : \"every_hour\" , \"interval\" : 1 }, }, }, ) return result [ \"data\" ] create_job_flow () Source code in prefect_dbt/cloud/utils.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 @task ( name = \"Call dbt Cloud administrative API endpoint\" , description = \"Calls a dbt Cloud administrative API endpoint\" , retries = 3 , retry_delay_seconds = 10 , ) async def call_dbt_cloud_administrative_api_endpoint ( dbt_cloud_credentials : DbtCloudCredentials , path : str , http_method : str , params : Optional [ Dict [ str , Any ]] = None , json : Optional [ Dict [ str , Any ]] = None , ) -> Any : \"\"\" Task that calls a specified endpoint in the dbt Cloud administrative API. Use this task if a prebuilt one is not yet available. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. path: The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. http_method: HTTP method to call on the endpoint. params: Query parameters to include in the request. json: JSON serializable body to send in the request. Returns: The body of the response. If the body is JSON serializable, then the result of `json.loads` with the body as the input will be returned. Otherwise, the body will be returned directly. Examples: List projects for an account: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def get_projects_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) result = call_dbt_cloud_administrative_api_endpoint( dbt_cloud_credentials=credentials, path=\"/projects/\", http_method=\"GET\", ) return result[\"data\"] get_projects_flow() ``` Create a new job: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def create_job_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) result = call_dbt_cloud_administrative_api_endpoint( dbt_cloud_credentials=credentials, path=\"/jobs/\", http_method=\"POST\", json={ \"id\": None, \"account_id\": 123456789, \"project_id\": 100, \"environment_id\": 10, \"name\": \"Nightly run\", \"dbt_version\": None, \"triggers\": {\"github_webhook\": True, \"schedule\": True}, \"execute_steps\": [\"dbt run\", \"dbt test\", \"dbt source snapshot-freshness\"], \"settings\": {\"threads\": 4, \"target_name\": \"prod\"}, \"state\": 1, \"schedule\": { \"date\": {\"type\": \"every_day\"}, \"time\": {\"type\": \"every_hour\", \"interval\": 1}, }, }, ) return result[\"data\"] create_job_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . call_endpoint ( http_method = http_method , path = path , params = params , json = json ) except HTTPStatusError as ex : raise DbtCloudAdministrativeApiCallFailed ( extract_developer_message ( ex )) from ex try : return response . json () except JSONDecodeError : return response . text extract_developer_message Extracts developer message from a error response from the dbt Cloud administrative API. Parameters: Name Type Description Default ex HTTPStatusError An HTTPStatusError raised by httpx required Returns: Type Description Optional [ str ] developer_message from dbt Cloud administrative API response or None if a Optional [ str ] developer_message cannot be extracted Source code in prefect_dbt/cloud/utils.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def extract_developer_message ( ex : HTTPStatusError ) -> Optional [ str ]: \"\"\" Extracts developer message from a error response from the dbt Cloud administrative API. Args: ex: An HTTPStatusError raised by httpx Returns: developer_message from dbt Cloud administrative API response or None if a developer_message cannot be extracted \"\"\" response_payload = ex . response . json () status = response_payload . get ( \"status\" , {}) return status . get ( \"developer_message\" ) extract_user_message Extracts user message from a error response from the dbt Cloud administrative API. Parameters: Name Type Description Default ex HTTPStatusError An HTTPStatusError raised by httpx required Returns: Type Description Optional [ str ] user_message from dbt Cloud administrative API response or None if a Optional [ str ] user_message cannot be extracted Source code in prefect_dbt/cloud/utils.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def extract_user_message ( ex : HTTPStatusError ) -> Optional [ str ]: \"\"\" Extracts user message from a error response from the dbt Cloud administrative API. Args: ex: An HTTPStatusError raised by httpx Returns: user_message from dbt Cloud administrative API response or None if a user_message cannot be extracted \"\"\" response_payload = ex . response . json () status = response_payload . get ( \"status\" , {}) return status . get ( \"user_message\" )","title":"Utils"},{"location":"cloud/utils/#prefect_dbt.cloud.utils","text":"Utilities for common interactions with the dbt Cloud API","title":"utils"},{"location":"cloud/utils/#prefect_dbt.cloud.utils.DbtCloudAdministrativeApiCallFailed","text":"Raised when a call to dbt Cloud administrative API fails. Source code in prefect_dbt/cloud/utils.py 44 45 46 47 class DbtCloudAdministrativeApiCallFailed ( Exception ): \"\"\"Raised when a call to dbt Cloud administrative API fails.\"\"\" pass","title":"DbtCloudAdministrativeApiCallFailed"},{"location":"cloud/utils/#prefect_dbt.cloud.utils.call_dbt_cloud_administrative_api_endpoint","text":"Task that calls a specified endpoint in the dbt Cloud administrative API. Use this task if a prebuilt one is not yet available. Parameters: Name Type Description Default dbt_cloud_credentials DbtCloudCredentials Credentials for authenticating with dbt Cloud. required path str The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. required http_method str HTTP method to call on the endpoint. required params Optional [ Dict [ str , Any ]] Query parameters to include in the request. None json Optional [ Dict [ str , Any ]] JSON serializable body to send in the request. None Returns: Type Description Any The body of the response. If the body is JSON serializable, then the result of json.loads with the body as the input will be returned. Otherwise, the body will be returned directly. Examples: List projects for an account: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def get_projects_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) result = call_dbt_cloud_administrative_api_endpoint ( dbt_cloud_credentials = credentials , path = \"/projects/\" , http_method = \"GET\" , ) return result [ \"data\" ] get_projects_flow () Create a new job: from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def create_job_flow (): credentials = DbtCloudCredentials ( api_key = \"my_api_key\" , account_id = 123456789 ) result = call_dbt_cloud_administrative_api_endpoint ( dbt_cloud_credentials = credentials , path = \"/jobs/\" , http_method = \"POST\" , json = { \"id\" : None , \"account_id\" : 123456789 , \"project_id\" : 100 , \"environment_id\" : 10 , \"name\" : \"Nightly run\" , \"dbt_version\" : None , \"triggers\" : { \"github_webhook\" : True , \"schedule\" : True }, \"execute_steps\" : [ \"dbt run\" , \"dbt test\" , \"dbt source snapshot-freshness\" ], \"settings\" : { \"threads\" : 4 , \"target_name\" : \"prod\" }, \"state\" : 1 , \"schedule\" : { \"date\" : { \"type\" : \"every_day\" }, \"time\" : { \"type\" : \"every_hour\" , \"interval\" : 1 }, }, }, ) return result [ \"data\" ] create_job_flow () Source code in prefect_dbt/cloud/utils.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 @task ( name = \"Call dbt Cloud administrative API endpoint\" , description = \"Calls a dbt Cloud administrative API endpoint\" , retries = 3 , retry_delay_seconds = 10 , ) async def call_dbt_cloud_administrative_api_endpoint ( dbt_cloud_credentials : DbtCloudCredentials , path : str , http_method : str , params : Optional [ Dict [ str , Any ]] = None , json : Optional [ Dict [ str , Any ]] = None , ) -> Any : \"\"\" Task that calls a specified endpoint in the dbt Cloud administrative API. Use this task if a prebuilt one is not yet available. Args: dbt_cloud_credentials: Credentials for authenticating with dbt Cloud. path: The partial path for the request (e.g. /projects/). Will be appended onto the base URL as determined by the client configuration. http_method: HTTP method to call on the endpoint. params: Query parameters to include in the request. json: JSON serializable body to send in the request. Returns: The body of the response. If the body is JSON serializable, then the result of `json.loads` with the body as the input will be returned. Otherwise, the body will be returned directly. Examples: List projects for an account: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def get_projects_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) result = call_dbt_cloud_administrative_api_endpoint( dbt_cloud_credentials=credentials, path=\"/projects/\", http_method=\"GET\", ) return result[\"data\"] get_projects_flow() ``` Create a new job: ```python from prefect import flow from prefect_dbt.cloud import DbtCloudCredentials from prefect_dbt.cloud.utils import call_dbt_cloud_administrative_api_endpoint @flow def create_job_flow(): credentials = DbtCloudCredentials(api_key=\"my_api_key\", account_id=123456789) result = call_dbt_cloud_administrative_api_endpoint( dbt_cloud_credentials=credentials, path=\"/jobs/\", http_method=\"POST\", json={ \"id\": None, \"account_id\": 123456789, \"project_id\": 100, \"environment_id\": 10, \"name\": \"Nightly run\", \"dbt_version\": None, \"triggers\": {\"github_webhook\": True, \"schedule\": True}, \"execute_steps\": [\"dbt run\", \"dbt test\", \"dbt source snapshot-freshness\"], \"settings\": {\"threads\": 4, \"target_name\": \"prod\"}, \"state\": 1, \"schedule\": { \"date\": {\"type\": \"every_day\"}, \"time\": {\"type\": \"every_hour\", \"interval\": 1}, }, }, ) return result[\"data\"] create_job_flow() ``` \"\"\" # noqa try : async with dbt_cloud_credentials . get_administrative_client () as client : response = await client . call_endpoint ( http_method = http_method , path = path , params = params , json = json ) except HTTPStatusError as ex : raise DbtCloudAdministrativeApiCallFailed ( extract_developer_message ( ex )) from ex try : return response . json () except JSONDecodeError : return response . text","title":"call_dbt_cloud_administrative_api_endpoint()"},{"location":"cloud/utils/#prefect_dbt.cloud.utils.extract_developer_message","text":"Extracts developer message from a error response from the dbt Cloud administrative API. Parameters: Name Type Description Default ex HTTPStatusError An HTTPStatusError raised by httpx required Returns: Type Description Optional [ str ] developer_message from dbt Cloud administrative API response or None if a Optional [ str ] developer_message cannot be extracted Source code in prefect_dbt/cloud/utils.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def extract_developer_message ( ex : HTTPStatusError ) -> Optional [ str ]: \"\"\" Extracts developer message from a error response from the dbt Cloud administrative API. Args: ex: An HTTPStatusError raised by httpx Returns: developer_message from dbt Cloud administrative API response or None if a developer_message cannot be extracted \"\"\" response_payload = ex . response . json () status = response_payload . get ( \"status\" , {}) return status . get ( \"developer_message\" )","title":"extract_developer_message()"},{"location":"cloud/utils/#prefect_dbt.cloud.utils.extract_user_message","text":"Extracts user message from a error response from the dbt Cloud administrative API. Parameters: Name Type Description Default ex HTTPStatusError An HTTPStatusError raised by httpx required Returns: Type Description Optional [ str ] user_message from dbt Cloud administrative API response or None if a Optional [ str ] user_message cannot be extracted Source code in prefect_dbt/cloud/utils.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def extract_user_message ( ex : HTTPStatusError ) -> Optional [ str ]: \"\"\" Extracts user message from a error response from the dbt Cloud administrative API. Args: ex: An HTTPStatusError raised by httpx Returns: user_message from dbt Cloud administrative API response or None if a user_message cannot be extracted \"\"\" response_payload = ex . response . json () status = response_payload . get ( \"status\" , {}) return status . get ( \"user_message\" )","title":"extract_user_message()"}]}